{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:299: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:315: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:321: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:342: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:346: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:347: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:350: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:351: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:352: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:306: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:273: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:405: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:115: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Populating replay memory...\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:164: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "\n",
      "Copied model parameters to target network.\n",
      "Step 174 (174) @ Episode 1/10000, loss: 0.0009155137231573462WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:245: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "\n",
      "Episode Reward: 0.0\n",
      "Step 174 (348) @ Episode 2/10000, loss: 0.0535809285938739876\n",
      "Episode Reward: 0.0\n",
      "Step 197 (545) @ Episode 3/10000, loss: 0.0009185342933051288\n",
      "Episode Reward: 1.0\n",
      "Step 163 (708) @ Episode 4/10000, loss: 0.0285609774291515352\n",
      "Episode Reward: 0.0\n",
      "Step 234 (942) @ Episode 5/10000, loss: 0.0009371703490614891\n",
      "Episode Reward: 1.0\n",
      "Step 169 (1111) @ Episode 6/10000, loss: 0.0008591270307078958\n",
      "Episode Reward: 0.0\n",
      "Step 362 (1473) @ Episode 7/10000, loss: 0.00052905135089531546\n",
      "Episode Reward: 3.0\n",
      "Step 207 (1680) @ Episode 8/10000, loss: 0.02490859106183052986\n",
      "Episode Reward: 1.0\n",
      "Step 363 (2043) @ Episode 9/10000, loss: 0.02466689981520176144\n",
      "Episode Reward: 3.0\n",
      "Step 247 (2290) @ Episode 10/10000, loss: 0.00015570111281704158\n",
      "Episode Reward: 1.0\n",
      "Step 212 (2502) @ Episode 11/10000, loss: 1.6433805285487324e-05\n",
      "Episode Reward: 1.0\n",
      "Step 285 (2787) @ Episode 12/10000, loss: 0.00020097843662369996\n",
      "Episode Reward: 2.0\n",
      "Step 244 (3031) @ Episode 13/10000, loss: 0.05000002309679985136\n",
      "Episode Reward: 1.0\n",
      "Step 178 (3209) @ Episode 14/10000, loss: 0.02430043928325176242\n",
      "Episode Reward: 0.0\n",
      "Step 287 (3496) @ Episode 15/10000, loss: 0.02404617145657539405\n",
      "Episode Reward: 2.0\n",
      "Step 175 (3671) @ Episode 16/10000, loss: 9.429878264199942e-052\n",
      "Episode Reward: 0.0\n",
      "Step 247 (3918) @ Episode 17/10000, loss: 6.531007238663733e-057\n",
      "Episode Reward: 2.0\n",
      "Step 210 (4128) @ Episode 18/10000, loss: 9.572146518621594e-056\n",
      "Episode Reward: 1.0\n",
      "Step 164 (4292) @ Episode 19/10000, loss: 0.02393179945647716596\n",
      "Episode Reward: 0.0\n",
      "Step 218 (4510) @ Episode 20/10000, loss: 0.02489926293492317217\n",
      "Episode Reward: 1.0\n",
      "Step 180 (4690) @ Episode 21/10000, loss: 0.00013897236203774812\n",
      "Episode Reward: 0.0\n",
      "Step 252 (4942) @ Episode 22/10000, loss: 6.14205637248233e-0598\n",
      "Episode Reward: 2.0\n",
      "Step 299 (5241) @ Episode 23/10000, loss: 0.02408184483647346536\n",
      "Episode Reward: 3.0\n",
      "Step 167 (5408) @ Episode 24/10000, loss: 0.02364424802362919863\n",
      "Episode Reward: 0.0\n",
      "Step 180 (5588) @ Episode 25/10000, loss: 0.02438440732657909454\n",
      "Episode Reward: 0.0\n",
      "Step 194 (5782) @ Episode 26/10000, loss: 0.00013870609109289944\n",
      "Episode Reward: 0.0\n",
      "Step 307 (6089) @ Episode 27/10000, loss: 0.00011588488996494561\n",
      "Episode Reward: 3.0\n",
      "Step 194 (6283) @ Episode 28/10000, loss: 0.00015938174328766763\n",
      "Episode Reward: 0.0\n",
      "Step 232 (6515) @ Episode 29/10000, loss: 0.02418732270598411645\n",
      "Episode Reward: 1.0\n",
      "Step 344 (6859) @ Episode 30/10000, loss: 3.616091635194607e-055\n",
      "Episode Reward: 3.0\n",
      "Step 269 (7128) @ Episode 31/10000, loss: 0.00010760258737718686\n",
      "Episode Reward: 2.0\n",
      "Step 389 (7517) @ Episode 32/10000, loss: 0.00017278897576034074\n",
      "Episode Reward: 3.0\n",
      "Step 342 (7859) @ Episode 33/10000, loss: 0.00020410543947946286\n",
      "Episode Reward: 3.0\n",
      "Step 191 (8050) @ Episode 34/10000, loss: 5.3536350606009364e-05\n",
      "Episode Reward: 0.0\n",
      "Step 175 (8225) @ Episode 35/10000, loss: 5.925561345065944e-058\n",
      "Episode Reward: 0.0\n",
      "Step 178 (8403) @ Episode 36/10000, loss: 3.899538569385186e-052\n",
      "Episode Reward: 0.0\n",
      "Step 297 (8700) @ Episode 37/10000, loss: 0.02411958947777748098\n",
      "Episode Reward: 2.0\n",
      "Step 369 (9069) @ Episode 38/10000, loss: 0.00027119051082991064\n",
      "Episode Reward: 4.0\n",
      "Step 177 (9246) @ Episode 39/10000, loss: 9.641400538384914e-056\n",
      "Episode Reward: 0.0\n",
      "Step 271 (9517) @ Episode 40/10000, loss: 0.00040667940629646186\n",
      "Episode Reward: 2.0\n",
      "Step 206 (9723) @ Episode 41/10000, loss: 0.00010889752593357116\n",
      "Episode Reward: 1.0\n",
      "Step 276 (9999) @ Episode 42/10000, loss: 0.02466470375657081605\n",
      "Copied model parameters to target network.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 414 (10137) @ Episode 42/10000, loss: 0.02443227358162403059\n",
      "Episode Reward: 4.0\n",
      "Step 474 (10611) @ Episode 43/10000, loss: 0.00012524919293355197\n",
      "Episode Reward: 5.0\n",
      "Step 213 (10824) @ Episode 44/10000, loss: 0.02424539998173713764\n",
      "Episode Reward: 1.0\n",
      "Step 175 (10999) @ Episode 45/10000, loss: 5.03250521433074e-0527\n",
      "Episode Reward: 0.0\n",
      "Step 164 (11163) @ Episode 46/10000, loss: 0.00013264376320876184\n",
      "Episode Reward: 0.0\n",
      "Step 169 (11332) @ Episode 47/10000, loss: 0.00019939285994041717\n",
      "Episode Reward: 0.0\n",
      "Step 179 (11511) @ Episode 48/10000, loss: 8.419596997555345e-055\n",
      "Episode Reward: 0.0\n",
      "Step 238 (11749) @ Episode 49/10000, loss: 0.00016322739247698337\n",
      "Episode Reward: 1.0\n",
      "Step 227 (11976) @ Episode 50/10000, loss: 0.00017790545825846493\n",
      "Episode Reward: 1.0\n",
      "Step 168 (12144) @ Episode 51/10000, loss: 0.00011684335913741961\n",
      "Episode Reward: 0.0\n",
      "Step 178 (12322) @ Episode 52/10000, loss: 0.02349364757537841814\n",
      "Episode Reward: 0.0\n",
      "Step 276 (12598) @ Episode 53/10000, loss: 0.00036750888102687895\n",
      "Episode Reward: 2.0\n",
      "Step 228 (12826) @ Episode 54/10000, loss: 0.02245342917740345567\n",
      "Episode Reward: 1.0\n",
      "Step 251 (13077) @ Episode 55/10000, loss: 0.00010111541632795706\n",
      "Episode Reward: 1.0\n",
      "Step 360 (13437) @ Episode 56/10000, loss: 0.02139280177652836667\n",
      "Episode Reward: 3.0\n",
      "Step 173 (13610) @ Episode 57/10000, loss: 0.02016446180641651056\n",
      "Episode Reward: 0.0\n",
      "Step 203 (13813) @ Episode 58/10000, loss: 0.00036636617733165621\n",
      "Episode Reward: 1.0\n",
      "Step 165 (13978) @ Episode 59/10000, loss: 0.02358930930495262265\n",
      "Episode Reward: 0.0\n",
      "Step 282 (14260) @ Episode 60/10000, loss: 0.00015090630040504038\n",
      "Episode Reward: 2.0\n",
      "Step 173 (14433) @ Episode 61/10000, loss: 0.00023473202600143854\n",
      "Episode Reward: 0.0\n",
      "Step 222 (14655) @ Episode 62/10000, loss: 0.00050000799819827087\n",
      "Episode Reward: 1.0\n",
      "Step 274 (14929) @ Episode 63/10000, loss: 0.00027262332150712612\n",
      "Episode Reward: 2.0\n",
      "Step 271 (15200) @ Episode 64/10000, loss: 0.02113756164908409697\n",
      "Episode Reward: 2.0\n",
      "Step 339 (15539) @ Episode 65/10000, loss: 0.04238910228013992768\n",
      "Episode Reward: 4.0\n",
      "Step 226 (15765) @ Episode 66/10000, loss: 0.00034476158907637885\n",
      "Episode Reward: 1.0\n",
      "Step 174 (15939) @ Episode 67/10000, loss: 0.00027320446679368615\n",
      "Episode Reward: 0.0\n",
      "Step 169 (16108) @ Episode 68/10000, loss: 0.00047952588647603997\n",
      "Episode Reward: 0.0\n",
      "Step 174 (16282) @ Episode 69/10000, loss: 0.01807498931884765627\n",
      "Episode Reward: 0.0\n",
      "Step 233 (16515) @ Episode 70/10000, loss: 0.02240447141230106437\n",
      "Episode Reward: 1.0\n",
      "Step 230 (16745) @ Episode 71/10000, loss: 0.02025192230939865067\n",
      "Episode Reward: 1.0\n",
      "Step 269 (17014) @ Episode 72/10000, loss: 0.00121596106328070163\n",
      "Episode Reward: 2.0\n",
      "Step 235 (17249) @ Episode 73/10000, loss: 0.00042892448254860946\n",
      "Episode Reward: 2.0\n",
      "Step 371 (17620) @ Episode 74/10000, loss: 0.00108126329723745584\n",
      "Episode Reward: 3.0\n",
      "Step 306 (17926) @ Episode 75/10000, loss: 0.00036840193206444385\n",
      "Episode Reward: 2.0\n",
      "Step 243 (18169) @ Episode 76/10000, loss: 0.00029886048287153244\n",
      "Episode Reward: 1.0\n",
      "Step 399 (18568) @ Episode 77/10000, loss: 0.00053097459021955738\n",
      "Episode Reward: 4.0\n",
      "Step 233 (18801) @ Episode 78/10000, loss: 0.00043179205385968096\n",
      "Episode Reward: 1.0\n",
      "Step 210 (19011) @ Episode 79/10000, loss: 0.00028301341808401053\n",
      "Episode Reward: 1.0\n",
      "Step 211 (19222) @ Episode 80/10000, loss: 0.00107476790435612266\n",
      "Episode Reward: 1.0\n",
      "Step 292 (19514) @ Episode 81/10000, loss: 0.00873935874551534734\n",
      "Episode Reward: 2.0\n",
      "Step 211 (19725) @ Episode 82/10000, loss: 0.01259734202176332584\n",
      "Episode Reward: 1.0\n",
      "Step 227 (19952) @ Episode 83/10000, loss: 0.00016012637934181846\n",
      "Episode Reward: 1.0\n",
      "Step 47 (19999) @ Episode 84/10000, loss: 0.00029599334811791787\n",
      "Copied model parameters to target network.\n",
      "Step 180 (20132) @ Episode 84/10000, loss: 0.05439776927232742225\n",
      "Episode Reward: 0.0\n",
      "Step 165 (20297) @ Episode 85/10000, loss: 0.02363103069365024696\n",
      "Episode Reward: 0.0\n",
      "Step 231 (20528) @ Episode 86/10000, loss: 0.01697250455617904765\n",
      "Episode Reward: 1.0\n",
      "Step 166 (20694) @ Episode 87/10000, loss: 0.00341911544091999534\n",
      "Episode Reward: 0.0\n",
      "Step 333 (21027) @ Episode 88/10000, loss: 0.00292796781286597255\n",
      "Episode Reward: 3.0\n",
      "Step 171 (21198) @ Episode 89/10000, loss: 0.00182132679037749776\n",
      "Episode Reward: 0.0\n",
      "Step 174 (21372) @ Episode 90/10000, loss: 0.00399965886026620944\n",
      "Episode Reward: 0.0\n",
      "Step 340 (21712) @ Episode 91/10000, loss: 0.00654358789324760472\n",
      "Episode Reward: 3.0\n",
      "Step 188 (21900) @ Episode 92/10000, loss: 0.00016556098125874996\n",
      "Episode Reward: 0.0\n",
      "Step 176 (22076) @ Episode 93/10000, loss: 0.00906673260033130693\n",
      "Episode Reward: 0.0\n",
      "Step 280 (22356) @ Episode 94/10000, loss: 0.00033194711431860924\n",
      "Episode Reward: 2.0\n",
      "Step 228 (22584) @ Episode 95/10000, loss: 0.00049103057244792587\n",
      "Episode Reward: 1.0\n",
      "Step 165 (22749) @ Episode 96/10000, loss: 0.00040543786599300884\n",
      "Episode Reward: 0.0\n",
      "Step 214 (22963) @ Episode 97/10000, loss: 0.00044465428800322115\n",
      "Episode Reward: 1.0\n",
      "Step 255 (23218) @ Episode 98/10000, loss: 0.00124922511167824273\n",
      "Episode Reward: 1.0\n",
      "Step 242 (23460) @ Episode 99/10000, loss: 0.00023346483067143708\n",
      "Episode Reward: 1.0\n",
      "Step 162 (23622) @ Episode 100/10000, loss: 0.00055227469420060525\n",
      "Episode Reward: 0.0\n",
      "Step 211 (23833) @ Episode 101/10000, loss: 0.00360255618579685797\n",
      "Episode Reward: 1.0\n",
      "Step 377 (24210) @ Episode 102/10000, loss: 0.00042589771328493953\n",
      "Episode Reward: 3.0\n",
      "Step 180 (24390) @ Episode 103/10000, loss: 0.00065916602034121754\n",
      "Episode Reward: 0.0\n",
      "Step 165 (24555) @ Episode 104/10000, loss: 0.00135095324367284777\n",
      "Episode Reward: 0.0\n",
      "Step 167 (24722) @ Episode 105/10000, loss: 0.00018915136752184483\n",
      "Episode Reward: 0.0\n",
      "Step 174 (24896) @ Episode 106/10000, loss: 0.00023520947434008121\n",
      "Episode Reward: 0.0\n",
      "Step 169 (25065) @ Episode 107/10000, loss: 0.00013481549103744328\n",
      "Episode Reward: 0.0\n",
      "Step 257 (25322) @ Episode 108/10000, loss: 0.00395943690091371533\n",
      "Episode Reward: 2.0\n",
      "Step 168 (25490) @ Episode 109/10000, loss: 0.00337875518016517169\n",
      "Episode Reward: 0.0\n",
      "Step 181 (25671) @ Episode 110/10000, loss: 0.00111235608346760279\n",
      "Episode Reward: 0.0\n",
      "Step 166 (25837) @ Episode 111/10000, loss: 0.00018607445235829875\n",
      "Episode Reward: 0.0\n",
      "Step 239 (26076) @ Episode 112/10000, loss: 0.00019391413661651313\n",
      "Episode Reward: 1.0\n",
      "Step 347 (26423) @ Episode 113/10000, loss: 0.00357469031587243177\n",
      "Episode Reward: 3.0\n",
      "Step 175 (26598) @ Episode 114/10000, loss: 0.00193590740673244555\n",
      "Episode Reward: 0.0\n",
      "Step 196 (26794) @ Episode 115/10000, loss: 0.00017970222688745707\n",
      "Episode Reward: 0.0\n",
      "Step 317 (27111) @ Episode 116/10000, loss: 0.00033804125268943615\n",
      "Episode Reward: 3.0\n",
      "Step 189 (27300) @ Episode 117/10000, loss: 0.00012266104749869555\n",
      "Episode Reward: 0.0\n",
      "Step 182 (27482) @ Episode 118/10000, loss: 0.00136599480174481875\n",
      "Episode Reward: 0.0\n",
      "Step 168 (27650) @ Episode 119/10000, loss: 0.00552493985742330555\n",
      "Episode Reward: 0.0\n",
      "Step 307 (27957) @ Episode 120/10000, loss: 0.00103884085547178983\n",
      "Episode Reward: 2.0\n",
      "Step 168 (28125) @ Episode 121/10000, loss: 8.793817687546834e-055\n",
      "Episode Reward: 0.0\n",
      "Step 360 (28485) @ Episode 122/10000, loss: 0.00024814001517370343\n",
      "Episode Reward: 3.0\n",
      "Step 193 (28678) @ Episode 123/10000, loss: 0.00019796362903434783\n",
      "Episode Reward: 0.0\n",
      "Step 223 (28901) @ Episode 124/10000, loss: 0.00036917626857757576\n",
      "Episode Reward: 1.0\n",
      "Step 265 (29166) @ Episode 125/10000, loss: 0.00978877209126949356\n",
      "Episode Reward: 2.0\n",
      "Step 364 (29530) @ Episode 126/10000, loss: 0.00020530112669803202\n",
      "Episode Reward: 4.0\n",
      "Step 186 (29716) @ Episode 127/10000, loss: 0.00010319385910406709\n",
      "Episode Reward: 0.0\n",
      "Step 283 (29999) @ Episode 128/10000, loss: 0.00015156390145421028\n",
      "Copied model parameters to target network.\n",
      "Step 290 (30006) @ Episode 128/10000, loss: 0.00300023891031742154\n",
      "Episode Reward: 3.0\n",
      "Step 214 (30220) @ Episode 129/10000, loss: 0.00063697138102725155\n",
      "Episode Reward: 1.0\n",
      "Step 223 (30443) @ Episode 130/10000, loss: 0.00179999391548335556\n",
      "Episode Reward: 1.0\n",
      "Step 237 (30680) @ Episode 131/10000, loss: 0.00048394020996056497\n",
      "Episode Reward: 1.0\n",
      "Step 236 (30916) @ Episode 132/10000, loss: 0.00126210902817547325\n",
      "Episode Reward: 1.0\n",
      "Step 171 (31087) @ Episode 133/10000, loss: 0.00032928615109995017\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 161 (31248) @ Episode 134/10000, loss: 0.00458779651671648734\n",
      "Episode Reward: 0.0\n",
      "Step 238 (31486) @ Episode 135/10000, loss: 5.9366448112996295e-05\n",
      "Episode Reward: 1.0\n",
      "Step 177 (31663) @ Episode 136/10000, loss: 0.00072350475238636143\n",
      "Episode Reward: 0.0\n",
      "Step 167 (31830) @ Episode 137/10000, loss: 0.00029712094692513347\n",
      "Episode Reward: 0.0\n",
      "Step 307 (32137) @ Episode 138/10000, loss: 0.00049456133274361495\n",
      "Episode Reward: 2.0\n",
      "Step 270 (32407) @ Episode 139/10000, loss: 0.00446560513228178285\n",
      "Episode Reward: 1.0\n",
      "Step 174 (32581) @ Episode 140/10000, loss: 0.00095371232600882655\n",
      "Episode Reward: 0.0\n",
      "Step 181 (32762) @ Episode 141/10000, loss: 0.00089173857122659687\n",
      "Episode Reward: 0.0\n",
      "Step 297 (33059) @ Episode 142/10000, loss: 0.00031330864294432104\n",
      "Episode Reward: 2.0\n",
      "Step 228 (33287) @ Episode 143/10000, loss: 0.00020746844529639934\n",
      "Episode Reward: 1.0\n",
      "Step 178 (33465) @ Episode 144/10000, loss: 0.00139623903669416937\n",
      "Episode Reward: 0.0\n",
      "Step 171 (33636) @ Episode 145/10000, loss: 0.00020115441293455663\n",
      "Episode Reward: 0.0\n",
      "Step 217 (33853) @ Episode 146/10000, loss: 0.00013338618737179786\n",
      "Episode Reward: 1.0\n",
      "Step 341 (34194) @ Episode 147/10000, loss: 0.00017393025336787105\n",
      "Episode Reward: 3.0\n",
      "Step 308 (34502) @ Episode 148/10000, loss: 0.00014443411782849582\n",
      "Episode Reward: 3.0\n",
      "Step 177 (34679) @ Episode 149/10000, loss: 0.00026919576339423656\n",
      "Episode Reward: 0.0\n",
      "Step 287 (34966) @ Episode 150/10000, loss: 0.00033670468837954104\n",
      "Episode Reward: 2.0\n",
      "Step 230 (35196) @ Episode 151/10000, loss: 0.00012422315194271505\n",
      "Episode Reward: 1.0\n",
      "Step 173 (35369) @ Episode 152/10000, loss: 0.00416348222643137056\n",
      "Episode Reward: 0.0\n",
      "Step 280 (35649) @ Episode 153/10000, loss: 0.00018068426288664345\n",
      "Episode Reward: 2.0\n",
      "Step 173 (35822) @ Episode 154/10000, loss: 0.00025155031471513213\n",
      "Episode Reward: 0.0\n",
      "Step 172 (35994) @ Episode 155/10000, loss: 0.00010538376227486879\n",
      "Episode Reward: 0.0\n",
      "Step 218 (36212) @ Episode 156/10000, loss: 5.761150532634929e-056\n",
      "Episode Reward: 1.0\n",
      "Step 329 (36541) @ Episode 157/10000, loss: 0.00063449511071667088\n",
      "Episode Reward: 3.0\n",
      "Step 242 (36783) @ Episode 158/10000, loss: 9.463675087317824e-055\n",
      "Episode Reward: 1.0\n",
      "Step 278 (37061) @ Episode 159/10000, loss: 0.00138932676054537397\n",
      "Episode Reward: 2.0\n",
      "Step 170 (37231) @ Episode 160/10000, loss: 0.00054718315368518238\n",
      "Episode Reward: 0.0\n",
      "Step 239 (37470) @ Episode 161/10000, loss: 0.00022934380103833973\n",
      "Episode Reward: 1.0\n",
      "Step 217 (37687) @ Episode 162/10000, loss: 0.00014087872114032507\n",
      "Episode Reward: 1.0\n",
      "Step 164 (37851) @ Episode 163/10000, loss: 8.024866110645235e-055\n",
      "Episode Reward: 0.0\n",
      "Step 169 (38020) @ Episode 164/10000, loss: 0.00030012681963853542\n",
      "Episode Reward: 0.0\n",
      "Step 228 (38248) @ Episode 165/10000, loss: 0.00031490912078879774\n",
      "Episode Reward: 1.0\n",
      "Step 235 (38483) @ Episode 166/10000, loss: 5.287888416205533e-055\n",
      "Episode Reward: 1.0\n",
      "Step 185 (38668) @ Episode 167/10000, loss: 0.00037016894202679396\n",
      "Episode Reward: 0.0\n",
      "Step 473 (39141) @ Episode 168/10000, loss: 0.00029133251518942416\n",
      "Episode Reward: 5.0\n",
      "Step 216 (39357) @ Episode 169/10000, loss: 0.00018180675397161394\n",
      "Episode Reward: 1.0\n",
      "Step 209 (39566) @ Episode 170/10000, loss: 0.00026555918157100688\n",
      "Episode Reward: 1.0\n",
      "Step 280 (39846) @ Episode 171/10000, loss: 0.00191317056305706503\n",
      "Episode Reward: 2.0\n",
      "Step 153 (39999) @ Episode 172/10000, loss: 0.00370999006554484376\n",
      "Copied model parameters to target network.\n",
      "Step 302 (40148) @ Episode 172/10000, loss: 0.00083696719957515698\n",
      "Episode Reward: 3.0\n",
      "Step 209 (40357) @ Episode 173/10000, loss: 0.00050284509779885413\n",
      "Episode Reward: 1.0\n",
      "Step 209 (40566) @ Episode 174/10000, loss: 0.00292857224121689875\n",
      "Episode Reward: 1.0\n",
      "Step 212 (40778) @ Episode 175/10000, loss: 0.00201598810963332657\n",
      "Episode Reward: 1.0\n",
      "Step 238 (41016) @ Episode 176/10000, loss: 0.00284602632746100434\n",
      "Episode Reward: 1.0\n",
      "Step 290 (41306) @ Episode 177/10000, loss: 0.00021663024381268775\n",
      "Episode Reward: 2.0\n",
      "Step 244 (41550) @ Episode 178/10000, loss: 0.00266299396753311166\n",
      "Episode Reward: 2.0\n",
      "Step 326 (41876) @ Episode 179/10000, loss: 0.00079953001113608486\n",
      "Episode Reward: 3.0\n",
      "Step 388 (42264) @ Episode 180/10000, loss: 0.00184017675928771557\n",
      "Episode Reward: 4.0\n",
      "Step 174 (42438) @ Episode 181/10000, loss: 0.00239175977185368544\n",
      "Episode Reward: 0.0\n",
      "Step 307 (42745) @ Episode 182/10000, loss: 0.00365436077117919922\n",
      "Episode Reward: 2.0\n",
      "Step 278 (43023) @ Episode 183/10000, loss: 0.00059607654111459854\n",
      "Episode Reward: 2.0\n",
      "Step 181 (43204) @ Episode 184/10000, loss: 0.00028042815392836932\n",
      "Episode Reward: 0.0\n",
      "Step 173 (43377) @ Episode 185/10000, loss: 0.00015772509505040944\n",
      "Episode Reward: 0.0\n",
      "Step 180 (43557) @ Episode 186/10000, loss: 0.00198521418496966364\n",
      "Episode Reward: 0.0\n",
      "Step 177 (43734) @ Episode 187/10000, loss: 0.00145623157732188767\n",
      "Episode Reward: 0.0\n",
      "Step 169 (43903) @ Episode 188/10000, loss: 0.00021805625874549157\n",
      "Episode Reward: 0.0\n",
      "Step 187 (44090) @ Episode 189/10000, loss: 0.00052023457828909164\n",
      "Episode Reward: 0.0\n",
      "Step 272 (44362) @ Episode 190/10000, loss: 0.00014588246995117515\n",
      "Episode Reward: 2.0\n",
      "Step 174 (44536) @ Episode 191/10000, loss: 0.00023894081823527813\n",
      "Episode Reward: 0.0\n",
      "Step 184 (44720) @ Episode 192/10000, loss: 0.00020717697043437511\n",
      "Episode Reward: 0.0\n",
      "Step 182 (44902) @ Episode 193/10000, loss: 0.00395315513014793496\n",
      "Episode Reward: 0.0\n",
      "Step 171 (45073) @ Episode 194/10000, loss: 0.00011076677037635818\n",
      "Episode Reward: 0.0\n",
      "Step 197 (45270) @ Episode 195/10000, loss: 0.00018295155314262956\n",
      "Episode Reward: 0.0\n",
      "Step 181 (45451) @ Episode 196/10000, loss: 0.00035317771835252644\n",
      "Episode Reward: 0.0\n",
      "Step 172 (45623) @ Episode 197/10000, loss: 9.525640780339018e-056\n",
      "Episode Reward: 0.0\n",
      "Step 172 (45795) @ Episode 198/10000, loss: 0.00036079503479413694\n",
      "Episode Reward: 0.0\n",
      "Step 225 (46020) @ Episode 199/10000, loss: 0.00192036293447017674\n",
      "Episode Reward: 1.0\n",
      "Step 284 (46304) @ Episode 200/10000, loss: 0.00553895067423582152\n",
      "Episode Reward: 2.0\n",
      "Step 263 (46567) @ Episode 201/10000, loss: 0.00022234483913052827\n",
      "Episode Reward: 1.0\n",
      "Step 270 (46837) @ Episode 202/10000, loss: 0.00031751143978908663\n",
      "Episode Reward: 2.0\n",
      "Step 302 (47139) @ Episode 203/10000, loss: 0.00020432306337170303\n",
      "Episode Reward: 2.0\n",
      "Step 171 (47310) @ Episode 204/10000, loss: 0.00020156407845206567\n",
      "Episode Reward: 0.0\n",
      "Step 265 (47575) @ Episode 205/10000, loss: 0.00028426235076040037\n",
      "Episode Reward: 2.0\n",
      "Step 179 (47754) @ Episode 206/10000, loss: 8.676423749420792e-055\n",
      "Episode Reward: 0.0\n",
      "Step 255 (48009) @ Episode 207/10000, loss: 0.00015918744611553848\n",
      "Episode Reward: 1.0\n",
      "Step 327 (48336) @ Episode 208/10000, loss: 0.00019862255430780355\n",
      "Episode Reward: 3.0\n",
      "Step 206 (48542) @ Episode 209/10000, loss: 0.00010575328633422032\n",
      "Episode Reward: 1.0\n",
      "Step 181 (48723) @ Episode 210/10000, loss: 0.00024497957201674584\n",
      "Episode Reward: 0.0\n",
      "Step 455 (49178) @ Episode 211/10000, loss: 0.00021462100266944617\n",
      "Episode Reward: 5.0\n",
      "Step 301 (49479) @ Episode 212/10000, loss: 0.00038809902616776526\n",
      "Episode Reward: 3.0\n",
      "Step 303 (49782) @ Episode 213/10000, loss: 0.00105982681270688774\n",
      "Episode Reward: 2.0\n",
      "Step 217 (49999) @ Episode 214/10000, loss: 0.00024298422795254737\n",
      "Copied model parameters to target network.\n",
      "Step 416 (50198) @ Episode 214/10000, loss: 0.00037048960803076625\n",
      "Episode Reward: 4.0\n",
      "Step 175 (50373) @ Episode 215/10000, loss: 0.00019266242452431477\n",
      "Episode Reward: 0.0\n",
      "Step 237 (50610) @ Episode 216/10000, loss: 0.00225028512068092824\n",
      "Episode Reward: 1.0\n",
      "Step 329 (50939) @ Episode 217/10000, loss: 0.00025158884818665683\n",
      "Episode Reward: 3.0\n",
      "Step 172 (51111) @ Episode 218/10000, loss: 0.00098003051243722444\n",
      "Episode Reward: 0.0\n",
      "Step 229 (51340) @ Episode 219/10000, loss: 0.00059495761524885895\n",
      "Episode Reward: 1.0\n",
      "Step 243 (51583) @ Episode 220/10000, loss: 0.00100611033849418167\n",
      "Episode Reward: 2.0\n",
      "Step 163 (51746) @ Episode 221/10000, loss: 0.00064342853147536526\n",
      "Episode Reward: 0.0\n",
      "Step 177 (51923) @ Episode 222/10000, loss: 0.00379879027605056767\n",
      "Episode Reward: 0.0\n",
      "Step 162 (52085) @ Episode 223/10000, loss: 0.00305913644842803488\n",
      "Episode Reward: 0.0\n",
      "Step 244 (52329) @ Episode 224/10000, loss: 0.00127301434986293328\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 229 (52558) @ Episode 225/10000, loss: 0.00034890123060904443\n",
      "Episode Reward: 1.0\n",
      "Step 309 (52867) @ Episode 226/10000, loss: 0.00385301234200596814\n",
      "Episode Reward: 3.0\n",
      "Step 163 (53030) @ Episode 227/10000, loss: 0.00016237997624557465\n",
      "Episode Reward: 0.0\n",
      "Step 176 (53206) @ Episode 228/10000, loss: 0.00064334610942751178\n",
      "Episode Reward: 0.0\n",
      "Step 299 (53505) @ Episode 229/10000, loss: 0.00056380347814410923\n",
      "Episode Reward: 2.0\n",
      "Step 266 (53771) @ Episode 230/10000, loss: 0.00012937180872540924\n",
      "Episode Reward: 2.0\n",
      "Step 283 (54054) @ Episode 231/10000, loss: 0.00028224100242368877\n",
      "Episode Reward: 3.0\n",
      "Step 213 (54267) @ Episode 232/10000, loss: 0.00114334037061780777\n",
      "Episode Reward: 1.0\n",
      "Step 242 (54509) @ Episode 233/10000, loss: 0.00057721650227904322\n",
      "Episode Reward: 1.0\n",
      "Step 165 (54674) @ Episode 234/10000, loss: 0.00056604325072839864\n",
      "Episode Reward: 0.0\n",
      "Step 167 (54841) @ Episode 235/10000, loss: 0.00032388599356636405\n",
      "Episode Reward: 0.0\n",
      "Step 180 (55021) @ Episode 236/10000, loss: 0.00039650220423936844\n",
      "Episode Reward: 0.0\n",
      "Step 189 (55210) @ Episode 237/10000, loss: 7.052946602925658e-056\n",
      "Episode Reward: 0.0\n",
      "Step 299 (55509) @ Episode 238/10000, loss: 0.00025985838146880272\n",
      "Episode Reward: 2.0\n",
      "Step 287 (55796) @ Episode 239/10000, loss: 0.00012998993042856455\n",
      "Episode Reward: 2.0\n",
      "Step 386 (56182) @ Episode 240/10000, loss: 0.00016615615459159017\n",
      "Episode Reward: 4.0\n",
      "Step 263 (56445) @ Episode 241/10000, loss: 6.849130295449868e-057\n",
      "Episode Reward: 2.0\n",
      "Step 243 (56688) @ Episode 242/10000, loss: 0.00044730273657478398\n",
      "Episode Reward: 1.0\n",
      "Step 209 (56897) @ Episode 243/10000, loss: 0.00027331089950166647\n",
      "Episode Reward: 1.0\n",
      "Step 268 (57165) @ Episode 244/10000, loss: 0.00040004425682127476\n",
      "Episode Reward: 2.0\n",
      "Step 237 (57402) @ Episode 245/10000, loss: 0.00033345184056088333\n",
      "Episode Reward: 1.0\n",
      "Step 280 (57682) @ Episode 246/10000, loss: 0.00050152360927313576\n",
      "Episode Reward: 2.0\n",
      "Step 278 (57960) @ Episode 247/10000, loss: 0.00014506987645290792\n",
      "Episode Reward: 2.0\n",
      "Step 170 (58130) @ Episode 248/10000, loss: 0.00011656538117676973\n",
      "Episode Reward: 0.0\n",
      "Step 180 (58310) @ Episode 249/10000, loss: 0.00035154572105966515\n",
      "Episode Reward: 0.0\n",
      "Step 208 (58518) @ Episode 250/10000, loss: 0.00016790008521638813\n",
      "Episode Reward: 1.0\n",
      "Step 308 (58826) @ Episode 251/10000, loss: 0.00030597587465308607\n",
      "Episode Reward: 2.0\n",
      "Step 296 (59122) @ Episode 252/10000, loss: 0.00063019094523042446\n",
      "Episode Reward: 2.0\n",
      "Step 174 (59296) @ Episode 253/10000, loss: 0.00041184382280334836\n",
      "Episode Reward: 0.0\n",
      "Step 593 (59889) @ Episode 254/10000, loss: 0.00026756594888865957\n",
      "Episode Reward: 8.0\n",
      "Step 110 (59999) @ Episode 255/10000, loss: 0.00067994889104738835\n",
      "Copied model parameters to target network.\n",
      "Step 231 (60120) @ Episode 255/10000, loss: 0.00203947280533611774\n",
      "Episode Reward: 1.0\n",
      "Step 221 (60341) @ Episode 256/10000, loss: 0.00111036130692809823\n",
      "Episode Reward: 1.0\n",
      "Step 183 (60524) @ Episode 257/10000, loss: 0.00023605013848282397\n",
      "Episode Reward: 0.0\n",
      "Step 198 (60722) @ Episode 258/10000, loss: 0.00025271048070862896\n",
      "Episode Reward: 1.0\n",
      "Step 363 (61085) @ Episode 259/10000, loss: 0.00174929073546081786\n",
      "Episode Reward: 3.0\n",
      "Step 180 (61265) @ Episode 260/10000, loss: 0.00033577214344404644\n",
      "Episode Reward: 0.0\n",
      "Step 202 (61467) @ Episode 261/10000, loss: 0.00075705646304413683\n",
      "Episode Reward: 1.0\n",
      "Step 216 (61683) @ Episode 262/10000, loss: 0.00060649251099675896\n",
      "Episode Reward: 1.0\n",
      "Step 269 (61952) @ Episode 263/10000, loss: 0.00128458149265497925\n",
      "Episode Reward: 2.0\n",
      "Step 202 (62154) @ Episode 264/10000, loss: 0.00029140937840566043\n",
      "Episode Reward: 1.0\n",
      "Step 372 (62526) @ Episode 265/10000, loss: 0.00113908876664936545\n",
      "Episode Reward: 3.0\n",
      "Step 224 (62750) @ Episode 266/10000, loss: 0.00023136226809583604\n",
      "Episode Reward: 1.0\n",
      "Step 285 (63035) @ Episode 267/10000, loss: 0.00098381389398127873\n",
      "Episode Reward: 2.0\n",
      "Step 202 (63237) @ Episode 268/10000, loss: 0.00066597521072253582\n",
      "Episode Reward: 1.0\n",
      "Step 220 (63457) @ Episode 269/10000, loss: 0.00035332576953805983\n",
      "Episode Reward: 1.0\n",
      "Step 208 (63665) @ Episode 270/10000, loss: 0.00053182657575234775\n",
      "Episode Reward: 0.0\n",
      "Step 220 (63885) @ Episode 271/10000, loss: 0.00036083813756704334\n",
      "Episode Reward: 1.0\n",
      "Step 176 (64061) @ Episode 272/10000, loss: 0.00198492803610861348\n",
      "Episode Reward: 0.0\n",
      "Step 282 (64343) @ Episode 273/10000, loss: 0.00152465107385069138\n",
      "Episode Reward: 2.0\n",
      "Step 169 (64512) @ Episode 274/10000, loss: 0.00024708974524401134\n",
      "Episode Reward: 0.0\n",
      "Step 392 (64904) @ Episode 275/10000, loss: 0.00034412281820550566\n",
      "Episode Reward: 3.0\n",
      "Step 246 (65150) @ Episode 276/10000, loss: 0.00011654601257760078\n",
      "Episode Reward: 1.0\n",
      "Step 173 (65323) @ Episode 277/10000, loss: 0.00189526285976171511\n",
      "Episode Reward: 0.0\n",
      "Step 269 (65592) @ Episode 278/10000, loss: 0.00014759026817046106\n",
      "Episode Reward: 2.0\n",
      "Step 170 (65762) @ Episode 279/10000, loss: 5.016498107579537e-053\n",
      "Episode Reward: 0.0\n",
      "Step 242 (66004) @ Episode 280/10000, loss: 7.26284779375419e-0504\n",
      "Episode Reward: 1.0\n",
      "Step 327 (66331) @ Episode 281/10000, loss: 0.00422550598159432414\n",
      "Episode Reward: 3.0\n",
      "Step 335 (66666) @ Episode 282/10000, loss: 0.00029222975717857485\n",
      "Episode Reward: 3.0\n",
      "Step 171 (66837) @ Episode 283/10000, loss: 0.00035683283931575716\n",
      "Episode Reward: 0.0\n",
      "Step 206 (67043) @ Episode 284/10000, loss: 0.00056251412024721554\n",
      "Episode Reward: 1.0\n",
      "Step 179 (67222) @ Episode 285/10000, loss: 9.115531429415569e-057\n",
      "Episode Reward: 0.0\n",
      "Step 189 (67411) @ Episode 286/10000, loss: 0.00038119737291708598\n",
      "Episode Reward: 0.0\n",
      "Step 177 (67588) @ Episode 287/10000, loss: 0.00010997955541824922\n",
      "Episode Reward: 0.0\n",
      "Step 186 (67774) @ Episode 288/10000, loss: 0.00023199702263809744\n",
      "Episode Reward: 0.0\n",
      "Step 283 (68057) @ Episode 289/10000, loss: 0.00041867877007462084\n",
      "Episode Reward: 2.0\n",
      "Step 281 (68338) @ Episode 290/10000, loss: 7.967984856804833e-054\n",
      "Episode Reward: 3.0\n",
      "Step 231 (68569) @ Episode 291/10000, loss: 0.00016487421817146242\n",
      "Episode Reward: 1.0\n",
      "Step 231 (68800) @ Episode 292/10000, loss: 0.00032274928526021547\n",
      "Episode Reward: 1.0\n",
      "Step 171 (68971) @ Episode 293/10000, loss: 5.0034439482260495e-05\n",
      "Episode Reward: 0.0\n",
      "Step 182 (69153) @ Episode 294/10000, loss: 0.00011961290147155523\n",
      "Episode Reward: 0.0\n",
      "Step 182 (69335) @ Episode 295/10000, loss: 0.00011194143735338002\n",
      "Episode Reward: 0.0\n",
      "Step 179 (69514) @ Episode 296/10000, loss: 9.08209549379535e-0546\n",
      "Episode Reward: 0.0\n",
      "Step 182 (69696) @ Episode 297/10000, loss: 0.00024057486734818667\n",
      "Episode Reward: 0.0\n",
      "Step 186 (69882) @ Episode 298/10000, loss: 0.00037300775875337425\n",
      "Episode Reward: 0.0\n",
      "Step 117 (69999) @ Episode 299/10000, loss: 8.841080125421286e-057\n",
      "Copied model parameters to target network.\n",
      "Step 179 (70061) @ Episode 299/10000, loss: 0.00685545895248651575\n",
      "Episode Reward: 0.0\n",
      "Step 339 (70400) @ Episode 300/10000, loss: 0.00487953377887606664\n",
      "Episode Reward: 3.0\n",
      "Step 468 (70868) @ Episode 301/10000, loss: 0.00060271425172686586\n",
      "Episode Reward: 5.0\n",
      "Step 527 (71395) @ Episode 302/10000, loss: 0.00362486252561211652\n",
      "Episode Reward: 6.0\n",
      "Step 368 (71763) @ Episode 303/10000, loss: 0.00052542047342285515\n",
      "Episode Reward: 3.0\n",
      "Step 406 (72169) @ Episode 304/10000, loss: 0.00105872424319386483\n",
      "Episode Reward: 4.0\n",
      "Step 382 (72551) @ Episode 305/10000, loss: 0.00037521068588830534\n",
      "Episode Reward: 4.0\n",
      "Step 312 (72863) @ Episode 306/10000, loss: 0.00229431176558136943\n",
      "Episode Reward: 3.0\n",
      "Step 248 (73111) @ Episode 307/10000, loss: 0.00036456191446632147\n",
      "Episode Reward: 2.0\n",
      "Step 219 (73330) @ Episode 308/10000, loss: 0.00014545313024427742\n",
      "Episode Reward: 1.0\n",
      "Step 205 (73535) @ Episode 309/10000, loss: 0.00074115471215918664\n",
      "Episode Reward: 1.0\n",
      "Step 301 (73836) @ Episode 310/10000, loss: 0.00058362062554806476\n",
      "Episode Reward: 2.0\n",
      "Step 192 (74028) @ Episode 311/10000, loss: 0.00063475169008597734\n",
      "Episode Reward: 0.0\n",
      "Step 304 (74332) @ Episode 312/10000, loss: 0.00016237406816799194\n",
      "Episode Reward: 2.0\n",
      "Step 328 (74660) @ Episode 313/10000, loss: 0.00111561012454330923\n",
      "Episode Reward: 3.0\n",
      "Step 274 (74934) @ Episode 314/10000, loss: 0.00047144573181867614\n",
      "Episode Reward: 2.0\n",
      "Step 231 (75165) @ Episode 315/10000, loss: 0.00110798957757651843\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 218 (75383) @ Episode 316/10000, loss: 0.00256956438533961773\n",
      "Episode Reward: 1.0\n",
      "Step 220 (75603) @ Episode 317/10000, loss: 0.00013601969112642113\n",
      "Episode Reward: 1.0\n",
      "Step 231 (75834) @ Episode 318/10000, loss: 0.00010983932588715106\n",
      "Episode Reward: 1.0\n",
      "Step 400 (76234) @ Episode 319/10000, loss: 0.00052384939044713974\n",
      "Episode Reward: 4.0\n",
      "Step 236 (76470) @ Episode 320/10000, loss: 0.00025214796187356114\n",
      "Episode Reward: 1.0\n",
      "Step 244 (76714) @ Episode 321/10000, loss: 0.00078502652468159872\n",
      "Episode Reward: 1.0\n",
      "Step 229 (76943) @ Episode 322/10000, loss: 0.00026752791018225258\n",
      "Episode Reward: 1.0\n",
      "Step 212 (77155) @ Episode 323/10000, loss: 8.295470615848899e-054\n",
      "Episode Reward: 1.0\n",
      "Step 379 (77534) @ Episode 324/10000, loss: 0.00052709085866808892\n",
      "Episode Reward: 4.0\n",
      "Step 167 (77701) @ Episode 325/10000, loss: 0.00036753405584022403\n",
      "Episode Reward: 0.0\n",
      "Step 320 (78021) @ Episode 326/10000, loss: 0.00041081695235334337\n",
      "Episode Reward: 3.0\n",
      "Step 171 (78192) @ Episode 327/10000, loss: 0.00115905515849590303\n",
      "Episode Reward: 0.0\n",
      "Step 273 (78465) @ Episode 328/10000, loss: 0.00031587461126036946\n",
      "Episode Reward: 2.0\n",
      "Step 216 (78681) @ Episode 329/10000, loss: 0.00019385857740417123\n",
      "Episode Reward: 1.0\n",
      "Step 293 (78974) @ Episode 330/10000, loss: 0.00092873780522495517\n",
      "Episode Reward: 2.0\n",
      "Step 226 (79200) @ Episode 331/10000, loss: 0.00160280521959066417\n",
      "Episode Reward: 1.0\n",
      "Step 179 (79379) @ Episode 332/10000, loss: 0.00117972330190241344\n",
      "Episode Reward: 0.0\n",
      "Step 382 (79761) @ Episode 333/10000, loss: 0.00038353694253601134\n",
      "Episode Reward: 3.0\n",
      "Step 182 (79943) @ Episode 334/10000, loss: 0.00803376547992229584\n",
      "Episode Reward: 0.0\n",
      "Step 56 (79999) @ Episode 335/10000, loss: 0.00030369815067388127\n",
      "Copied model parameters to target network.\n",
      "Step 269 (80212) @ Episode 335/10000, loss: 0.00083043379709124575\n",
      "Episode Reward: 2.0\n",
      "Step 293 (80505) @ Episode 336/10000, loss: 0.00161428167484700686\n",
      "Episode Reward: 2.0\n",
      "Step 278 (80783) @ Episode 337/10000, loss: 0.00056123908143490555\n",
      "Episode Reward: 2.0\n",
      "Step 309 (81092) @ Episode 338/10000, loss: 0.00122902751900255684\n",
      "Episode Reward: 2.0\n",
      "Step 350 (81442) @ Episode 339/10000, loss: 0.00025255410582758486\n",
      "Episode Reward: 3.0\n",
      "Step 235 (81677) @ Episode 340/10000, loss: 0.00036721825017593826\n",
      "Episode Reward: 1.0\n",
      "Step 273 (81950) @ Episode 341/10000, loss: 0.00060725642833858733\n",
      "Episode Reward: 2.0\n",
      "Step 234 (82184) @ Episode 342/10000, loss: 0.00098607211839407685\n",
      "Episode Reward: 1.0\n",
      "Step 184 (82368) @ Episode 343/10000, loss: 0.00172280403785407543\n",
      "Episode Reward: 0.0\n",
      "Step 238 (82606) @ Episode 344/10000, loss: 0.00021903324523009365\n",
      "Episode Reward: 1.0\n",
      "Step 175 (82781) @ Episode 345/10000, loss: 0.00027330644661560655\n",
      "Episode Reward: 0.0\n",
      "Step 300 (83081) @ Episode 346/10000, loss: 0.00148902670480310926\n",
      "Episode Reward: 2.0\n",
      "Step 226 (83307) @ Episode 347/10000, loss: 0.00104105530772358187\n",
      "Episode Reward: 1.0\n",
      "Step 232 (83539) @ Episode 348/10000, loss: 0.00062647991580888636\n",
      "Episode Reward: 1.0\n",
      "Step 239 (83778) @ Episode 349/10000, loss: 0.00016537550254724923\n",
      "Episode Reward: 1.0\n",
      "Step 170 (83948) @ Episode 350/10000, loss: 0.00016604126722086224\n",
      "Episode Reward: 0.0\n",
      "Step 167 (84115) @ Episode 351/10000, loss: 0.00093195971567183737\n",
      "Episode Reward: 0.0\n",
      "Step 231 (84346) @ Episode 352/10000, loss: 0.00044353492558002473\n",
      "Episode Reward: 1.0\n",
      "Step 227 (84573) @ Episode 353/10000, loss: 0.00065452291164547206\n",
      "Episode Reward: 1.0\n",
      "Step 312 (84885) @ Episode 354/10000, loss: 0.00052317621884867557\n",
      "Episode Reward: 2.0\n",
      "Step 163 (85048) @ Episode 355/10000, loss: 0.00045398887596093128\n",
      "Episode Reward: 0.0\n",
      "Step 173 (85221) @ Episode 356/10000, loss: 0.00011397502385079861\n",
      "Episode Reward: 0.0\n",
      "Step 231 (85452) @ Episode 357/10000, loss: 0.00108858780004084127\n",
      "Episode Reward: 1.0\n",
      "Step 298 (85750) @ Episode 358/10000, loss: 0.00075467082206159834\n",
      "Episode Reward: 2.0\n",
      "Step 223 (85973) @ Episode 359/10000, loss: 0.00072980881668627268\n",
      "Episode Reward: 1.0\n",
      "Step 338 (86311) @ Episode 360/10000, loss: 0.00030458168475888675\n",
      "Episode Reward: 3.0\n",
      "Step 165 (86476) @ Episode 361/10000, loss: 0.00069996778620406996\n",
      "Episode Reward: 0.0\n",
      "Step 479 (86955) @ Episode 362/10000, loss: 0.00062796787824481736\n",
      "Episode Reward: 6.0\n",
      "Step 273 (87228) @ Episode 363/10000, loss: 0.00025595512124709785\n",
      "Episode Reward: 2.0\n",
      "Step 165 (87393) @ Episode 364/10000, loss: 0.00013350934023037553\n",
      "Episode Reward: 0.0\n",
      "Step 238 (87631) @ Episode 365/10000, loss: 0.00012067271018167958\n",
      "Episode Reward: 1.0\n",
      "Step 216 (87847) @ Episode 366/10000, loss: 0.00016141950618475676\n",
      "Episode Reward: 1.0\n",
      "Step 299 (88146) @ Episode 367/10000, loss: 0.00077901018084958263\n",
      "Episode Reward: 2.0\n",
      "Step 343 (88489) @ Episode 368/10000, loss: 0.00012277983478270472\n",
      "Episode Reward: 3.0\n",
      "Step 188 (88677) @ Episode 369/10000, loss: 0.00016722510918043554\n",
      "Episode Reward: 0.0\n",
      "Step 237 (88914) @ Episode 370/10000, loss: 0.00014318160538095983\n",
      "Episode Reward: 1.0\n",
      "Step 175 (89089) @ Episode 371/10000, loss: 0.00044595130020752555\n",
      "Episode Reward: 0.0\n",
      "Step 219 (89308) @ Episode 372/10000, loss: 0.00036316941259428863\n",
      "Episode Reward: 1.0\n",
      "Step 225 (89533) @ Episode 373/10000, loss: 0.00033611370599828662\n",
      "Episode Reward: 1.0\n",
      "Step 221 (89754) @ Episode 374/10000, loss: 0.00018434284720569853\n",
      "Episode Reward: 1.0\n",
      "Step 167 (89921) @ Episode 375/10000, loss: 0.00063394603785127467\n",
      "Episode Reward: 0.0\n",
      "Step 78 (89999) @ Episode 376/10000, loss: 0.00059944204986095434\n",
      "Copied model parameters to target network.\n",
      "Step 247 (90168) @ Episode 376/10000, loss: 0.00208001397550106054\n",
      "Episode Reward: 1.0\n",
      "Step 177 (90345) @ Episode 377/10000, loss: 0.00347226439043879514\n",
      "Episode Reward: 0.0\n",
      "Step 207 (90552) @ Episode 378/10000, loss: 0.01176913361996412395\n",
      "Episode Reward: 1.0\n",
      "Step 285 (90837) @ Episode 379/10000, loss: 0.00045512663200497627\n",
      "Episode Reward: 2.0\n",
      "Step 237 (91074) @ Episode 380/10000, loss: 0.00053980364464223385\n",
      "Episode Reward: 1.0\n",
      "Step 415 (91489) @ Episode 381/10000, loss: 0.00168301817029714586\n",
      "Episode Reward: 4.0\n",
      "Step 463 (91952) @ Episode 382/10000, loss: 0.00086188939167186627\n",
      "Episode Reward: 5.0\n",
      "Step 274 (92226) @ Episode 383/10000, loss: 0.00133318186271935786\n",
      "Episode Reward: 2.0\n",
      "Step 255 (92481) @ Episode 384/10000, loss: 0.00089207896962761882\n",
      "Episode Reward: 2.0\n",
      "Step 251 (92732) @ Episode 385/10000, loss: 0.00146922236308455475\n",
      "Episode Reward: 1.0\n",
      "Step 165 (92897) @ Episode 386/10000, loss: 0.00051712826825678355\n",
      "Episode Reward: 0.0\n",
      "Step 259 (93156) @ Episode 387/10000, loss: 0.00020058678637724376\n",
      "Episode Reward: 2.0\n",
      "Step 243 (93399) @ Episode 388/10000, loss: 0.00174271385185420514\n",
      "Episode Reward: 1.0\n",
      "Step 243 (93642) @ Episode 389/10000, loss: 0.00363386864773929173\n",
      "Episode Reward: 1.0\n",
      "Step 302 (93944) @ Episode 390/10000, loss: 0.00035775834112428134\n",
      "Episode Reward: 2.0\n",
      "Step 257 (94201) @ Episode 391/10000, loss: 0.00012148031964898115\n",
      "Episode Reward: 1.0\n",
      "Step 291 (94492) @ Episode 392/10000, loss: 0.00024731611483730376\n",
      "Episode Reward: 2.0\n",
      "Step 178 (94670) @ Episode 393/10000, loss: 0.00020414136815816164\n",
      "Episode Reward: 0.0\n",
      "Step 178 (94848) @ Episode 394/10000, loss: 0.00252683274447917945\n",
      "Episode Reward: 0.0\n",
      "Step 199 (95047) @ Episode 395/10000, loss: 0.00049620546633377676\n",
      "Episode Reward: 0.0\n",
      "Step 250 (95297) @ Episode 396/10000, loss: 0.00104476429987698865\n",
      "Episode Reward: 1.0\n",
      "Step 285 (95582) @ Episode 397/10000, loss: 0.00013631148613058037\n",
      "Episode Reward: 2.0\n",
      "Step 268 (95850) @ Episode 398/10000, loss: 0.00043832734809257094\n",
      "Episode Reward: 2.0\n",
      "Step 405 (96255) @ Episode 399/10000, loss: 0.00046468089567497373\n",
      "Episode Reward: 4.0\n",
      "Step 200 (96455) @ Episode 400/10000, loss: 0.00047221413115039473\n",
      "Episode Reward: 0.0\n",
      "Step 178 (96633) @ Episode 401/10000, loss: 0.00076300435466691855\n",
      "Episode Reward: 0.0\n",
      "Step 272 (96905) @ Episode 402/10000, loss: 0.00053938833298161632\n",
      "Episode Reward: 2.0\n",
      "Step 238 (97143) @ Episode 403/10000, loss: 0.00029210251523181796\n",
      "Episode Reward: 1.0\n",
      "Step 230 (97373) @ Episode 404/10000, loss: 0.00037837479612790055\n",
      "Episode Reward: 1.0\n",
      "Step 269 (97642) @ Episode 405/10000, loss: 0.00028591690352186563\n",
      "Episode Reward: 2.0\n",
      "Step 179 (97821) @ Episode 406/10000, loss: 0.00017108974861912434\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 261 (98082) @ Episode 407/10000, loss: 0.00017490561003796756\n",
      "Episode Reward: 2.0\n",
      "Step 178 (98260) @ Episode 408/10000, loss: 0.00011174117389600724\n",
      "Episode Reward: 0.0\n",
      "Step 253 (98513) @ Episode 409/10000, loss: 0.00050987757276743657\n",
      "Episode Reward: 1.0\n",
      "Step 179 (98692) @ Episode 410/10000, loss: 0.00129669462330639364\n",
      "Episode Reward: 0.0\n",
      "Step 285 (98977) @ Episode 411/10000, loss: 0.00014073065540287644\n",
      "Episode Reward: 3.0\n",
      "Step 286 (99263) @ Episode 412/10000, loss: 0.00016284899902530015\n",
      "Episode Reward: 2.0\n",
      "Step 238 (99501) @ Episode 413/10000, loss: 0.00028810094227083035\n",
      "Episode Reward: 1.0\n",
      "Step 223 (99724) @ Episode 414/10000, loss: 0.00177795870695263154\n",
      "Episode Reward: 1.0\n",
      "Step 233 (99957) @ Episode 415/10000, loss: 0.00021013373043388128\n",
      "Episode Reward: 1.0\n",
      "Step 42 (99999) @ Episode 416/10000, loss: 0.00065044465009123096\n",
      "Copied model parameters to target network.\n",
      "Step 236 (100193) @ Episode 416/10000, loss: 0.00165810086764395245\n",
      "Episode Reward: 1.0\n",
      "Step 242 (100435) @ Episode 417/10000, loss: 0.00445746257901191706\n",
      "Episode Reward: 1.0\n",
      "Step 179 (100614) @ Episode 418/10000, loss: 0.00088794098701328042\n",
      "Episode Reward: 0.0\n",
      "Step 196 (100810) @ Episode 419/10000, loss: 0.00215759361162781714\n",
      "Episode Reward: 0.0\n",
      "Step 187 (100997) @ Episode 420/10000, loss: 0.00096670800121501095\n",
      "Episode Reward: 0.0\n",
      "Step 214 (101211) @ Episode 421/10000, loss: 0.00059048074763268235\n",
      "Episode Reward: 1.0\n",
      "Step 235 (101446) @ Episode 422/10000, loss: 0.00028643797850236297\n",
      "Episode Reward: 1.0\n",
      "Step 360 (101806) @ Episode 423/10000, loss: 0.00257462682202458467\n",
      "Episode Reward: 3.0\n",
      "Step 207 (102013) @ Episode 424/10000, loss: 8.584121678723022e-058\n",
      "Episode Reward: 1.0\n",
      "Step 187 (102200) @ Episode 425/10000, loss: 0.00172336329706013293\n",
      "Episode Reward: 0.0\n",
      "Step 214 (102414) @ Episode 426/10000, loss: 0.00129279098473489285\n",
      "Episode Reward: 1.0\n",
      "Step 529 (102943) @ Episode 427/10000, loss: 0.00079907698091119537\n",
      "Episode Reward: 6.0\n",
      "Step 166 (103109) @ Episode 428/10000, loss: 0.00097231043037027127\n",
      "Episode Reward: 0.0\n",
      "Step 356 (103465) @ Episode 429/10000, loss: 0.00089128100080415613\n",
      "Episode Reward: 3.0\n",
      "Step 229 (103694) @ Episode 430/10000, loss: 0.00083489192184060816\n",
      "Episode Reward: 1.0\n",
      "Step 229 (103923) @ Episode 431/10000, loss: 0.00017706640937831253\n",
      "Episode Reward: 1.0\n",
      "Step 299 (104222) @ Episode 432/10000, loss: 0.00026450242148712284\n",
      "Episode Reward: 2.0\n",
      "Step 180 (104402) @ Episode 433/10000, loss: 0.00132659508381038956\n",
      "Episode Reward: 0.0\n",
      "Step 175 (104577) @ Episode 434/10000, loss: 0.00038346997462213046\n",
      "Episode Reward: 0.0\n",
      "Step 180 (104757) @ Episode 435/10000, loss: 0.00089122541248798374\n",
      "Episode Reward: 0.0\n",
      "Step 231 (104988) @ Episode 436/10000, loss: 0.00057456979993730785\n",
      "Episode Reward: 1.0\n",
      "Step 274 (105262) @ Episode 437/10000, loss: 0.00047229891060851514\n",
      "Episode Reward: 2.0\n",
      "Step 167 (105429) @ Episode 438/10000, loss: 0.00025549117708578706\n",
      "Episode Reward: 0.0\n",
      "Step 179 (105608) @ Episode 439/10000, loss: 0.00028119294438511133\n",
      "Episode Reward: 0.0\n",
      "Step 240 (105848) @ Episode 440/10000, loss: 0.00054290803382173186\n",
      "Episode Reward: 1.0\n",
      "Step 288 (106136) @ Episode 441/10000, loss: 0.00013983229291625327\n",
      "Episode Reward: 2.0\n",
      "Step 225 (106361) @ Episode 442/10000, loss: 0.00018027571786660753\n",
      "Episode Reward: 1.0\n",
      "Step 164 (106525) @ Episode 443/10000, loss: 0.00093267578631639482\n",
      "Episode Reward: 0.0\n",
      "Step 183 (106708) @ Episode 444/10000, loss: 0.00025950936833396554\n",
      "Episode Reward: 0.0\n",
      "Step 383 (107091) @ Episode 445/10000, loss: 0.00019371460075490177\n",
      "Episode Reward: 3.0\n",
      "Step 245 (107336) @ Episode 446/10000, loss: 0.00097958999685943135\n",
      "Episode Reward: 1.0\n",
      "Step 191 (107527) @ Episode 447/10000, loss: 0.00020102613780181855\n",
      "Episode Reward: 0.0\n",
      "Step 277 (107804) @ Episode 448/10000, loss: 0.00109426002018153676\n",
      "Episode Reward: 2.0\n",
      "Step 241 (108045) @ Episode 449/10000, loss: 0.00011459466622909531\n",
      "Episode Reward: 1.0\n",
      "Step 219 (108264) @ Episode 450/10000, loss: 0.00010229458712274209\n",
      "Episode Reward: 1.0\n",
      "Step 243 (108507) @ Episode 451/10000, loss: 0.00023937430523801595\n",
      "Episode Reward: 1.0\n",
      "Step 184 (108691) @ Episode 452/10000, loss: 0.00017547998868394643\n",
      "Episode Reward: 0.0\n",
      "Step 248 (108939) @ Episode 453/10000, loss: 0.00010107993148267269\n",
      "Episode Reward: 2.0\n",
      "Step 210 (109149) @ Episode 454/10000, loss: 0.00020014040637761354\n",
      "Episode Reward: 1.0\n",
      "Step 211 (109360) @ Episode 455/10000, loss: 0.00044808659004047513\n",
      "Episode Reward: 1.0\n",
      "Step 269 (109629) @ Episode 456/10000, loss: 0.00045964587479829793\n",
      "Episode Reward: 2.0\n",
      "Step 186 (109815) @ Episode 457/10000, loss: 0.00069418235216289763\n",
      "Episode Reward: 0.0\n",
      "Step 184 (109999) @ Episode 458/10000, loss: 0.00032730214297771454\n",
      "Copied model parameters to target network.\n",
      "Step 289 (110104) @ Episode 458/10000, loss: 0.00177227961830794813\n",
      "Episode Reward: 2.0\n",
      "Step 242 (110346) @ Episode 459/10000, loss: 0.00051088444888591777\n",
      "Episode Reward: 1.0\n",
      "Step 208 (110554) @ Episode 460/10000, loss: 0.00175427016802132133\n",
      "Episode Reward: 1.0\n",
      "Step 176 (110730) @ Episode 461/10000, loss: 0.00070486532058566816\n",
      "Episode Reward: 0.0\n",
      "Step 168 (110898) @ Episode 462/10000, loss: 0.00047114380868151784\n",
      "Episode Reward: 0.0\n",
      "Step 230 (111128) @ Episode 463/10000, loss: 0.00029862811788916595\n",
      "Episode Reward: 1.0\n",
      "Step 283 (111411) @ Episode 464/10000, loss: 0.00197126716375350955\n",
      "Episode Reward: 2.0\n",
      "Step 227 (111638) @ Episode 465/10000, loss: 0.00012407339818309993\n",
      "Episode Reward: 1.0\n",
      "Step 252 (111890) @ Episode 466/10000, loss: 0.00065482896752655517\n",
      "Episode Reward: 1.0\n",
      "Step 333 (112223) @ Episode 467/10000, loss: 0.00214884919114410887\n",
      "Episode Reward: 3.0\n",
      "Step 206 (112429) @ Episode 468/10000, loss: 0.00014197526616044343\n",
      "Episode Reward: 1.0\n",
      "Step 207 (112636) @ Episode 469/10000, loss: 0.00015795134822838008\n",
      "Episode Reward: 1.0\n",
      "Step 245 (112881) @ Episode 470/10000, loss: 0.00080988166155293586\n",
      "Episode Reward: 1.0\n",
      "Step 180 (113061) @ Episode 471/10000, loss: 0.00176692509558051823\n",
      "Episode Reward: 0.0\n",
      "Step 165 (113226) @ Episode 472/10000, loss: 0.00260601658374071146\n",
      "Episode Reward: 0.0\n",
      "Step 200 (113426) @ Episode 473/10000, loss: 0.00063496455550193797\n",
      "Episode Reward: 1.0\n",
      "Step 278 (113704) @ Episode 474/10000, loss: 0.00097295281011611225\n",
      "Episode Reward: 2.0\n",
      "Step 229 (113933) @ Episode 475/10000, loss: 0.00014669839583802968\n",
      "Episode Reward: 1.0\n",
      "Step 328 (114261) @ Episode 476/10000, loss: 0.00042099514394067233\n",
      "Episode Reward: 3.0\n",
      "Step 181 (114442) @ Episode 477/10000, loss: 0.00016647516167722642\n",
      "Episode Reward: 0.0\n",
      "Step 339 (114781) @ Episode 478/10000, loss: 0.00017280483734793964\n",
      "Episode Reward: 3.0\n",
      "Step 227 (115008) @ Episode 479/10000, loss: 0.00036566989729180935\n",
      "Episode Reward: 1.0\n",
      "Step 327 (115335) @ Episode 480/10000, loss: 0.00060412654420360924\n",
      "Episode Reward: 3.0\n",
      "Step 228 (115563) @ Episode 481/10000, loss: 0.00017720460891723633\n",
      "Episode Reward: 1.0\n",
      "Step 170 (115733) @ Episode 482/10000, loss: 0.00080451415851712238\n",
      "Episode Reward: 0.0\n",
      "Step 173 (115906) @ Episode 483/10000, loss: 0.00010038275650003925\n",
      "Episode Reward: 0.0\n",
      "Step 219 (116125) @ Episode 484/10000, loss: 0.00017542549176141625\n",
      "Episode Reward: 1.0\n",
      "Step 299 (116424) @ Episode 485/10000, loss: 0.00051319587510079154\n",
      "Episode Reward: 2.0\n",
      "Step 373 (116797) @ Episode 486/10000, loss: 0.00067044887691736221\n",
      "Episode Reward: 3.0\n",
      "Step 301 (117098) @ Episode 487/10000, loss: 0.00109627074562013155\n",
      "Episode Reward: 3.0\n",
      "Step 163 (117261) @ Episode 488/10000, loss: 0.00019787997007369995\n",
      "Episode Reward: 0.0\n",
      "Step 164 (117425) @ Episode 489/10000, loss: 0.00028708126046694815\n",
      "Episode Reward: 0.0\n",
      "Step 172 (117597) @ Episode 490/10000, loss: 0.00052474875701591373\n",
      "Episode Reward: 0.0\n",
      "Step 177 (117774) @ Episode 491/10000, loss: 0.00015665990940760824\n",
      "Episode Reward: 0.0\n",
      "Step 203 (117977) @ Episode 492/10000, loss: 0.00030370318563655026\n",
      "Episode Reward: 1.0\n",
      "Step 223 (118200) @ Episode 493/10000, loss: 0.00044291251106187757\n",
      "Episode Reward: 1.0\n",
      "Step 184 (118384) @ Episode 494/10000, loss: 0.00032131568877957764\n",
      "Episode Reward: 0.0\n",
      "Step 172 (118556) @ Episode 495/10000, loss: 0.00012937295832671225\n",
      "Episode Reward: 0.0\n",
      "Step 205 (118761) @ Episode 496/10000, loss: 0.00294711044989526272\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 404 (119165) @ Episode 497/10000, loss: 0.00012959432206116617\n",
      "Episode Reward: 4.0\n",
      "Step 204 (119369) @ Episode 498/10000, loss: 0.00012154696742072701\n",
      "Episode Reward: 1.0\n",
      "Step 267 (119636) @ Episode 499/10000, loss: 0.00022594971233047545\n",
      "Episode Reward: 2.0\n",
      "Step 192 (119828) @ Episode 500/10000, loss: 0.00074001925531774763\n",
      "Episode Reward: 0.0\n",
      "Step 171 (119999) @ Episode 501/10000, loss: 0.00189768825657665735\n",
      "Copied model parameters to target network.\n",
      "Step 230 (120058) @ Episode 501/10000, loss: 0.0040989303961396225\n",
      "Episode Reward: 1.0\n",
      "Step 219 (120277) @ Episode 502/10000, loss: 0.00231914734467864046\n",
      "Episode Reward: 1.0\n",
      "Step 175 (120452) @ Episode 503/10000, loss: 0.00147948798257857565\n",
      "Episode Reward: 0.0\n",
      "Step 204 (120656) @ Episode 504/10000, loss: 0.00100505608133971755\n",
      "Episode Reward: 1.0\n",
      "Step 172 (120828) @ Episode 505/10000, loss: 0.00035014568129554395\n",
      "Episode Reward: 0.0\n",
      "Step 230 (121058) @ Episode 506/10000, loss: 0.00156390515621751556\n",
      "Episode Reward: 1.0\n",
      "Step 290 (121348) @ Episode 507/10000, loss: 0.00019584844994824384\n",
      "Episode Reward: 2.0\n",
      "Step 274 (121622) @ Episode 508/10000, loss: 0.00153849576599895955\n",
      "Episode Reward: 2.0\n",
      "Step 169 (121791) @ Episode 509/10000, loss: 0.00053160148672759534\n",
      "Episode Reward: 0.0\n",
      "Step 166 (121957) @ Episode 510/10000, loss: 0.00029724766500294216\n",
      "Episode Reward: 0.0\n",
      "Step 206 (122163) @ Episode 511/10000, loss: 0.00232613319531083164\n",
      "Episode Reward: 1.0\n",
      "Step 173 (122336) @ Episode 512/10000, loss: 0.00079857168020680558\n",
      "Episode Reward: 0.0\n",
      "Step 171 (122507) @ Episode 513/10000, loss: 0.00018436305981595077\n",
      "Episode Reward: 0.0\n",
      "Step 237 (122744) @ Episode 514/10000, loss: 0.00025945794186554858\n",
      "Episode Reward: 1.0\n",
      "Step 227 (122971) @ Episode 515/10000, loss: 0.00045036914525553584\n",
      "Episode Reward: 1.0\n",
      "Step 238 (123209) @ Episode 516/10000, loss: 0.00047029502457007766\n",
      "Episode Reward: 1.0\n",
      "Step 330 (123539) @ Episode 517/10000, loss: 0.00018090951198246339\n",
      "Episode Reward: 3.0\n",
      "Step 174 (123713) @ Episode 518/10000, loss: 0.00022681351401843137\n",
      "Episode Reward: 0.0\n",
      "Step 173 (123886) @ Episode 519/10000, loss: 0.00129988300614058976\n",
      "Episode Reward: 0.0\n",
      "Step 292 (124178) @ Episode 520/10000, loss: 0.00039578517316840597\n",
      "Episode Reward: 2.0\n",
      "Step 292 (124470) @ Episode 521/10000, loss: 0.00057269539684057244\n",
      "Episode Reward: 2.0\n",
      "Step 299 (124769) @ Episode 522/10000, loss: 0.00080918316962197424\n",
      "Episode Reward: 2.0\n",
      "Step 179 (124948) @ Episode 523/10000, loss: 0.00026226748013868938\n",
      "Episode Reward: 0.0\n",
      "Step 234 (125182) @ Episode 524/10000, loss: 0.00024999779998324816\n",
      "Episode Reward: 1.0\n",
      "Step 161 (125343) @ Episode 525/10000, loss: 0.00063611456425860525\n",
      "Episode Reward: 0.0\n",
      "Step 372 (125715) @ Episode 526/10000, loss: 0.00045367347775027156\n",
      "Episode Reward: 4.0\n",
      "Step 222 (125937) @ Episode 527/10000, loss: 0.00061311537865549335\n",
      "Episode Reward: 1.0\n",
      "Step 242 (126179) @ Episode 528/10000, loss: 0.00036720247589983046\n",
      "Episode Reward: 1.0\n",
      "Step 170 (126349) @ Episode 529/10000, loss: 0.00103626528289169074\n",
      "Episode Reward: 0.0\n",
      "Step 217 (126566) @ Episode 530/10000, loss: 0.00038240221329033375\n",
      "Episode Reward: 1.0\n",
      "Step 363 (126929) @ Episode 531/10000, loss: 0.00026069639716297393\n",
      "Episode Reward: 3.0\n",
      "Step 356 (127285) @ Episode 532/10000, loss: 0.00064070161897689188\n",
      "Episode Reward: 3.0\n",
      "Step 280 (127565) @ Episode 533/10000, loss: 0.00023629437782801688\n",
      "Episode Reward: 2.0\n",
      "Step 237 (127802) @ Episode 534/10000, loss: 0.00053599366219714282\n",
      "Episode Reward: 1.0\n",
      "Step 311 (128113) @ Episode 535/10000, loss: 0.00011374168389011174\n",
      "Episode Reward: 2.0\n",
      "Step 296 (128409) @ Episode 536/10000, loss: 0.00023477373179048385\n",
      "Episode Reward: 2.0\n",
      "Step 161 (128570) @ Episode 537/10000, loss: 0.00021774056949652731\n",
      "Episode Reward: 0.0\n",
      "Step 180 (128750) @ Episode 538/10000, loss: 0.00112986657768487934\n",
      "Episode Reward: 0.0\n",
      "Step 334 (129084) @ Episode 539/10000, loss: 0.00027408829191699624\n",
      "Episode Reward: 3.0\n",
      "Step 211 (129295) @ Episode 540/10000, loss: 0.00032282574102282524\n",
      "Episode Reward: 1.0\n",
      "Step 176 (129471) @ Episode 541/10000, loss: 0.00214871601201593884\n",
      "Episode Reward: 0.0\n",
      "Step 234 (129705) @ Episode 542/10000, loss: 0.00011858285870403051\n",
      "Episode Reward: 1.0\n",
      "Step 175 (129880) @ Episode 543/10000, loss: 0.00011889195593539625\n",
      "Episode Reward: 0.0\n",
      "Step 119 (129999) @ Episode 544/10000, loss: 0.00058939179871231328\n",
      "Copied model parameters to target network.\n",
      "Step 272 (130152) @ Episode 544/10000, loss: 0.00115063262637704686\n",
      "Episode Reward: 2.0\n",
      "Step 257 (130409) @ Episode 545/10000, loss: 0.00150526245124638085\n",
      "Episode Reward: 1.0\n",
      "Step 173 (130582) @ Episode 546/10000, loss: 0.00049458706052973873\n",
      "Episode Reward: 0.0\n",
      "Step 314 (130896) @ Episode 547/10000, loss: 0.00044697980047203684\n",
      "Episode Reward: 3.0\n",
      "Step 264 (131160) @ Episode 548/10000, loss: 0.00434922333806753235\n",
      "Episode Reward: 2.0\n",
      "Step 189 (131349) @ Episode 549/10000, loss: 0.00040653868927620355\n",
      "Episode Reward: 0.0\n",
      "Step 239 (131588) @ Episode 550/10000, loss: 0.00091626588255167016\n",
      "Episode Reward: 1.0\n",
      "Step 409 (131997) @ Episode 551/10000, loss: 0.00037426600465551025\n",
      "Episode Reward: 4.0\n",
      "Step 176 (132173) @ Episode 552/10000, loss: 0.00086253788322210312\n",
      "Episode Reward: 0.0\n",
      "Step 208 (132381) @ Episode 553/10000, loss: 0.00117583409883081916\n",
      "Episode Reward: 1.0\n",
      "Step 228 (132609) @ Episode 554/10000, loss: 0.00017863963148556654\n",
      "Episode Reward: 1.0\n",
      "Step 309 (132918) @ Episode 555/10000, loss: 0.00023879364016465843\n",
      "Episode Reward: 2.0\n",
      "Step 203 (133121) @ Episode 556/10000, loss: 0.00255796080455184087\n",
      "Episode Reward: 1.0\n",
      "Step 481 (133602) @ Episode 557/10000, loss: 0.00064808659953996544\n",
      "Episode Reward: 5.0\n",
      "Step 218 (133820) @ Episode 558/10000, loss: 0.00069583492586389186\n",
      "Episode Reward: 1.0\n",
      "Step 224 (134044) @ Episode 559/10000, loss: 0.00179206836037337781\n",
      "Episode Reward: 1.0\n",
      "Step 249 (134293) @ Episode 560/10000, loss: 0.00052906927885487687\n",
      "Episode Reward: 1.0\n",
      "Step 168 (134461) @ Episode 561/10000, loss: 0.00153074925765395165\n",
      "Episode Reward: 0.0\n",
      "Step 273 (134734) @ Episode 562/10000, loss: 0.00101729249581694615\n",
      "Episode Reward: 2.0\n",
      "Step 275 (135009) @ Episode 563/10000, loss: 0.00021439828560687602\n",
      "Episode Reward: 2.0\n",
      "Step 247 (135256) @ Episode 564/10000, loss: 0.00109556852839887147\n",
      "Episode Reward: 1.0\n",
      "Step 176 (135432) @ Episode 565/10000, loss: 0.00033369945595040927\n",
      "Episode Reward: 0.0\n",
      "Step 271 (135703) @ Episode 566/10000, loss: 0.00063326017698273065\n",
      "Episode Reward: 2.0\n",
      "Step 364 (136067) @ Episode 567/10000, loss: 0.00020643463358283043\n",
      "Episode Reward: 3.0\n",
      "Step 245 (136312) @ Episode 568/10000, loss: 0.00100301392376422888\n",
      "Episode Reward: 2.0\n",
      "Step 363 (136675) @ Episode 569/10000, loss: 0.00051086628809571277\n",
      "Episode Reward: 3.0\n",
      "Step 173 (136848) @ Episode 570/10000, loss: 0.00083843839820474395\n",
      "Episode Reward: 0.0\n",
      "Step 301 (137149) @ Episode 571/10000, loss: 0.00023495755158364773\n",
      "Episode Reward: 2.0\n",
      "Step 234 (137383) @ Episode 572/10000, loss: 0.00027944595785811543\n",
      "Episode Reward: 1.0\n",
      "Step 238 (137621) @ Episode 573/10000, loss: 0.00141205859836190942\n",
      "Episode Reward: 1.0\n",
      "Step 207 (137828) @ Episode 574/10000, loss: 0.00091920484555885276\n",
      "Episode Reward: 1.0\n",
      "Step 236 (138064) @ Episode 575/10000, loss: 0.00053833873244002462\n",
      "Episode Reward: 1.0\n",
      "Step 296 (138360) @ Episode 576/10000, loss: 0.00084946892457082876\n",
      "Episode Reward: 2.0\n",
      "Step 375 (138735) @ Episode 577/10000, loss: 0.00010460089106345549\n",
      "Episode Reward: 4.0\n",
      "Step 305 (139040) @ Episode 578/10000, loss: 0.00022548619017470628\n",
      "Episode Reward: 3.0\n",
      "Step 239 (139279) @ Episode 579/10000, loss: 0.00053152546752244235\n",
      "Episode Reward: 2.0\n",
      "Step 235 (139514) @ Episode 580/10000, loss: 0.00018001385615207255\n",
      "Episode Reward: 1.0\n",
      "Step 170 (139684) @ Episode 581/10000, loss: 0.00020535869407467544\n",
      "Episode Reward: 0.0\n",
      "Step 246 (139930) @ Episode 582/10000, loss: 0.00244480418041348465\n",
      "Episode Reward: 1.0\n",
      "Step 69 (139999) @ Episode 583/10000, loss: 0.00032458230271004146\n",
      "Copied model parameters to target network.\n",
      "Step 170 (140100) @ Episode 583/10000, loss: 0.00037220056401565675\n",
      "Episode Reward: 0.0\n",
      "Step 206 (140306) @ Episode 584/10000, loss: 0.00065118662314489483\n",
      "Episode Reward: 1.0\n",
      "Step 409 (140715) @ Episode 585/10000, loss: 0.00218753772787749774\n",
      "Episode Reward: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 269 (140984) @ Episode 586/10000, loss: 0.00071574922185391198\n",
      "Episode Reward: 2.0\n",
      "Step 343 (141327) @ Episode 587/10000, loss: 0.00203977222554385667\n",
      "Episode Reward: 3.0\n",
      "Step 287 (141614) @ Episode 588/10000, loss: 0.00103078666143119347\n",
      "Episode Reward: 2.0\n",
      "Step 185 (141799) @ Episode 589/10000, loss: 0.00085345358820632137\n",
      "Episode Reward: 0.0\n",
      "Step 350 (142149) @ Episode 590/10000, loss: 0.00227348064072430134\n",
      "Episode Reward: 3.0\n",
      "Step 325 (142474) @ Episode 591/10000, loss: 0.00084058876382187014\n",
      "Episode Reward: 3.0\n",
      "Step 167 (142641) @ Episode 592/10000, loss: 0.00055804202565923336\n",
      "Episode Reward: 0.0\n",
      "Step 278 (142919) @ Episode 593/10000, loss: 0.00077072792919352656\n",
      "Episode Reward: 2.0\n",
      "Step 228 (143147) @ Episode 594/10000, loss: 0.00059372093528509146\n",
      "Episode Reward: 1.0\n",
      "Step 170 (143317) @ Episode 595/10000, loss: 0.00049710366874933244\n",
      "Episode Reward: 0.0\n",
      "Step 356 (143673) @ Episode 596/10000, loss: 0.00062799366423860194\n",
      "Episode Reward: 3.0\n",
      "Step 276 (143949) @ Episode 597/10000, loss: 0.00084291922394186265\n",
      "Episode Reward: 2.0\n",
      "Step 174 (144123) @ Episode 598/10000, loss: 0.00028205796843394637\n",
      "Episode Reward: 0.0\n",
      "Step 183 (144306) @ Episode 599/10000, loss: 0.00023775905719958246\n",
      "Episode Reward: 0.0\n",
      "Step 411 (144717) @ Episode 600/10000, loss: 0.00070751301245763937\n",
      "Episode Reward: 4.0\n",
      "Step 396 (145113) @ Episode 601/10000, loss: 0.00033331141457892954\n",
      "Episode Reward: 5.0\n",
      "Step 238 (145351) @ Episode 602/10000, loss: 0.00033975709811784327\n",
      "Episode Reward: 1.0\n",
      "Step 229 (145580) @ Episode 603/10000, loss: 0.00126200844533741476\n",
      "Episode Reward: 1.0\n",
      "Step 391 (145971) @ Episode 604/10000, loss: 0.00142785697244107727\n",
      "Episode Reward: 4.0\n",
      "Step 161 (146132) @ Episode 605/10000, loss: 0.00034576057805679747\n",
      "Episode Reward: 0.0\n",
      "Step 173 (146305) @ Episode 606/10000, loss: 0.00055058515863493083\n",
      "Episode Reward: 0.0\n",
      "Step 364 (146669) @ Episode 607/10000, loss: 0.00023046290152706206\n",
      "Episode Reward: 3.0\n",
      "Step 205 (146874) @ Episode 608/10000, loss: 0.00112748681567609333\n",
      "Episode Reward: 1.0\n",
      "Step 179 (147053) @ Episode 609/10000, loss: 0.00025119239580817525\n",
      "Episode Reward: 0.0\n",
      "Step 168 (147221) @ Episode 610/10000, loss: 0.00120741559658199555\n",
      "Episode Reward: 0.0\n",
      "Step 232 (147453) @ Episode 611/10000, loss: 0.00016610074089840055\n",
      "Episode Reward: 1.0\n",
      "Step 173 (147626) @ Episode 612/10000, loss: 0.00041875513852573935\n",
      "Episode Reward: 0.0\n",
      "Step 165 (147791) @ Episode 613/10000, loss: 0.00059055304154753684\n",
      "Episode Reward: 0.0\n",
      "Step 382 (148173) @ Episode 614/10000, loss: 0.00017385072715114802\n",
      "Episode Reward: 4.0\n",
      "Step 268 (148441) @ Episode 615/10000, loss: 0.00024598822346888488\n",
      "Episode Reward: 2.0\n",
      "Step 256 (148697) @ Episode 616/10000, loss: 0.00041945301927626133\n",
      "Episode Reward: 1.0\n",
      "Step 282 (148979) @ Episode 617/10000, loss: 0.00094133440870791674\n",
      "Episode Reward: 2.0\n",
      "Step 168 (149147) @ Episode 618/10000, loss: 0.00220179138705134439\n",
      "Episode Reward: 0.0\n",
      "Step 239 (149386) @ Episode 619/10000, loss: 0.00043414736865088344\n",
      "Episode Reward: 1.0\n",
      "Step 263 (149649) @ Episode 620/10000, loss: 0.00036713769077323377\n",
      "Episode Reward: 2.0\n",
      "Step 350 (149999) @ Episode 621/10000, loss: 0.00079932733206078414\n",
      "Copied model parameters to target network.\n",
      "Step 380 (150029) @ Episode 621/10000, loss: 0.0039298273622989655\n",
      "Episode Reward: 4.0\n",
      "Step 237 (150266) @ Episode 622/10000, loss: 0.00105244969017803677\n",
      "Episode Reward: 1.0\n",
      "Step 254 (150520) @ Episode 623/10000, loss: 0.00061872700462117796\n",
      "Episode Reward: 1.0\n",
      "Step 293 (150813) @ Episode 624/10000, loss: 0.00121876620687544353\n",
      "Episode Reward: 2.0\n",
      "Step 279 (151092) @ Episode 625/10000, loss: 0.00186637858860194684\n",
      "Episode Reward: 2.0\n",
      "Step 227 (151319) @ Episode 626/10000, loss: 0.00081424490781500945\n",
      "Episode Reward: 1.0\n",
      "Step 337 (151656) @ Episode 627/10000, loss: 0.00083708891179412647\n",
      "Episode Reward: 3.0\n",
      "Step 418 (152074) @ Episode 628/10000, loss: 0.00081768335076048976\n",
      "Episode Reward: 4.0\n",
      "Step 502 (152576) @ Episode 629/10000, loss: 0.00025547214318066835\n",
      "Episode Reward: 6.0\n",
      "Step 302 (152878) @ Episode 630/10000, loss: 0.00076350138988345865\n",
      "Episode Reward: 2.0\n",
      "Step 172 (153050) @ Episode 631/10000, loss: 0.00923688709735870486\n",
      "Episode Reward: 0.0\n",
      "Step 338 (153388) @ Episode 632/10000, loss: 0.00070018746191635736\n",
      "Episode Reward: 3.0\n",
      "Step 183 (153571) @ Episode 633/10000, loss: 0.00123983505181968213\n",
      "Episode Reward: 0.0\n",
      "Step 292 (153863) @ Episode 634/10000, loss: 0.00024317884526681155\n",
      "Episode Reward: 2.0\n",
      "Step 313 (154176) @ Episode 635/10000, loss: 0.00053044286323711286\n",
      "Episode Reward: 2.0\n",
      "Step 223 (154399) @ Episode 636/10000, loss: 0.00082566792843863375\n",
      "Episode Reward: 1.0\n",
      "Step 342 (154741) @ Episode 637/10000, loss: 0.00050850061234086752\n",
      "Episode Reward: 3.0\n",
      "Step 211 (154952) @ Episode 638/10000, loss: 0.00037021265598013997\n",
      "Episode Reward: 1.0\n",
      "Step 215 (155167) @ Episode 639/10000, loss: 0.00102383340708911426\n",
      "Episode Reward: 1.0\n",
      "Step 165 (155332) @ Episode 640/10000, loss: 0.00047028521657921374\n",
      "Episode Reward: 0.0\n",
      "Step 165 (155497) @ Episode 641/10000, loss: 0.00020392941951286048\n",
      "Episode Reward: 0.0\n",
      "Step 170 (155667) @ Episode 642/10000, loss: 0.00107261654920876034\n",
      "Episode Reward: 0.0\n",
      "Step 309 (155976) @ Episode 643/10000, loss: 0.00051617447752505547\n",
      "Episode Reward: 2.0\n",
      "Step 218 (156194) @ Episode 644/10000, loss: 0.00029957055812701583\n",
      "Episode Reward: 1.0\n",
      "Step 182 (156376) @ Episode 645/10000, loss: 0.00099863158538937574\n",
      "Episode Reward: 0.0\n",
      "Step 292 (156668) @ Episode 646/10000, loss: 0.00031543997465632856\n",
      "Episode Reward: 2.0\n",
      "Step 300 (156968) @ Episode 647/10000, loss: 0.00027469551423564553\n",
      "Episode Reward: 2.0\n",
      "Step 167 (157135) @ Episode 648/10000, loss: 0.00049228896386921417\n",
      "Episode Reward: 0.0\n",
      "Step 232 (157367) @ Episode 649/10000, loss: 0.00103387213312089445\n",
      "Episode Reward: 1.0\n",
      "Step 270 (157637) @ Episode 650/10000, loss: 0.00040527246892452246\n",
      "Episode Reward: 2.0\n",
      "Step 304 (157941) @ Episode 651/10000, loss: 0.00067471025977283725\n",
      "Episode Reward: 2.0\n",
      "Step 267 (158208) @ Episode 652/10000, loss: 0.00016317420522682377\n",
      "Episode Reward: 2.0\n",
      "Step 169 (158377) @ Episode 653/10000, loss: 0.00029358835308812564\n",
      "Episode Reward: 0.0\n",
      "Step 287 (158664) @ Episode 654/10000, loss: 0.00094602245371788747\n",
      "Episode Reward: 2.0\n",
      "Step 226 (158890) @ Episode 655/10000, loss: 0.00016925948148127645\n",
      "Episode Reward: 1.0\n",
      "Step 270 (159160) @ Episode 656/10000, loss: 0.00061834056396037343\n",
      "Episode Reward: 2.0\n",
      "Step 353 (159513) @ Episode 657/10000, loss: 0.00027606642106547955\n",
      "Episode Reward: 3.0\n",
      "Step 173 (159686) @ Episode 658/10000, loss: 0.00057407718850299727\n",
      "Episode Reward: 0.0\n",
      "Step 171 (159857) @ Episode 659/10000, loss: 0.00031922801281325523\n",
      "Episode Reward: 0.0\n",
      "Step 142 (159999) @ Episode 660/10000, loss: 0.00015028864436317235\n",
      "Copied model parameters to target network.\n",
      "Step 283 (160140) @ Episode 660/10000, loss: 0.00101769273169338727\n",
      "Episode Reward: 2.0\n",
      "Step 237 (160377) @ Episode 661/10000, loss: 0.00189320032950490714\n",
      "Episode Reward: 1.0\n",
      "Step 174 (160551) @ Episode 662/10000, loss: 0.00116755964700132664\n",
      "Episode Reward: 0.0\n",
      "Step 218 (160769) @ Episode 663/10000, loss: 0.00171132013201713564\n",
      "Episode Reward: 1.0\n",
      "Step 172 (160941) @ Episode 664/10000, loss: 0.00128478498663753273\n",
      "Episode Reward: 0.0\n",
      "Step 165 (161106) @ Episode 665/10000, loss: 0.00205255299806594856\n",
      "Episode Reward: 0.0\n",
      "Step 172 (161278) @ Episode 666/10000, loss: 0.00086217263014987117\n",
      "Episode Reward: 0.0\n",
      "Step 291 (161569) @ Episode 667/10000, loss: 0.00200858386233449885\n",
      "Episode Reward: 3.0\n",
      "Step 185 (161754) @ Episode 668/10000, loss: 0.00150347151793539526\n",
      "Episode Reward: 0.0\n",
      "Step 279 (162033) @ Episode 669/10000, loss: 0.00034024417982436717\n",
      "Episode Reward: 2.0\n",
      "Step 259 (162292) @ Episode 670/10000, loss: 0.00030716095352545384\n",
      "Episode Reward: 2.0\n",
      "Step 234 (162526) @ Episode 671/10000, loss: 0.00057866837596520786\n",
      "Episode Reward: 1.0\n",
      "Step 236 (162762) @ Episode 672/10000, loss: 0.00022625163546763366\n",
      "Episode Reward: 1.0\n",
      "Step 170 (162932) @ Episode 673/10000, loss: 0.00055216363398358237\n",
      "Episode Reward: 0.0\n",
      "Step 242 (163174) @ Episode 674/10000, loss: 0.00033581603202037513\n",
      "Episode Reward: 1.0\n",
      "Step 329 (163503) @ Episode 675/10000, loss: 0.00111019238829612735\n",
      "Episode Reward: 3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 274 (163777) @ Episode 676/10000, loss: 0.00805259495973587925\n",
      "Episode Reward: 2.0\n",
      "Step 283 (164060) @ Episode 677/10000, loss: 0.00050706381443887955\n",
      "Episode Reward: 2.0\n",
      "Step 235 (164295) @ Episode 678/10000, loss: 0.00141005893237888815\n",
      "Episode Reward: 1.0\n",
      "Step 410 (164705) @ Episode 679/10000, loss: 0.00021843108697794378\n",
      "Episode Reward: 4.0\n",
      "Step 166 (164871) @ Episode 680/10000, loss: 0.00114196690265089275\n",
      "Episode Reward: 0.0\n",
      "Step 225 (165096) @ Episode 681/10000, loss: 0.00038807431701570756\n",
      "Episode Reward: 1.0\n",
      "Step 314 (165410) @ Episode 682/10000, loss: 0.00030152560793794696\n",
      "Episode Reward: 2.0\n",
      "Step 242 (165652) @ Episode 683/10000, loss: 0.00023869860160630196\n",
      "Episode Reward: 1.0\n",
      "Step 225 (165877) @ Episode 684/10000, loss: 0.00074467778904363518\n",
      "Episode Reward: 1.0\n",
      "Step 295 (166172) @ Episode 685/10000, loss: 0.00031837788992561435\n",
      "Episode Reward: 2.0\n",
      "Step 376 (166548) @ Episode 686/10000, loss: 0.00066789035918191085\n",
      "Episode Reward: 3.0\n",
      "Step 219 (166767) @ Episode 687/10000, loss: 0.00228427536785602576\n",
      "Episode Reward: 1.0\n",
      "Step 235 (167002) @ Episode 688/10000, loss: 0.00014916356303729117\n",
      "Episode Reward: 1.0\n",
      "Step 265 (167267) @ Episode 689/10000, loss: 0.00059807108482345946\n",
      "Episode Reward: 2.0\n",
      "Step 294 (167561) @ Episode 690/10000, loss: 0.00023000438523013145\n",
      "Episode Reward: 2.0\n",
      "Step 281 (167842) @ Episode 691/10000, loss: 0.00024845381267368793\n",
      "Episode Reward: 2.0\n",
      "Step 212 (168054) @ Episode 692/10000, loss: 0.00026445783441886306\n",
      "Episode Reward: 1.0\n",
      "Step 167 (168221) @ Episode 693/10000, loss: 0.00027942750602960587\n",
      "Episode Reward: 0.0\n",
      "Step 275 (168496) @ Episode 694/10000, loss: 0.00187200924847275024\n",
      "Episode Reward: 2.0\n",
      "Step 176 (168672) @ Episode 695/10000, loss: 0.00012384237197693437\n",
      "Episode Reward: 0.0\n",
      "Step 236 (168908) @ Episode 696/10000, loss: 0.00038016244070604444\n",
      "Episode Reward: 1.0\n",
      "Step 310 (169218) @ Episode 697/10000, loss: 0.00030478258850052953\n",
      "Episode Reward: 2.0\n",
      "Step 230 (169448) @ Episode 698/10000, loss: 0.00036392718902789056\n",
      "Episode Reward: 1.0\n",
      "Step 183 (169631) @ Episode 699/10000, loss: 0.00045933452202007174\n",
      "Episode Reward: 0.0\n",
      "Step 180 (169811) @ Episode 700/10000, loss: 0.00023895269259810448\n",
      "Episode Reward: 0.0\n",
      "Step 179 (169990) @ Episode 701/10000, loss: 0.00073609815444797286\n",
      "Episode Reward: 0.0\n",
      "Step 9 (169999) @ Episode 702/10000, loss: 0.00083085289224982269\n",
      "Copied model parameters to target network.\n",
      "Step 278 (170268) @ Episode 702/10000, loss: 0.00041168797179125259\n",
      "Episode Reward: 2.0\n",
      "Step 284 (170552) @ Episode 703/10000, loss: 0.00106379785574972636\n",
      "Episode Reward: 2.0\n",
      "Step 172 (170724) @ Episode 704/10000, loss: 0.00036264988011680543\n",
      "Episode Reward: 0.0\n",
      "Step 239 (170963) @ Episode 705/10000, loss: 0.00258848024532198992\n",
      "Episode Reward: 1.0\n",
      "Step 320 (171283) @ Episode 706/10000, loss: 0.00605040369555354115\n",
      "Episode Reward: 3.0\n",
      "Step 181 (171464) @ Episode 707/10000, loss: 0.00080515968147665265\n",
      "Episode Reward: 0.0\n",
      "Step 197 (171661) @ Episode 708/10000, loss: 0.00039484360604546964\n",
      "Episode Reward: 0.0\n",
      "Step 185 (171846) @ Episode 709/10000, loss: 0.00036254321457818156\n",
      "Episode Reward: 0.0\n",
      "Step 186 (172032) @ Episode 710/10000, loss: 0.00023162583238445222\n",
      "Episode Reward: 0.0\n",
      "Step 201 (172233) @ Episode 711/10000, loss: 0.00027174569549970334\n",
      "Episode Reward: 1.0\n",
      "Step 279 (172512) @ Episode 712/10000, loss: 0.00039627906517125666\n",
      "Episode Reward: 2.0\n",
      "Step 169 (172681) @ Episode 713/10000, loss: 0.00018215214367955923\n",
      "Episode Reward: 0.0\n",
      "Step 231 (172912) @ Episode 714/10000, loss: 0.00095517036970704793\n",
      "Episode Reward: 1.0\n",
      "Step 396 (173308) @ Episode 715/10000, loss: 0.00010859491158043966\n",
      "Episode Reward: 4.0\n",
      "Step 334 (173642) @ Episode 716/10000, loss: 0.00052256096387282015\n",
      "Episode Reward: 3.0\n",
      "Step 167 (173809) @ Episode 717/10000, loss: 0.00108006631489843133\n",
      "Episode Reward: 0.0\n",
      "Step 235 (174044) @ Episode 718/10000, loss: 0.00073132646502926954\n",
      "Episode Reward: 1.0\n",
      "Step 239 (174283) @ Episode 719/10000, loss: 0.00266943057067692353\n",
      "Episode Reward: 1.0\n",
      "Step 305 (174588) @ Episode 720/10000, loss: 0.00125131907407194383\n",
      "Episode Reward: 2.0\n",
      "Step 382 (174970) @ Episode 721/10000, loss: 0.00055730657186359172\n",
      "Episode Reward: 4.0\n",
      "Step 293 (175263) @ Episode 722/10000, loss: 0.00013617092918138953\n",
      "Episode Reward: 2.0\n",
      "Step 288 (175551) @ Episode 723/10000, loss: 0.00093890319112688355\n",
      "Episode Reward: 2.0\n",
      "Step 307 (175858) @ Episode 724/10000, loss: 0.00104482122696936135\n",
      "Episode Reward: 2.0\n",
      "Step 206 (176064) @ Episode 725/10000, loss: 0.00048135741963051265\n",
      "Episode Reward: 1.0\n",
      "Step 178 (176242) @ Episode 726/10000, loss: 0.00086841004667803655\n",
      "Episode Reward: 0.0\n",
      "Step 275 (176517) @ Episode 727/10000, loss: 0.00098367664031684433\n",
      "Episode Reward: 2.0\n",
      "Step 296 (176813) @ Episode 728/10000, loss: 0.00016564651741646238\n",
      "Episode Reward: 2.0\n",
      "Step 260 (177073) @ Episode 729/10000, loss: 0.00072964583523571494\n",
      "Episode Reward: 2.0\n",
      "Step 237 (177310) @ Episode 730/10000, loss: 0.00012993349810130894\n",
      "Episode Reward: 1.0\n",
      "Step 170 (177480) @ Episode 731/10000, loss: 0.00052517309086397296\n",
      "Episode Reward: 0.0\n",
      "Step 246 (177726) @ Episode 732/10000, loss: 0.00017531256889924407\n",
      "Episode Reward: 1.0\n",
      "Step 178 (177904) @ Episode 733/10000, loss: 0.00019184900156687945\n",
      "Episode Reward: 0.0\n",
      "Step 182 (178086) @ Episode 734/10000, loss: 0.00027445208979770545\n",
      "Episode Reward: 0.0\n",
      "Step 174 (178260) @ Episode 735/10000, loss: 0.00010519153147470206\n",
      "Episode Reward: 0.0\n",
      "Step 407 (178667) @ Episode 736/10000, loss: 0.00043293376802466812\n",
      "Episode Reward: 4.0\n",
      "Step 435 (179102) @ Episode 737/10000, loss: 0.00036772285238839686\n",
      "Episode Reward: 4.0\n",
      "Step 179 (179281) @ Episode 738/10000, loss: 0.00024825870059430667\n",
      "Episode Reward: 0.0\n",
      "Step 164 (179445) @ Episode 739/10000, loss: 0.00017364609811920673\n",
      "Episode Reward: 0.0\n",
      "Step 484 (179929) @ Episode 740/10000, loss: 0.00024649035185575485\n",
      "Episode Reward: 5.0\n",
      "Step 70 (179999) @ Episode 741/10000, loss: 0.00038560028770007193\n",
      "Copied model parameters to target network.\n",
      "Step 208 (180137) @ Episode 741/10000, loss: 0.00058006029576063168\n",
      "Episode Reward: 1.0\n",
      "Step 166 (180303) @ Episode 742/10000, loss: 0.00150435441173613076\n",
      "Episode Reward: 0.0\n",
      "Step 164 (180467) @ Episode 743/10000, loss: 0.00098476768471300643\n",
      "Episode Reward: 0.0\n",
      "Step 210 (180677) @ Episode 744/10000, loss: 0.00023723614867776632\n",
      "Episode Reward: 1.0\n",
      "Step 165 (180842) @ Episode 745/10000, loss: 0.00032538533560000365\n",
      "Episode Reward: 0.0\n",
      "Step 301 (181143) @ Episode 746/10000, loss: 0.00336927850730717286\n",
      "Episode Reward: 2.0\n",
      "Step 210 (181353) @ Episode 747/10000, loss: 0.00226194038987159737\n",
      "Episode Reward: 1.0\n",
      "Step 321 (181674) @ Episode 748/10000, loss: 0.00040135794552043085\n",
      "Episode Reward: 2.0\n",
      "Step 339 (182013) @ Episode 749/10000, loss: 0.00014166548498906195\n",
      "Episode Reward: 3.0\n",
      "Step 257 (182270) @ Episode 750/10000, loss: 0.00018598929455038166\n",
      "Episode Reward: 1.0\n",
      "Step 237 (182507) @ Episode 751/10000, loss: 0.00041608902392908934\n",
      "Episode Reward: 1.0\n",
      "Step 310 (182817) @ Episode 752/10000, loss: 0.00076994195114821224\n",
      "Episode Reward: 2.0\n",
      "Step 339 (183156) @ Episode 753/10000, loss: 0.00070292147574946284\n",
      "Episode Reward: 3.0\n",
      "Step 189 (183345) @ Episode 754/10000, loss: 0.00017757662863004953\n",
      "Episode Reward: 0.0\n",
      "Step 333 (183678) @ Episode 755/10000, loss: 0.00098899309523403643\n",
      "Episode Reward: 3.0\n",
      "Step 312 (183990) @ Episode 756/10000, loss: 0.00094004685524851088\n",
      "Episode Reward: 2.0\n",
      "Step 212 (184202) @ Episode 757/10000, loss: 0.00018379275570623577\n",
      "Episode Reward: 1.0\n",
      "Step 360 (184562) @ Episode 758/10000, loss: 0.00067732628667727113\n",
      "Episode Reward: 3.0\n",
      "Step 170 (184732) @ Episode 759/10000, loss: 0.00027072560624219477\n",
      "Episode Reward: 0.0\n",
      "Step 172 (184904) @ Episode 760/10000, loss: 0.00019091395370196556\n",
      "Episode Reward: 0.0\n",
      "Step 170 (185074) @ Episode 761/10000, loss: 0.00027717970078811054\n",
      "Episode Reward: 0.0\n",
      "Step 313 (185387) @ Episode 762/10000, loss: 0.00051850255113095053\n",
      "Episode Reward: 3.0\n",
      "Step 378 (185765) @ Episode 763/10000, loss: 0.00099548045545816423\n",
      "Episode Reward: 3.0\n",
      "Step 275 (186040) @ Episode 764/10000, loss: 0.00153503974433988336\n",
      "Episode Reward: 3.0\n",
      "Step 178 (186218) @ Episode 765/10000, loss: 0.00016945612151175737\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 313 (186531) @ Episode 766/10000, loss: 0.00044368012459017336\n",
      "Episode Reward: 2.0\n",
      "Step 247 (186778) @ Episode 767/10000, loss: 0.00083894992712885146\n",
      "Episode Reward: 1.0\n",
      "Step 268 (187046) @ Episode 768/10000, loss: 0.00015957767027430236\n",
      "Episode Reward: 2.0\n",
      "Step 182 (187228) @ Episode 769/10000, loss: 0.00017601861327420927\n",
      "Episode Reward: 0.0\n",
      "Step 161 (187389) @ Episode 770/10000, loss: 0.00021091848611831665\n",
      "Episode Reward: 0.0\n",
      "Step 164 (187553) @ Episode 771/10000, loss: 0.00017701086471788585\n",
      "Episode Reward: 0.0\n",
      "Step 495 (188048) @ Episode 772/10000, loss: 0.00024863408179953694\n",
      "Episode Reward: 5.0\n",
      "Step 241 (188289) @ Episode 773/10000, loss: 0.00044875376624986534\n",
      "Episode Reward: 2.0\n",
      "Step 177 (188466) @ Episode 774/10000, loss: 0.00038250212674029179\n",
      "Episode Reward: 0.0\n",
      "Step 699 (189165) @ Episode 775/10000, loss: 0.00012135074939578772\n",
      "Episode Reward: 9.0\n",
      "Step 246 (189411) @ Episode 776/10000, loss: 0.00098282750695943836\n",
      "Episode Reward: 1.0\n",
      "Step 187 (189598) @ Episode 777/10000, loss: 0.00023463446996174753\n",
      "Episode Reward: 0.0\n",
      "Step 174 (189772) @ Episode 778/10000, loss: 0.00100203510373830813\n",
      "Episode Reward: 0.0\n",
      "Step 227 (189999) @ Episode 779/10000, loss: 0.00080287142191082246\n",
      "Copied model parameters to target network.\n",
      "Step 249 (190021) @ Episode 779/10000, loss: 0.00048725149827077985\n",
      "Episode Reward: 1.0\n",
      "Step 262 (190283) @ Episode 780/10000, loss: 0.00275991647504270086\n",
      "Episode Reward: 1.0\n",
      "Step 232 (190515) @ Episode 781/10000, loss: 0.00162911973893642433\n",
      "Episode Reward: 1.0\n",
      "Step 279 (190794) @ Episode 782/10000, loss: 0.00149465142749249943\n",
      "Episode Reward: 2.0\n",
      "Step 239 (191033) @ Episode 783/10000, loss: 0.00050148321315646173\n",
      "Episode Reward: 1.0\n",
      "Step 282 (191315) @ Episode 784/10000, loss: 0.00089044478954747324\n",
      "Episode Reward: 2.0\n",
      "Step 284 (191599) @ Episode 785/10000, loss: 0.00040982064092531845\n",
      "Episode Reward: 2.0\n",
      "Step 236 (191835) @ Episode 786/10000, loss: 0.00119142467156052663\n",
      "Episode Reward: 1.0\n",
      "Step 175 (192010) @ Episode 787/10000, loss: 0.00051736226305365565\n",
      "Episode Reward: 0.0\n",
      "Step 305 (192315) @ Episode 788/10000, loss: 0.00041691958904266363\n",
      "Episode Reward: 2.0\n",
      "Step 281 (192596) @ Episode 789/10000, loss: 0.00081816565943881878\n",
      "Episode Reward: 2.0\n",
      "Step 180 (192776) @ Episode 790/10000, loss: 0.00046959976316429675\n",
      "Episode Reward: 0.0\n",
      "Step 172 (192948) @ Episode 791/10000, loss: 0.00073270831489935526\n",
      "Episode Reward: 0.0\n",
      "Step 271 (193219) @ Episode 792/10000, loss: 0.00029341276967898013\n",
      "Episode Reward: 2.0\n",
      "Step 238 (193457) @ Episode 793/10000, loss: 0.00079184316564351326\n",
      "Episode Reward: 1.0\n",
      "Step 176 (193633) @ Episode 794/10000, loss: 0.00026541939587332313\n",
      "Episode Reward: 0.0\n",
      "Step 240 (193873) @ Episode 795/10000, loss: 0.00036197286681272094\n",
      "Episode Reward: 1.0\n",
      "Step 180 (194053) @ Episode 796/10000, loss: 0.00050845195073634397\n",
      "Episode Reward: 0.0\n",
      "Step 168 (194221) @ Episode 797/10000, loss: 0.00061182177159935243\n",
      "Episode Reward: 0.0\n",
      "Step 308 (194529) @ Episode 798/10000, loss: 0.00047793221892789006\n",
      "Episode Reward: 2.0\n",
      "Step 440 (194969) @ Episode 799/10000, loss: 0.00126118340995162734\n",
      "Episode Reward: 5.0\n",
      "Step 235 (195204) @ Episode 800/10000, loss: 0.00049954821588471535\n",
      "Episode Reward: 1.0\n",
      "Step 185 (195389) @ Episode 801/10000, loss: 0.00062046572566032416\n",
      "Episode Reward: 0.0\n",
      "Step 210 (195599) @ Episode 802/10000, loss: 0.00056645844597369438\n",
      "Episode Reward: 1.0\n",
      "Step 170 (195769) @ Episode 803/10000, loss: 0.00046814084635116165\n",
      "Episode Reward: 0.0\n",
      "Step 275 (196044) @ Episode 804/10000, loss: 0.00076982070459052926\n",
      "Episode Reward: 1.0\n",
      "Step 261 (196305) @ Episode 805/10000, loss: 0.00087825150694698104\n",
      "Episode Reward: 2.0\n",
      "Step 290 (196595) @ Episode 806/10000, loss: 0.00028429125086404383\n",
      "Episode Reward: 2.0\n",
      "Step 179 (196774) @ Episode 807/10000, loss: 0.00125763670075684796\n",
      "Episode Reward: 0.0\n",
      "Step 281 (197055) @ Episode 808/10000, loss: 0.00055280135711655027\n",
      "Episode Reward: 2.0\n",
      "Step 172 (197227) @ Episode 809/10000, loss: 0.00048933003563433897\n",
      "Episode Reward: 0.0\n",
      "Step 182 (197409) @ Episode 810/10000, loss: 0.00038262357702478766\n",
      "Episode Reward: 0.0\n",
      "Step 237 (197646) @ Episode 811/10000, loss: 0.00090515287593007096\n",
      "Episode Reward: 1.0\n",
      "Step 297 (197943) @ Episode 812/10000, loss: 0.00040709870518185265\n",
      "Episode Reward: 3.0\n",
      "Step 280 (198223) @ Episode 813/10000, loss: 0.00012652661825995892\n",
      "Episode Reward: 2.0\n",
      "Step 509 (198732) @ Episode 814/10000, loss: 0.00040478369919583287\n",
      "Episode Reward: 6.0\n",
      "Step 173 (198905) @ Episode 815/10000, loss: 0.00023457589850295335\n",
      "Episode Reward: 0.0\n",
      "Step 226 (199131) @ Episode 816/10000, loss: 0.00034974591108039024\n",
      "Episode Reward: 1.0\n",
      "Step 209 (199340) @ Episode 817/10000, loss: 0.00092691974714398383\n",
      "Episode Reward: 1.0\n",
      "Step 432 (199772) @ Episode 818/10000, loss: 0.00030472569051198665\n",
      "Episode Reward: 4.0\n",
      "Step 227 (199999) @ Episode 819/10000, loss: 0.00045019277604296803\n",
      "Copied model parameters to target network.\n",
      "Step 381 (200153) @ Episode 819/10000, loss: 0.00082341785309836275\n",
      "Episode Reward: 3.0\n",
      "Step 173 (200326) @ Episode 820/10000, loss: 0.00123475212603807454\n",
      "Episode Reward: 0.0\n",
      "Step 231 (200557) @ Episode 821/10000, loss: 0.00129635899793356665\n",
      "Episode Reward: 1.0\n",
      "Step 199 (200756) @ Episode 822/10000, loss: 0.00117570941802114257\n",
      "Episode Reward: 0.0\n",
      "Step 366 (201122) @ Episode 823/10000, loss: 0.00045290682464838035\n",
      "Episode Reward: 3.0\n",
      "Step 169 (201291) @ Episode 824/10000, loss: 0.00053387990919873126\n",
      "Episode Reward: 0.0\n",
      "Step 235 (201526) @ Episode 825/10000, loss: 0.00062403676565736537\n",
      "Episode Reward: 1.0\n",
      "Step 241 (201767) @ Episode 826/10000, loss: 0.00049628654960542925\n",
      "Episode Reward: 1.0\n",
      "Step 235 (202002) @ Episode 827/10000, loss: 0.00045287166722118855\n",
      "Episode Reward: 1.0\n",
      "Step 307 (202309) @ Episode 828/10000, loss: 0.00048241633339785047\n",
      "Episode Reward: 2.0\n",
      "Step 225 (202534) @ Episode 829/10000, loss: 0.00053619674872606993\n",
      "Episode Reward: 1.0\n",
      "Step 175 (202709) @ Episode 830/10000, loss: 0.00043308787280693653\n",
      "Episode Reward: 0.0\n",
      "Step 303 (203012) @ Episode 831/10000, loss: 0.00025149312568828464\n",
      "Episode Reward: 2.0\n",
      "Step 272 (203284) @ Episode 832/10000, loss: 0.00062481622444465764\n",
      "Episode Reward: 2.0\n",
      "Step 177 (203461) @ Episode 833/10000, loss: 0.00099315389525145374\n",
      "Episode Reward: 0.0\n",
      "Step 169 (203630) @ Episode 834/10000, loss: 0.00074301147833466534\n",
      "Episode Reward: 0.0\n",
      "Step 174 (203804) @ Episode 835/10000, loss: 0.00085693330038338974\n",
      "Episode Reward: 0.0\n",
      "Step 248 (204052) @ Episode 836/10000, loss: 0.00088160281302407384\n",
      "Episode Reward: 1.0\n",
      "Step 196 (204248) @ Episode 837/10000, loss: 0.00104248418938368563\n",
      "Episode Reward: 0.0\n",
      "Step 263 (204511) @ Episode 838/10000, loss: 0.00100405106786638557\n",
      "Episode Reward: 1.0\n",
      "Step 189 (204700) @ Episode 839/10000, loss: 0.00065479986369609836\n",
      "Episode Reward: 0.0\n",
      "Step 216 (204916) @ Episode 840/10000, loss: 0.00052327045705169443\n",
      "Episode Reward: 1.0\n",
      "Step 211 (205127) @ Episode 841/10000, loss: 0.00137593992985785552\n",
      "Episode Reward: 1.0\n",
      "Step 208 (205335) @ Episode 842/10000, loss: 0.00055570586118847136\n",
      "Episode Reward: 1.0\n",
      "Step 250 (205585) @ Episode 843/10000, loss: 0.00054739433107897645\n",
      "Episode Reward: 1.0\n",
      "Step 241 (205826) @ Episode 844/10000, loss: 0.00148410710971802478\n",
      "Episode Reward: 1.0\n",
      "Step 252 (206078) @ Episode 845/10000, loss: 0.00086840277072042234\n",
      "Episode Reward: 1.0\n",
      "Step 223 (206301) @ Episode 846/10000, loss: 0.00028378129354678094\n",
      "Episode Reward: 1.0\n",
      "Step 220 (206521) @ Episode 847/10000, loss: 0.00054487306624650966\n",
      "Episode Reward: 1.0\n",
      "Step 291 (206812) @ Episode 848/10000, loss: 0.00138175208121538162\n",
      "Episode Reward: 2.0\n",
      "Step 265 (207077) @ Episode 849/10000, loss: 0.00074490194674581294\n",
      "Episode Reward: 2.0\n",
      "Step 234 (207311) @ Episode 850/10000, loss: 0.00029127119341865185\n",
      "Episode Reward: 1.0\n",
      "Step 292 (207603) @ Episode 851/10000, loss: 0.00037115154555067423\n",
      "Episode Reward: 3.0\n",
      "Step 190 (207793) @ Episode 852/10000, loss: 0.00059264141600579026\n",
      "Episode Reward: 0.0\n",
      "Step 205 (207998) @ Episode 853/10000, loss: 0.00063255813438445335\n",
      "Episode Reward: 1.0\n",
      "Step 236 (208234) @ Episode 854/10000, loss: 0.00020032325119245797\n",
      "Episode Reward: 1.0\n",
      "Step 241 (208475) @ Episode 855/10000, loss: 0.00046391761861741543\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 244 (208719) @ Episode 856/10000, loss: 0.00049385888269171125\n",
      "Episode Reward: 1.0\n",
      "Step 178 (208897) @ Episode 857/10000, loss: 0.00041883089579641823\n",
      "Episode Reward: 0.0\n",
      "Step 192 (209089) @ Episode 858/10000, loss: 0.00020380348723847425\n",
      "Episode Reward: 0.0\n",
      "Step 277 (209366) @ Episode 859/10000, loss: 0.00078653666423633787\n",
      "Episode Reward: 2.0\n",
      "Step 179 (209545) @ Episode 860/10000, loss: 0.00025438578450120986\n",
      "Episode Reward: 0.0\n",
      "Step 200 (209745) @ Episode 861/10000, loss: 0.00109454314224421985\n",
      "Episode Reward: 0.0\n",
      "Step 225 (209970) @ Episode 862/10000, loss: 0.00027661872445605695\n",
      "Episode Reward: 1.0\n",
      "Step 29 (209999) @ Episode 863/10000, loss: 0.00032946455758064985\n",
      "Copied model parameters to target network.\n",
      "Step 175 (210145) @ Episode 863/10000, loss: 0.00109525211155414585\n",
      "Episode Reward: 0.0\n",
      "Step 178 (210323) @ Episode 864/10000, loss: 0.00161726144142448954\n",
      "Episode Reward: 0.0\n",
      "Step 161 (210484) @ Episode 865/10000, loss: 0.00204132823273539546\n",
      "Episode Reward: 0.0\n",
      "Step 329 (210813) @ Episode 866/10000, loss: 0.00209031044505536563\n",
      "Episode Reward: 3.0\n",
      "Step 198 (211011) @ Episode 867/10000, loss: 0.00086783245205879214\n",
      "Episode Reward: 1.0\n",
      "Step 290 (211301) @ Episode 868/10000, loss: 0.00077660399256274194\n",
      "Episode Reward: 2.0\n",
      "Step 175 (211476) @ Episode 869/10000, loss: 0.00065797881688922646\n",
      "Episode Reward: 0.0\n",
      "Step 233 (211709) @ Episode 870/10000, loss: 0.00034881912870332674\n",
      "Episode Reward: 1.0\n",
      "Step 173 (211882) @ Episode 871/10000, loss: 0.00031724059954285624\n",
      "Episode Reward: 0.0\n",
      "Step 318 (212200) @ Episode 872/10000, loss: 0.00048527386388741434\n",
      "Episode Reward: 2.0\n",
      "Step 223 (212423) @ Episode 873/10000, loss: 0.00024961130111478278\n",
      "Episode Reward: 1.0\n",
      "Step 335 (212758) @ Episode 874/10000, loss: 0.00049066822975873957\n",
      "Episode Reward: 2.0\n",
      "Step 172 (212930) @ Episode 875/10000, loss: 0.00068645889405161143\n",
      "Episode Reward: 0.0\n",
      "Step 240 (213170) @ Episode 876/10000, loss: 0.00116417836397886287\n",
      "Episode Reward: 1.0\n",
      "Step 226 (213396) @ Episode 877/10000, loss: 0.00024449903867207472\n",
      "Episode Reward: 1.0\n",
      "Step 255 (213651) @ Episode 878/10000, loss: 0.00058793782955035576\n",
      "Episode Reward: 1.0\n",
      "Step 186 (213837) @ Episode 879/10000, loss: 0.00027159153250977397\n",
      "Episode Reward: 0.0\n",
      "Step 226 (214063) @ Episode 880/10000, loss: 0.00115336989983916284\n",
      "Episode Reward: 1.0\n",
      "Step 241 (214304) @ Episode 881/10000, loss: 0.00042073070653714246\n",
      "Episode Reward: 1.0\n",
      "Step 166 (214470) @ Episode 882/10000, loss: 0.01457594614475965512\n",
      "Episode Reward: 0.0\n",
      "Step 170 (214640) @ Episode 883/10000, loss: 0.00086392695084214215\n",
      "Episode Reward: 0.0\n",
      "Step 480 (215120) @ Episode 884/10000, loss: 0.00047871359856799245\n",
      "Episode Reward: 6.0\n",
      "Step 294 (215414) @ Episode 885/10000, loss: 0.00129383162129670386\n",
      "Episode Reward: 2.0\n",
      "Step 325 (215739) @ Episode 886/10000, loss: 0.00070182763738557744\n",
      "Episode Reward: 2.0\n",
      "Step 231 (215970) @ Episode 887/10000, loss: 0.00077865947969257837\n",
      "Episode Reward: 1.0\n",
      "Step 294 (216264) @ Episode 888/10000, loss: 0.00064797542290762074\n",
      "Episode Reward: 2.0\n",
      "Step 169 (216433) @ Episode 889/10000, loss: 0.00070965138729661764\n",
      "Episode Reward: 0.0\n",
      "Step 249 (216682) @ Episode 890/10000, loss: 0.00033627572702243924\n",
      "Episode Reward: 1.0\n",
      "Step 168 (216850) @ Episode 891/10000, loss: 0.00029562006238847976\n",
      "Episode Reward: 0.0\n",
      "Step 299 (217149) @ Episode 892/10000, loss: 0.00069500249810516833\n",
      "Episode Reward: 2.0\n",
      "Step 241 (217390) @ Episode 893/10000, loss: 0.00045295112067833543\n",
      "Episode Reward: 1.0\n",
      "Step 180 (217570) @ Episode 894/10000, loss: 0.00056799652520567187\n",
      "Episode Reward: 0.0\n",
      "Step 240 (217810) @ Episode 895/10000, loss: 0.00029500521486625075\n",
      "Episode Reward: 1.0\n",
      "Step 174 (217984) @ Episode 896/10000, loss: 0.00075808889232575898\n",
      "Episode Reward: 0.0\n",
      "Step 228 (218212) @ Episode 897/10000, loss: 0.00036617397563531995\n",
      "Episode Reward: 1.0\n",
      "Step 285 (218497) @ Episode 898/10000, loss: 0.00093709008069708946\n",
      "Episode Reward: 2.0\n",
      "Step 238 (218735) @ Episode 899/10000, loss: 0.00070545967901125555\n",
      "Episode Reward: 1.0\n",
      "Step 166 (218901) @ Episode 900/10000, loss: 0.00049223488895222544\n",
      "Episode Reward: 0.0\n",
      "Step 183 (219084) @ Episode 901/10000, loss: 0.00015776741201989353\n",
      "Episode Reward: 0.0\n",
      "Step 200 (219284) @ Episode 902/10000, loss: 0.00128173548728227627\n",
      "Episode Reward: 1.0\n",
      "Step 344 (219628) @ Episode 903/10000, loss: 0.00235736859031021633\n",
      "Episode Reward: 3.0\n",
      "Step 339 (219967) @ Episode 904/10000, loss: 0.00021250033751130104\n",
      "Episode Reward: 3.0\n",
      "Step 32 (219999) @ Episode 905/10000, loss: 0.00070035486714914444\n",
      "Copied model parameters to target network.\n",
      "Step 244 (220211) @ Episode 905/10000, loss: 0.00080700434045866135\n",
      "Episode Reward: 2.0\n",
      "Step 181 (220392) @ Episode 906/10000, loss: 0.00113707245327532316\n",
      "Episode Reward: 0.0\n",
      "Step 264 (220656) @ Episode 907/10000, loss: 0.00092530605616047983\n",
      "Episode Reward: 2.0\n",
      "Step 277 (220933) @ Episode 908/10000, loss: 0.00106813374441117056\n",
      "Episode Reward: 2.0\n",
      "Step 247 (221180) @ Episode 909/10000, loss: 0.00026167478063143794\n",
      "Episode Reward: 1.0\n",
      "Step 184 (221364) @ Episode 910/10000, loss: 0.00029516982613131404\n",
      "Episode Reward: 0.0\n",
      "Step 269 (221633) @ Episode 911/10000, loss: 0.00048442027764394885\n",
      "Episode Reward: 2.0\n",
      "Step 268 (221901) @ Episode 912/10000, loss: 0.00033457722747698426\n",
      "Episode Reward: 2.0\n",
      "Step 298 (222199) @ Episode 913/10000, loss: 0.00057150935754179957\n",
      "Episode Reward: 3.0\n",
      "Step 213 (222412) @ Episode 914/10000, loss: 0.00135347794275730854\n",
      "Episode Reward: 1.0\n",
      "Step 213 (222625) @ Episode 915/10000, loss: 0.00407836539670825315\n",
      "Episode Reward: 1.0\n",
      "Step 208 (222833) @ Episode 916/10000, loss: 0.00061537354486063126\n",
      "Episode Reward: 1.0\n",
      "Step 240 (223073) @ Episode 917/10000, loss: 0.00131461245473474264\n",
      "Episode Reward: 1.0\n",
      "Step 318 (223391) @ Episode 918/10000, loss: 0.00070796813815832147\n",
      "Episode Reward: 3.0\n",
      "Step 210 (223601) @ Episode 919/10000, loss: 0.00127551087643951184\n",
      "Episode Reward: 1.0\n",
      "Step 544 (224145) @ Episode 920/10000, loss: 0.00048586828052066267\n",
      "Episode Reward: 6.0\n",
      "Step 163 (224308) @ Episode 921/10000, loss: 0.00105431117117404945\n",
      "Episode Reward: 0.0\n",
      "Step 212 (224520) @ Episode 922/10000, loss: 0.00041808249079622333\n",
      "Episode Reward: 1.0\n",
      "Step 196 (224716) @ Episode 923/10000, loss: 0.00033033970976248384\n",
      "Episode Reward: 0.0\n",
      "Step 164 (224880) @ Episode 924/10000, loss: 0.00030842138221487403\n",
      "Episode Reward: 0.0\n",
      "Step 181 (225061) @ Episode 925/10000, loss: 0.00022319909476209432\n",
      "Episode Reward: 0.0\n",
      "Step 288 (225349) @ Episode 926/10000, loss: 0.00036379741504788476\n",
      "Episode Reward: 2.0\n",
      "Step 272 (225621) @ Episode 927/10000, loss: 0.00049504020716995675\n",
      "Episode Reward: 2.0\n",
      "Step 167 (225788) @ Episode 928/10000, loss: 0.00028068679966963838\n",
      "Episode Reward: 0.0\n",
      "Step 297 (226085) @ Episode 929/10000, loss: 0.00136545032728463416\n",
      "Episode Reward: 2.0\n",
      "Step 222 (226307) @ Episode 930/10000, loss: 0.00045206639333628123\n",
      "Episode Reward: 1.0\n",
      "Step 240 (226547) @ Episode 931/10000, loss: 0.00024158712767530233\n",
      "Episode Reward: 1.0\n",
      "Step 286 (226833) @ Episode 932/10000, loss: 0.00057605566689744594\n",
      "Episode Reward: 2.0\n",
      "Step 275 (227108) @ Episode 933/10000, loss: 0.00148482806980609949\n",
      "Episode Reward: 2.0\n",
      "Step 261 (227369) @ Episode 934/10000, loss: 0.00055050646187737583\n",
      "Episode Reward: 2.0\n",
      "Step 431 (227800) @ Episode 935/10000, loss: 0.00051467918092384938\n",
      "Episode Reward: 4.0\n",
      "Step 169 (227969) @ Episode 936/10000, loss: 0.00053611397743225113\n",
      "Episode Reward: 0.0\n",
      "Step 212 (228181) @ Episode 937/10000, loss: 0.00191008369438350257\n",
      "Episode Reward: 1.0\n",
      "Step 282 (228463) @ Episode 938/10000, loss: 0.00012901937589049347\n",
      "Episode Reward: 2.0\n",
      "Step 252 (228715) @ Episode 939/10000, loss: 0.00033679194166325033\n",
      "Episode Reward: 2.0\n",
      "Step 182 (228897) @ Episode 940/10000, loss: 0.00153360085096210243\n",
      "Episode Reward: 0.0\n",
      "Step 221 (229118) @ Episode 941/10000, loss: 0.00030708615668118975\n",
      "Episode Reward: 1.0\n",
      "Step 271 (229389) @ Episode 942/10000, loss: 0.00096961110830307017\n",
      "Episode Reward: 2.0\n",
      "Step 244 (229633) @ Episode 943/10000, loss: 0.00038190381019376227\n",
      "Episode Reward: 1.0\n",
      "Step 251 (229884) @ Episode 944/10000, loss: 0.00093423313228413465\n",
      "Episode Reward: 1.0\n",
      "Step 115 (229999) @ Episode 945/10000, loss: 0.00068020552862435583\n",
      "Copied model parameters to target network.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 206 (230090) @ Episode 945/10000, loss: 0.00096715707331895835\n",
      "Episode Reward: 0.0\n",
      "Step 207 (230297) @ Episode 946/10000, loss: 0.00054131413344293836\n",
      "Episode Reward: 0.0\n",
      "Step 171 (230468) @ Episode 947/10000, loss: 0.00098870974034070975\n",
      "Episode Reward: 0.0\n",
      "Step 234 (230702) @ Episode 948/10000, loss: 0.00369698787108063735\n",
      "Episode Reward: 1.0\n",
      "Step 170 (230872) @ Episode 949/10000, loss: 0.00113879214040935043\n",
      "Episode Reward: 0.0\n",
      "Step 171 (231043) @ Episode 950/10000, loss: 0.00053147354628890756\n",
      "Episode Reward: 0.0\n",
      "Step 249 (231292) @ Episode 951/10000, loss: 0.00089125859085470446\n",
      "Episode Reward: 1.0\n",
      "Step 173 (231465) @ Episode 952/10000, loss: 0.00130665802862495183\n",
      "Episode Reward: 0.0\n",
      "Step 227 (231692) @ Episode 953/10000, loss: 0.00085606629727408297\n",
      "Episode Reward: 1.0\n",
      "Step 171 (231863) @ Episode 954/10000, loss: 0.00075515994103625425\n",
      "Episode Reward: 0.0\n",
      "Step 303 (232166) @ Episode 955/10000, loss: 0.00045587279601022667\n",
      "Episode Reward: 2.0\n",
      "Step 246 (232412) @ Episode 956/10000, loss: 0.00050322443712502727\n",
      "Episode Reward: 1.0\n",
      "Step 247 (232659) @ Episode 957/10000, loss: 0.00076659675687551534\n",
      "Episode Reward: 2.0\n",
      "Step 241 (232900) @ Episode 958/10000, loss: 0.00093583168927580127\n",
      "Episode Reward: 2.0\n",
      "Step 209 (233109) @ Episode 959/10000, loss: 0.00128553039394319064\n",
      "Episode Reward: 1.0\n",
      "Step 242 (233351) @ Episode 960/10000, loss: 0.00077837595017626886\n",
      "Episode Reward: 1.0\n",
      "Step 228 (233579) @ Episode 961/10000, loss: 0.00120940990746021273\n",
      "Episode Reward: 1.0\n",
      "Step 289 (233868) @ Episode 962/10000, loss: 0.00120787858031690124\n",
      "Episode Reward: 2.0\n",
      "Step 238 (234106) @ Episode 963/10000, loss: 0.00068580114748328923\n",
      "Episode Reward: 1.0\n",
      "Step 178 (234284) @ Episode 964/10000, loss: 0.00024272403970826417\n",
      "Episode Reward: 0.0\n",
      "Step 219 (234503) @ Episode 965/10000, loss: 0.00051616562996059666\n",
      "Episode Reward: 1.0\n",
      "Step 172 (234675) @ Episode 966/10000, loss: 0.00229355506598949432\n",
      "Episode Reward: 0.0\n",
      "Step 192 (234867) @ Episode 967/10000, loss: 0.00064913183450698856\n",
      "Episode Reward: 0.0\n",
      "Step 188 (235055) @ Episode 968/10000, loss: 0.00071574066532775763\n",
      "Episode Reward: 0.0\n",
      "Step 227 (235282) @ Episode 969/10000, loss: 0.00042075748206116263\n",
      "Episode Reward: 1.0\n",
      "Step 172 (235454) @ Episode 970/10000, loss: 0.00100457877852022653\n",
      "Episode Reward: 0.0\n",
      "Step 177 (235631) @ Episode 971/10000, loss: 0.00083132635336369285\n",
      "Episode Reward: 0.0\n",
      "Step 299 (235930) @ Episode 972/10000, loss: 0.00021751745953224645\n",
      "Episode Reward: 2.0\n",
      "Step 219 (236149) @ Episode 973/10000, loss: 0.00091714243171736626\n",
      "Episode Reward: 1.0\n",
      "Step 347 (236496) @ Episode 974/10000, loss: 0.00058740307576954367\n",
      "Episode Reward: 4.0\n",
      "Step 244 (236740) @ Episode 975/10000, loss: 0.00029579375404864554\n",
      "Episode Reward: 1.0\n",
      "Step 272 (237012) @ Episode 976/10000, loss: 0.00078885006951168184\n",
      "Episode Reward: 2.0\n",
      "Step 181 (237193) @ Episode 977/10000, loss: 0.00041712922393344346\n",
      "Episode Reward: 0.0\n",
      "Step 355 (237548) @ Episode 978/10000, loss: 0.00071823189500719317\n",
      "Episode Reward: 3.0\n",
      "Step 223 (237771) @ Episode 979/10000, loss: 0.00030896929092705256\n",
      "Episode Reward: 1.0\n",
      "Step 173 (237944) @ Episode 980/10000, loss: 0.00046335780643858016\n",
      "Episode Reward: 0.0\n",
      "Step 247 (238191) @ Episode 981/10000, loss: 0.00046808537445031106\n",
      "Episode Reward: 1.0\n",
      "Step 299 (238490) @ Episode 982/10000, loss: 0.00125681061763316413\n",
      "Episode Reward: 3.0\n",
      "Step 253 (238743) @ Episode 983/10000, loss: 0.00177984568290412434\n",
      "Episode Reward: 1.0\n",
      "Step 441 (239184) @ Episode 984/10000, loss: 0.00117076444439589987\n",
      "Episode Reward: 5.0\n",
      "Step 298 (239482) @ Episode 985/10000, loss: 0.00067415880039334395\n",
      "Episode Reward: 2.0\n",
      "Step 209 (239691) @ Episode 986/10000, loss: 0.00023771729320287704\n",
      "Episode Reward: 1.0\n",
      "Step 264 (239955) @ Episode 987/10000, loss: 0.00083580985665321357\n",
      "Episode Reward: 1.0\n",
      "Step 44 (239999) @ Episode 988/10000, loss: 0.00056879257317632443\n",
      "Copied model parameters to target network.\n",
      "Step 284 (240239) @ Episode 988/10000, loss: 0.00058798387181013826\n",
      "Episode Reward: 2.0\n",
      "Step 351 (240590) @ Episode 989/10000, loss: 0.00063835049513727434\n",
      "Episode Reward: 2.0\n",
      "Step 170 (240760) @ Episode 990/10000, loss: 0.00064904254395514735\n",
      "Episode Reward: 0.0\n",
      "Step 198 (240958) @ Episode 991/10000, loss: 0.00075819791527464995\n",
      "Episode Reward: 0.0\n",
      "Step 210 (241168) @ Episode 992/10000, loss: 0.00039903138531371957\n",
      "Episode Reward: 1.0\n",
      "Step 184 (241352) @ Episode 993/10000, loss: 0.00073589175008237366\n",
      "Episode Reward: 0.0\n",
      "Step 289 (241641) @ Episode 994/10000, loss: 0.00057901843683794146\n",
      "Episode Reward: 2.0\n",
      "Step 210 (241851) @ Episode 995/10000, loss: 0.00293462863191962243\n",
      "Episode Reward: 1.0\n",
      "Step 328 (242179) @ Episode 996/10000, loss: 0.00043363549048081047\n",
      "Episode Reward: 3.0\n",
      "Step 178 (242357) @ Episode 997/10000, loss: 0.00101855315733701225\n",
      "Episode Reward: 0.0\n",
      "Step 189 (242546) @ Episode 998/10000, loss: 0.00183861481491476334\n",
      "Episode Reward: 0.0\n",
      "Step 238 (242784) @ Episode 999/10000, loss: 0.00053042196668684487\n",
      "Episode Reward: 1.0\n",
      "Step 175 (242959) @ Episode 1000/10000, loss: 0.00038025082903914154\n",
      "Episode Reward: 0.0\n",
      "Step 184 (243143) @ Episode 1001/10000, loss: 0.00297212949953973397\n",
      "Episode Reward: 0.0\n",
      "Step 211 (243354) @ Episode 1002/10000, loss: 0.00155094137880951177\n",
      "Episode Reward: 1.0\n",
      "Step 231 (243585) @ Episode 1003/10000, loss: 0.00111338682472705843\n",
      "Episode Reward: 1.0\n",
      "Step 187 (243772) @ Episode 1004/10000, loss: 0.00058375234948471198\n",
      "Episode Reward: 0.0\n",
      "Step 238 (244010) @ Episode 1005/10000, loss: 0.00317833246663212784\n",
      "Episode Reward: 1.0\n",
      "Step 185 (244195) @ Episode 1006/10000, loss: 0.00112447689753025776\n",
      "Episode Reward: 0.0\n",
      "Step 167 (244362) @ Episode 1007/10000, loss: 0.00078064855188131334\n",
      "Episode Reward: 0.0\n",
      "Step 214 (244576) @ Episode 1008/10000, loss: 0.00118852942250669257\n",
      "Episode Reward: 1.0\n",
      "Step 222 (244798) @ Episode 1009/10000, loss: 0.00050770089728757745\n",
      "Episode Reward: 1.0\n",
      "Step 208 (245006) @ Episode 1010/10000, loss: 0.00045852625044062734\n",
      "Episode Reward: 1.0\n",
      "Step 268 (245274) @ Episode 1011/10000, loss: 0.00081024348037317421\n",
      "Episode Reward: 2.0\n",
      "Step 186 (245460) @ Episode 1012/10000, loss: 0.00035258330171927815\n",
      "Episode Reward: 0.0\n",
      "Step 162 (245622) @ Episode 1013/10000, loss: 0.00072804943192750225\n",
      "Episode Reward: 0.0\n",
      "Step 230 (245852) @ Episode 1014/10000, loss: 0.00044307493953965604\n",
      "Episode Reward: 1.0\n",
      "Step 179 (246031) @ Episode 1015/10000, loss: 0.00027090421644970775\n",
      "Episode Reward: 0.0\n",
      "Step 210 (246241) @ Episode 1016/10000, loss: 0.00125751236919313675\n",
      "Episode Reward: 1.0\n",
      "Step 178 (246419) @ Episode 1017/10000, loss: 0.00045584113104268917\n",
      "Episode Reward: 0.0\n",
      "Step 314 (246733) @ Episode 1018/10000, loss: 0.00083125411765649913\n",
      "Episode Reward: 2.0\n",
      "Step 176 (246909) @ Episode 1019/10000, loss: 0.00112541159614920624\n",
      "Episode Reward: 0.0\n",
      "Step 186 (247095) @ Episode 1020/10000, loss: 0.00064410304185003048\n",
      "Episode Reward: 0.0\n",
      "Step 309 (247404) @ Episode 1021/10000, loss: 0.00034788201446644964\n",
      "Episode Reward: 2.0\n",
      "Step 207 (247611) @ Episode 1022/10000, loss: 0.00119795335922390225\n",
      "Episode Reward: 1.0\n",
      "Step 279 (247890) @ Episode 1023/10000, loss: 0.00052876106929034273\n",
      "Episode Reward: 2.0\n",
      "Step 416 (248306) @ Episode 1024/10000, loss: 0.00042192358523607254\n",
      "Episode Reward: 5.0\n",
      "Step 189 (248495) @ Episode 1025/10000, loss: 0.00206636777147650748\n",
      "Episode Reward: 0.0\n",
      "Step 340 (248835) @ Episode 1026/10000, loss: 0.00028743938310071826\n",
      "Episode Reward: 3.0\n",
      "Step 215 (249050) @ Episode 1027/10000, loss: 0.00076967477798461914\n",
      "Episode Reward: 1.0\n",
      "Step 245 (249295) @ Episode 1028/10000, loss: 0.00214466173201799413\n",
      "Episode Reward: 1.0\n",
      "Step 228 (249523) @ Episode 1029/10000, loss: 0.00078257767017930753\n",
      "Episode Reward: 1.0\n",
      "Step 171 (249694) @ Episode 1030/10000, loss: 0.00097350514261052014\n",
      "Episode Reward: 0.0\n",
      "Step 270 (249964) @ Episode 1031/10000, loss: 0.00092402443988248714\n",
      "Episode Reward: 2.0\n",
      "Step 35 (249999) @ Episode 1032/10000, loss: 0.00028771348297595988\n",
      "Copied model parameters to target network.\n",
      "Step 348 (250312) @ Episode 1032/10000, loss: 0.00038725923513993624\n",
      "Episode Reward: 3.0\n",
      "Step 317 (250629) @ Episode 1033/10000, loss: 0.00101225136313587435\n",
      "Episode Reward: 2.0\n",
      "Step 228 (250857) @ Episode 1034/10000, loss: 0.00082631531404331333\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 467 (251324) @ Episode 1035/10000, loss: 0.00048031317419372594\n",
      "Episode Reward: 4.0\n",
      "Step 388 (251712) @ Episode 1036/10000, loss: 0.00215978617779910565\n",
      "Episode Reward: 3.0\n",
      "Step 306 (252018) @ Episode 1037/10000, loss: 0.00123936159070581275\n",
      "Episode Reward: 2.0\n",
      "Step 430 (252448) @ Episode 1038/10000, loss: 0.00133260758593678475\n",
      "Episode Reward: 4.0\n",
      "Step 172 (252620) @ Episode 1039/10000, loss: 0.00042487503378652036\n",
      "Episode Reward: 0.0\n",
      "Step 170 (252790) @ Episode 1040/10000, loss: 0.00322419661097228537\n",
      "Episode Reward: 0.0\n",
      "Step 299 (253089) @ Episode 1041/10000, loss: 0.00100723910145461563\n",
      "Episode Reward: 2.0\n",
      "Step 312 (253401) @ Episode 1042/10000, loss: 0.00068558275233954196\n",
      "Episode Reward: 2.0\n",
      "Step 313 (253714) @ Episode 1043/10000, loss: 0.00092165003297850496\n",
      "Episode Reward: 2.0\n",
      "Step 191 (253905) @ Episode 1044/10000, loss: 0.00060922984266653663\n",
      "Episode Reward: 0.0\n",
      "Step 371 (254276) @ Episode 1045/10000, loss: 0.00151451304554939276\n",
      "Episode Reward: 4.0\n",
      "Step 214 (254490) @ Episode 1046/10000, loss: 0.00072817207546904684\n",
      "Episode Reward: 1.0\n",
      "Step 396 (254886) @ Episode 1047/10000, loss: 0.00812513194978237265\n",
      "Episode Reward: 4.0\n",
      "Step 231 (255117) @ Episode 1048/10000, loss: 0.00053635484073311093\n",
      "Episode Reward: 1.0\n",
      "Step 184 (255301) @ Episode 1049/10000, loss: 0.00070801004767417918\n",
      "Episode Reward: 0.0\n",
      "Step 254 (255555) @ Episode 1050/10000, loss: 0.00090218859259039167\n",
      "Episode Reward: 1.0\n",
      "Step 168 (255723) @ Episode 1051/10000, loss: 0.00069578894181177027\n",
      "Episode Reward: 0.0\n",
      "Step 276 (255999) @ Episode 1052/10000, loss: 0.00148473435547202832\n",
      "Episode Reward: 2.0\n",
      "Step 167 (256166) @ Episode 1053/10000, loss: 0.00102681107819080355\n",
      "Episode Reward: 0.0\n",
      "Step 179 (256345) @ Episode 1054/10000, loss: 0.00036233122227713466\n",
      "Episode Reward: 0.0\n",
      "Step 231 (256576) @ Episode 1055/10000, loss: 0.00039110262878239155\n",
      "Episode Reward: 1.0\n",
      "Step 255 (256831) @ Episode 1056/10000, loss: 0.00071905413642525675\n",
      "Episode Reward: 1.0\n",
      "Step 341 (257172) @ Episode 1057/10000, loss: 0.00023172795772552497\n",
      "Episode Reward: 3.0\n",
      "Step 532 (257704) @ Episode 1058/10000, loss: 0.00042153993854299193\n",
      "Episode Reward: 9.0\n",
      "Step 231 (257935) @ Episode 1059/10000, loss: 0.00105860829353332525\n",
      "Episode Reward: 1.0\n",
      "Step 274 (258209) @ Episode 1060/10000, loss: 0.00229746545664966176\n",
      "Episode Reward: 2.0\n",
      "Step 216 (258425) @ Episode 1061/10000, loss: 0.00419424707069993936\n",
      "Episode Reward: 1.0\n",
      "Step 339 (258764) @ Episode 1062/10000, loss: 0.00043463008478283884\n",
      "Episode Reward: 3.0\n",
      "Step 242 (259006) @ Episode 1063/10000, loss: 0.00194760260637849575\n",
      "Episode Reward: 1.0\n",
      "Step 187 (259193) @ Episode 1064/10000, loss: 0.00039386065327562393\n",
      "Episode Reward: 0.0\n",
      "Step 174 (259367) @ Episode 1065/10000, loss: 0.00091197295114398666\n",
      "Episode Reward: 0.0\n",
      "Step 334 (259701) @ Episode 1066/10000, loss: 0.00074615032644942476\n",
      "Episode Reward: 3.0\n",
      "Step 295 (259996) @ Episode 1067/10000, loss: 0.00077061948832124475\n",
      "Episode Reward: 3.0\n",
      "Step 3 (259999) @ Episode 1068/10000, loss: 0.00094139360589906573\n",
      "Copied model parameters to target network.\n",
      "Step 378 (260374) @ Episode 1068/10000, loss: 0.0007180800894275308\n",
      "Episode Reward: 3.0\n",
      "Step 175 (260549) @ Episode 1069/10000, loss: 0.00203304435126483446\n",
      "Episode Reward: 0.0\n",
      "Step 450 (260999) @ Episode 1070/10000, loss: 0.00090229994384571915\n",
      "Episode Reward: 6.0\n",
      "Step 470 (261469) @ Episode 1071/10000, loss: 0.00414673145860433673\n",
      "Episode Reward: 5.0\n",
      "Step 276 (261745) @ Episode 1072/10000, loss: 0.00525477482005953826\n",
      "Episode Reward: 2.0\n",
      "Step 346 (262091) @ Episode 1073/10000, loss: 0.00179762183688581854\n",
      "Episode Reward: 3.0\n",
      "Step 287 (262378) @ Episode 1074/10000, loss: 0.00152585352770984176\n",
      "Episode Reward: 2.0\n",
      "Step 199 (262577) @ Episode 1075/10000, loss: 0.00028505976661108434\n",
      "Episode Reward: 0.0\n",
      "Step 249 (262826) @ Episode 1076/10000, loss: 0.00052026531193405396\n",
      "Episode Reward: 1.0\n",
      "Step 425 (263251) @ Episode 1077/10000, loss: 0.00065453909337520684\n",
      "Episode Reward: 8.0\n",
      "Step 237 (263488) @ Episode 1078/10000, loss: 0.00158586294855922465\n",
      "Episode Reward: 1.0\n",
      "Step 271 (263759) @ Episode 1079/10000, loss: 0.00070661498466506666\n",
      "Episode Reward: 2.0\n",
      "Step 237 (263996) @ Episode 1080/10000, loss: 0.02527461946010589696\n",
      "Episode Reward: 1.0\n",
      "Step 233 (264229) @ Episode 1081/10000, loss: 0.00046956175356172025\n",
      "Episode Reward: 1.0\n",
      "Step 272 (264501) @ Episode 1082/10000, loss: 0.00082996225683018577\n",
      "Episode Reward: 2.0\n",
      "Step 202 (264703) @ Episode 1083/10000, loss: 0.00096594000933691866\n",
      "Episode Reward: 1.0\n",
      "Step 187 (264890) @ Episode 1084/10000, loss: 0.00104721868410706523\n",
      "Episode Reward: 0.0\n",
      "Step 349 (265239) @ Episode 1085/10000, loss: 0.00202414626255631453\n",
      "Episode Reward: 3.0\n",
      "Step 381 (265620) @ Episode 1086/10000, loss: 0.00094438932137563826\n",
      "Episode Reward: 4.0\n",
      "Step 310 (265930) @ Episode 1087/10000, loss: 0.00131228589452803134\n",
      "Episode Reward: 2.0\n",
      "Step 342 (266272) @ Episode 1088/10000, loss: 0.00045450567267835143\n",
      "Episode Reward: 3.0\n",
      "Step 288 (266560) @ Episode 1089/10000, loss: 0.00143374572508037145\n",
      "Episode Reward: 2.0\n",
      "Step 171 (266731) @ Episode 1090/10000, loss: 0.00036522810114547617\n",
      "Episode Reward: 0.0\n",
      "Step 317 (267048) @ Episode 1091/10000, loss: 0.00338250468485057353\n",
      "Episode Reward: 3.0\n",
      "Step 378 (267426) @ Episode 1092/10000, loss: 0.00033937857369892384\n",
      "Episode Reward: 4.0\n",
      "Step 368 (267794) @ Episode 1093/10000, loss: 0.00087889761198312047\n",
      "Episode Reward: 3.0\n",
      "Step 454 (268248) @ Episode 1094/10000, loss: 0.00730267819017171936\n",
      "Episode Reward: 5.0\n",
      "Step 361 (268609) @ Episode 1095/10000, loss: 0.00042305592796765276\n",
      "Episode Reward: 3.0\n",
      "Step 291 (268900) @ Episode 1096/10000, loss: 0.00055150128901004795\n",
      "Episode Reward: 2.0\n",
      "Step 268 (269168) @ Episode 1097/10000, loss: 0.00043657785863615572\n",
      "Episode Reward: 2.0\n",
      "Step 269 (269437) @ Episode 1098/10000, loss: 0.00072350027039647167\n",
      "Episode Reward: 2.0\n",
      "Step 165 (269602) @ Episode 1099/10000, loss: 0.00063133082585409283\n",
      "Episode Reward: 0.0\n",
      "Step 174 (269776) @ Episode 1100/10000, loss: 0.00052251789020374423\n",
      "Episode Reward: 0.0\n",
      "Step 223 (269999) @ Episode 1101/10000, loss: 0.00048986921319738036\n",
      "Copied model parameters to target network.\n",
      "Step 235 (270011) @ Episode 1101/10000, loss: 0.0020384748931974173\n",
      "Episode Reward: 1.0\n",
      "Step 309 (270320) @ Episode 1102/10000, loss: 0.00222807982936501537\n",
      "Episode Reward: 2.0\n",
      "Step 415 (270735) @ Episode 1103/10000, loss: 0.00222690147347748383\n",
      "Episode Reward: 4.0\n",
      "Step 192 (270927) @ Episode 1104/10000, loss: 0.0013803431065753102\n",
      "Episode Reward: 0.0\n",
      "Step 244 (271171) @ Episode 1105/10000, loss: 0.00050641375128179793\n",
      "Episode Reward: 1.0\n",
      "Step 183 (271354) @ Episode 1106/10000, loss: 0.00202348409220576356\n",
      "Episode Reward: 0.0\n",
      "Step 214 (271568) @ Episode 1107/10000, loss: 0.00078265974298119544\n",
      "Episode Reward: 1.0\n",
      "Step 270 (271838) @ Episode 1108/10000, loss: 0.00034148176200687885\n",
      "Episode Reward: 2.0\n",
      "Step 239 (272077) @ Episode 1109/10000, loss: 0.00109182321466505537\n",
      "Episode Reward: 1.0\n",
      "Step 247 (272324) @ Episode 1110/10000, loss: 0.00380270788446068766\n",
      "Episode Reward: 1.0\n",
      "Step 225 (272549) @ Episode 1111/10000, loss: 0.00101366685703396877\n",
      "Episode Reward: 1.0\n",
      "Step 334 (272883) @ Episode 1112/10000, loss: 0.00090542051475495164\n",
      "Episode Reward: 3.0\n",
      "Step 180 (273063) @ Episode 1113/10000, loss: 0.00164106453303247786\n",
      "Episode Reward: 0.0\n",
      "Step 212 (273275) @ Episode 1114/10000, loss: 0.00080202351091429597\n",
      "Episode Reward: 1.0\n",
      "Step 289 (273564) @ Episode 1115/10000, loss: 0.00179984641727060087\n",
      "Episode Reward: 2.0\n",
      "Step 413 (273977) @ Episode 1116/10000, loss: 0.00143050157930701976\n",
      "Episode Reward: 4.0\n",
      "Step 283 (274260) @ Episode 1117/10000, loss: 0.00094408867880702024\n",
      "Episode Reward: 2.0\n",
      "Step 228 (274488) @ Episode 1118/10000, loss: 0.00113635847810655835\n",
      "Episode Reward: 1.0\n",
      "Step 231 (274719) @ Episode 1119/10000, loss: 0.00043106885277666153\n",
      "Episode Reward: 1.0\n",
      "Step 219 (274938) @ Episode 1120/10000, loss: 0.00077757751569151887\n",
      "Episode Reward: 1.0\n",
      "Step 173 (275111) @ Episode 1121/10000, loss: 0.00138665025588125724\n",
      "Episode Reward: 0.0\n",
      "Step 313 (275424) @ Episode 1122/10000, loss: 0.00160624121781438596\n",
      "Episode Reward: 2.0\n",
      "Step 348 (275772) @ Episode 1123/10000, loss: 0.00110115564893931154\n",
      "Episode Reward: 3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 314 (276086) @ Episode 1124/10000, loss: 0.00071016408037394296\n",
      "Episode Reward: 2.0\n",
      "Step 415 (276501) @ Episode 1125/10000, loss: 0.00084463990060612566\n",
      "Episode Reward: 5.0\n",
      "Step 169 (276670) @ Episode 1126/10000, loss: 0.00054459407692775135\n",
      "Episode Reward: 0.0\n",
      "Step 239 (276909) @ Episode 1127/10000, loss: 0.00284228497184813025\n",
      "Episode Reward: 1.0\n",
      "Step 228 (277137) @ Episode 1128/10000, loss: 0.00177700910717248925\n",
      "Episode Reward: 1.0\n",
      "Step 334 (277471) @ Episode 1129/10000, loss: 0.00210920535027980887\n",
      "Episode Reward: 3.0\n",
      "Step 375 (277846) @ Episode 1130/10000, loss: 0.00073048082413151865\n",
      "Episode Reward: 4.0\n",
      "Step 441 (278287) @ Episode 1131/10000, loss: 0.00082422082778066467\n",
      "Episode Reward: 4.0\n",
      "Step 191 (278478) @ Episode 1132/10000, loss: 0.00064072135137394074\n",
      "Episode Reward: 0.0\n",
      "Step 265 (278743) @ Episode 1133/10000, loss: 0.00159587210509926084\n",
      "Episode Reward: 1.0\n",
      "Step 219 (278962) @ Episode 1134/10000, loss: 0.00054807198466733177\n",
      "Episode Reward: 1.0\n",
      "Step 278 (279240) @ Episode 1135/10000, loss: 0.00234691426157951356\n",
      "Episode Reward: 2.0\n",
      "Step 393 (279633) @ Episode 1136/10000, loss: 0.00033066119067370895\n",
      "Episode Reward: 5.0\n",
      "Step 320 (279953) @ Episode 1137/10000, loss: 0.00066078006057068717\n",
      "Episode Reward: 2.0\n",
      "Step 46 (279999) @ Episode 1138/10000, loss: 0.00121920148376375445\n",
      "Copied model parameters to target network.\n",
      "Step 384 (280337) @ Episode 1138/10000, loss: 0.00329613499343395236\n",
      "Episode Reward: 3.0\n",
      "Step 285 (280622) @ Episode 1139/10000, loss: 0.0005640272283926606\n",
      "Episode Reward: 2.0\n",
      "Step 430 (281052) @ Episode 1140/10000, loss: 0.00088915508240461353\n",
      "Episode Reward: 5.0\n",
      "Step 366 (281418) @ Episode 1141/10000, loss: 0.00255738710984587676\n",
      "Episode Reward: 3.0\n",
      "Step 305 (281723) @ Episode 1142/10000, loss: 0.01117430347949266455\n",
      "Episode Reward: 3.0\n",
      "Step 181 (281904) @ Episode 1143/10000, loss: 0.00152754480950534343\n",
      "Episode Reward: 0.0\n",
      "Step 213 (282117) @ Episode 1144/10000, loss: 0.00073674588929861786\n",
      "Episode Reward: 1.0\n",
      "Step 319 (282436) @ Episode 1145/10000, loss: 0.00096341891912743455\n",
      "Episode Reward: 3.0\n",
      "Step 277 (282713) @ Episode 1146/10000, loss: 0.00138713046908378673\n",
      "Episode Reward: 2.0\n",
      "Step 289 (283002) @ Episode 1147/10000, loss: 0.00070554361445829274\n",
      "Episode Reward: 2.0\n",
      "Step 256 (283258) @ Episode 1148/10000, loss: 0.00052853225497528914\n",
      "Episode Reward: 2.0\n",
      "Step 317 (283575) @ Episode 1149/10000, loss: 0.00096013641450554135\n",
      "Episode Reward: 2.0\n",
      "Step 458 (284033) @ Episode 1150/10000, loss: 0.00389128364622592937\n",
      "Episode Reward: 4.0\n",
      "Step 232 (284265) @ Episode 1151/10000, loss: 0.00083435315173119315\n",
      "Episode Reward: 1.0\n",
      "Step 279 (284544) @ Episode 1152/10000, loss: 0.00247720768675208174\n",
      "Episode Reward: 2.0\n",
      "Step 320 (284864) @ Episode 1153/10000, loss: 0.00056386238429695374\n",
      "Episode Reward: 3.0\n",
      "Step 310 (285174) @ Episode 1154/10000, loss: 0.00053800997557118545\n",
      "Episode Reward: 2.0\n",
      "Step 451 (285625) @ Episode 1155/10000, loss: 0.00037704984424635777\n",
      "Episode Reward: 4.0\n",
      "Step 218 (285843) @ Episode 1156/10000, loss: 0.00080323003930971037\n",
      "Episode Reward: 1.0\n",
      "Step 306 (286149) @ Episode 1157/10000, loss: 0.00163502362556755544\n",
      "Episode Reward: 2.0\n",
      "Step 364 (286513) @ Episode 1158/10000, loss: 0.00043003185419365764\n",
      "Episode Reward: 3.0\n",
      "Step 326 (286839) @ Episode 1159/10000, loss: 0.00079298095079138885\n",
      "Episode Reward: 3.0\n",
      "Step 273 (287112) @ Episode 1160/10000, loss: 0.00190128572285175323\n",
      "Episode Reward: 2.0\n",
      "Step 388 (287500) @ Episode 1161/10000, loss: 0.00294934818521142947\n",
      "Episode Reward: 3.0\n",
      "Step 345 (287845) @ Episode 1162/10000, loss: 0.00118911149911582476\n",
      "Episode Reward: 3.0\n",
      "Step 428 (288273) @ Episode 1163/10000, loss: 0.00036357139470055734\n",
      "Episode Reward: 6.0\n",
      "Step 317 (288590) @ Episode 1164/10000, loss: 0.00574831245467066886\n",
      "Episode Reward: 3.0\n",
      "Step 181 (288771) @ Episode 1165/10000, loss: 0.00035207491600885987\n",
      "Episode Reward: 0.0\n",
      "Step 411 (289182) @ Episode 1166/10000, loss: 0.00165914965327829123\n",
      "Episode Reward: 4.0\n",
      "Step 189 (289371) @ Episode 1167/10000, loss: 0.00073519570287317044\n",
      "Episode Reward: 0.0\n",
      "Step 478 (289849) @ Episode 1168/10000, loss: 0.00053839426254853615\n",
      "Episode Reward: 5.0\n",
      "Step 150 (289999) @ Episode 1169/10000, loss: 0.00040886440547183156\n",
      "Copied model parameters to target network.\n",
      "Step 254 (290103) @ Episode 1169/10000, loss: 0.0040474981069564824\n",
      "Episode Reward: 1.0\n",
      "Step 326 (290429) @ Episode 1170/10000, loss: 0.0096474727615714072\n",
      "Episode Reward: 2.0\n",
      "Step 367 (290796) @ Episode 1171/10000, loss: 0.0046892641112208375\n",
      "Episode Reward: 3.0\n",
      "Step 313 (291109) @ Episode 1172/10000, loss: 0.0010650372132658958\n",
      "Episode Reward: 2.0\n",
      "Step 181 (291290) @ Episode 1173/10000, loss: 0.00087896501645445827\n",
      "Episode Reward: 0.0\n",
      "Step 329 (291619) @ Episode 1174/10000, loss: 0.00088937638793140657\n",
      "Episode Reward: 2.0\n",
      "Step 546 (292165) @ Episode 1175/10000, loss: 0.01123784389346838327\n",
      "Episode Reward: 6.0\n",
      "Step 341 (292506) @ Episode 1176/10000, loss: 0.00296412082388997083\n",
      "Episode Reward: 3.0\n",
      "Step 320 (292826) @ Episode 1177/10000, loss: 0.00062950578285381287\n",
      "Episode Reward: 3.0\n",
      "Step 315 (293141) @ Episode 1178/10000, loss: 0.00781699363142252324\n",
      "Episode Reward: 3.0\n",
      "Step 451 (293592) @ Episode 1179/10000, loss: 0.00115168222691863787\n",
      "Episode Reward: 5.0\n",
      "Step 494 (294086) @ Episode 1180/10000, loss: 0.00075821892824023964\n",
      "Episode Reward: 6.0\n",
      "Step 477 (294563) @ Episode 1181/10000, loss: 0.00209424202330410525\n",
      "Episode Reward: 5.0\n",
      "Step 222 (294785) @ Episode 1182/10000, loss: 0.00078797031892463567\n",
      "Episode Reward: 1.0\n",
      "Step 301 (295086) @ Episode 1183/10000, loss: 0.00050866894889622935\n",
      "Episode Reward: 2.0\n",
      "Step 435 (295521) @ Episode 1184/10000, loss: 0.00164642254821956162\n",
      "Episode Reward: 4.0\n",
      "Step 405 (295926) @ Episode 1185/10000, loss: 0.00693477317690849355\n",
      "Episode Reward: 4.0\n",
      "Step 316 (296242) @ Episode 1186/10000, loss: 0.00063552183564752347\n",
      "Episode Reward: 2.0\n",
      "Step 410 (296652) @ Episode 1187/10000, loss: 0.00051440310198813687\n",
      "Episode Reward: 4.0\n",
      "Step 290 (296942) @ Episode 1188/10000, loss: 0.00085388746811077687\n",
      "Episode Reward: 2.0\n",
      "Step 472 (297414) @ Episode 1189/10000, loss: 0.00222613709047436784\n",
      "Episode Reward: 6.0\n",
      "Step 598 (298012) @ Episode 1190/10000, loss: 0.00042354856850579383\n",
      "Episode Reward: 8.0\n",
      "Step 427 (298439) @ Episode 1191/10000, loss: 0.00088854151545092465\n",
      "Episode Reward: 4.0\n",
      "Step 467 (298906) @ Episode 1192/10000, loss: 0.00052224361570551997\n",
      "Episode Reward: 5.0\n",
      "Step 397 (299303) @ Episode 1193/10000, loss: 0.00096878979820758133\n",
      "Episode Reward: 4.0\n",
      "Step 260 (299563) @ Episode 1194/10000, loss: 0.00263244402594864376\n",
      "Episode Reward: 1.0\n",
      "Step 436 (299999) @ Episode 1195/10000, loss: 0.00145656871609389786\n",
      "Copied model parameters to target network.\n",
      "Step 452 (300015) @ Episode 1195/10000, loss: 0.0013916343450546265\n",
      "Episode Reward: 5.0\n",
      "Step 229 (300244) @ Episode 1196/10000, loss: 0.0069776149466633847\n",
      "Episode Reward: 1.0\n",
      "Step 272 (300516) @ Episode 1197/10000, loss: 0.0027934629470109946\n",
      "Episode Reward: 1.0\n",
      "Step 346 (300862) @ Episode 1198/10000, loss: 0.00198643794283270846\n",
      "Episode Reward: 3.0\n",
      "Step 323 (301185) @ Episode 1199/10000, loss: 0.00218350160866975846\n",
      "Episode Reward: 3.0\n",
      "Step 388 (301573) @ Episode 1200/10000, loss: 0.00165550620295107363\n",
      "Episode Reward: 4.0\n",
      "Step 351 (301924) @ Episode 1201/10000, loss: 0.00287134712561965726\n",
      "Episode Reward: 3.0\n",
      "Step 503 (302427) @ Episode 1202/10000, loss: 0.00136655918322503576\n",
      "Episode Reward: 6.0\n",
      "Step 270 (302697) @ Episode 1203/10000, loss: 0.00062293920200318177\n",
      "Episode Reward: 2.0\n",
      "Step 292 (302989) @ Episode 1204/10000, loss: 0.00079212774289771915\n",
      "Episode Reward: 2.0\n",
      "Step 300 (303289) @ Episode 1205/10000, loss: 0.00068639201344922185\n",
      "Episode Reward: 2.0\n",
      "Step 526 (303815) @ Episode 1206/10000, loss: 0.00195612898096442224\n",
      "Episode Reward: 6.0\n",
      "Step 210 (304025) @ Episode 1207/10000, loss: 0.00148967874702066187\n",
      "Episode Reward: 1.0\n",
      "Step 308 (304333) @ Episode 1208/10000, loss: 0.00235394318588078026\n",
      "Episode Reward: 2.0\n",
      "Step 276 (304609) @ Episode 1209/10000, loss: 0.00099016027525067335\n",
      "Episode Reward: 2.0\n",
      "Step 239 (304848) @ Episode 1210/10000, loss: 0.00419221352785825785\n",
      "Episode Reward: 1.0\n",
      "Step 270 (305118) @ Episode 1211/10000, loss: 0.00117981375660747363\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 312 (305430) @ Episode 1212/10000, loss: 0.00069561396958306432\n",
      "Episode Reward: 3.0\n",
      "Step 429 (305859) @ Episode 1213/10000, loss: 0.00237885303795337686\n",
      "Episode Reward: 5.0\n",
      "Step 330 (306189) @ Episode 1214/10000, loss: 0.00072290340904146437\n",
      "Episode Reward: 3.0\n",
      "Step 386 (306575) @ Episode 1215/10000, loss: 0.00090843799989670526\n",
      "Episode Reward: 4.0\n",
      "Step 347 (306922) @ Episode 1216/10000, loss: 0.00338646583259105745\n",
      "Episode Reward: 4.0\n",
      "Step 554 (307476) @ Episode 1217/10000, loss: 0.00232275086455047136\n",
      "Episode Reward: 6.0\n",
      "Step 291 (307767) @ Episode 1218/10000, loss: 0.00081949168816208843\n",
      "Episode Reward: 2.0\n",
      "Step 284 (308051) @ Episode 1219/10000, loss: 0.00111488858237862597\n",
      "Episode Reward: 2.0\n",
      "Step 313 (308364) @ Episode 1220/10000, loss: 0.00079515855759382254\n",
      "Episode Reward: 2.0\n",
      "Step 548 (308912) @ Episode 1221/10000, loss: 0.00094724958762526517\n",
      "Episode Reward: 7.0\n",
      "Step 434 (309346) @ Episode 1222/10000, loss: 0.00093242042930796745\n",
      "Episode Reward: 5.0\n",
      "Step 305 (309651) @ Episode 1223/10000, loss: 0.00140943995211273434\n",
      "Episode Reward: 3.0\n",
      "Step 348 (309999) @ Episode 1224/10000, loss: 0.00302641699090669262\n",
      "Copied model parameters to target network.\n",
      "Step 359 (310010) @ Episode 1224/10000, loss: 0.0024847625754773617\n",
      "Episode Reward: 3.0\n",
      "Step 230 (310240) @ Episode 1225/10000, loss: 0.0011960950214415789\n",
      "Episode Reward: 1.0\n",
      "Step 220 (310460) @ Episode 1226/10000, loss: 0.0025815789122134447\n",
      "Episode Reward: 1.0\n",
      "Step 250 (310710) @ Episode 1227/10000, loss: 0.0012612948194146156\n",
      "Episode Reward: 1.0\n",
      "Step 241 (310951) @ Episode 1228/10000, loss: 0.0016743864398449662\n",
      "Episode Reward: 1.0\n",
      "Step 469 (311420) @ Episode 1229/10000, loss: 0.00096688763005658983\n",
      "Episode Reward: 5.0\n",
      "Step 336 (311756) @ Episode 1230/10000, loss: 0.00080562930088490253\n",
      "Episode Reward: 3.0\n",
      "Step 274 (312030) @ Episode 1231/10000, loss: 0.00108551757875829945\n",
      "Episode Reward: 2.0\n",
      "Step 404 (312434) @ Episode 1232/10000, loss: 0.00057975313393399124\n",
      "Episode Reward: 4.0\n",
      "Step 415 (312849) @ Episode 1233/10000, loss: 0.00185908190906047825\n",
      "Episode Reward: 5.0\n",
      "Step 379 (313228) @ Episode 1234/10000, loss: 0.00559506285935640336\n",
      "Episode Reward: 4.0\n",
      "Step 515 (313743) @ Episode 1235/10000, loss: 0.00217269756831228735\n",
      "Episode Reward: 6.0\n",
      "Step 311 (314054) @ Episode 1236/10000, loss: 0.00086786336032673726\n",
      "Episode Reward: 3.0\n",
      "Step 570 (314624) @ Episode 1237/10000, loss: 0.00037058681482449174\n",
      "Episode Reward: 10.0\n",
      "Step 292 (314916) @ Episode 1238/10000, loss: 0.0016470504924654968\n",
      "Episode Reward: 2.0\n",
      "Step 478 (315394) @ Episode 1239/10000, loss: 0.00268349912948906447\n",
      "Episode Reward: 5.0\n",
      "Step 227 (315621) @ Episode 1240/10000, loss: 0.00116969796363264326\n",
      "Episode Reward: 1.0\n",
      "Step 349 (315970) @ Episode 1241/10000, loss: 0.0030893255025148397\n",
      "Episode Reward: 3.0\n",
      "Step 202 (316172) @ Episode 1242/10000, loss: 0.00117791257798671724\n",
      "Episode Reward: 1.0\n",
      "Step 384 (316556) @ Episode 1243/10000, loss: 0.00103387050330638894\n",
      "Episode Reward: 4.0\n",
      "Step 275 (316831) @ Episode 1244/10000, loss: 0.00099047808907926086\n",
      "Episode Reward: 2.0\n",
      "Step 314 (317145) @ Episode 1245/10000, loss: 0.00551489740610122752\n",
      "Episode Reward: 3.0\n",
      "Step 220 (317365) @ Episode 1246/10000, loss: 0.0008377645281143486\n",
      "Episode Reward: 1.0\n",
      "Step 275 (317640) @ Episode 1247/10000, loss: 0.00380648369900882247\n",
      "Episode Reward: 2.0\n",
      "Step 274 (317914) @ Episode 1248/10000, loss: 0.00131637451704591513\n",
      "Episode Reward: 2.0\n",
      "Step 445 (318359) @ Episode 1249/10000, loss: 0.00341929635033011446\n",
      "Episode Reward: 5.0\n",
      "Step 167 (318526) @ Episode 1250/10000, loss: 0.0013198170345276594\n",
      "Episode Reward: 0.0\n",
      "Step 267 (318793) @ Episode 1251/10000, loss: 0.01168554462492466365\n",
      "Episode Reward: 2.0\n",
      "Step 536 (319329) @ Episode 1252/10000, loss: 0.00134466285817325125\n",
      "Episode Reward: 6.0\n",
      "Step 567 (319896) @ Episode 1253/10000, loss: 0.00441924063488841147\n",
      "Episode Reward: 7.0\n",
      "Step 103 (319999) @ Episode 1254/10000, loss: 0.00048450613394379616\n",
      "Copied model parameters to target network.\n",
      "Step 336 (320232) @ Episode 1254/10000, loss: 0.0016517890617251396\n",
      "Episode Reward: 2.0\n",
      "Step 247 (320479) @ Episode 1255/10000, loss: 0.0017922881525009875\n",
      "Episode Reward: 2.0\n",
      "Step 174 (320653) @ Episode 1256/10000, loss: 0.0057048113085329533\n",
      "Episode Reward: 0.0\n",
      "Step 268 (320921) @ Episode 1257/10000, loss: 0.0026430808939039707\n",
      "Episode Reward: 2.0\n",
      "Step 493 (321414) @ Episode 1258/10000, loss: 0.0024870608467608695\n",
      "Episode Reward: 6.0\n",
      "Step 390 (321804) @ Episode 1259/10000, loss: 0.0025884222704917192\n",
      "Episode Reward: 4.0\n",
      "Step 309 (322113) @ Episode 1260/10000, loss: 0.00182929600123316055\n",
      "Episode Reward: 2.0\n",
      "Step 393 (322506) @ Episode 1261/10000, loss: 0.0017610227223485708\n",
      "Episode Reward: 4.0\n",
      "Step 667 (323173) @ Episode 1262/10000, loss: 0.0048917271196842196\n",
      "Episode Reward: 7.0\n",
      "Step 375 (323548) @ Episode 1263/10000, loss: 0.00263595045544207167\n",
      "Episode Reward: 3.0\n",
      "Step 435 (323983) @ Episode 1264/10000, loss: 0.01275111455470323616\n",
      "Episode Reward: 5.0\n",
      "Step 353 (324336) @ Episode 1265/10000, loss: 0.0075158118270337587\n",
      "Episode Reward: 3.0\n",
      "Step 300 (324636) @ Episode 1266/10000, loss: 0.0018064699834212665\n",
      "Episode Reward: 2.0\n",
      "Step 457 (325093) @ Episode 1267/10000, loss: 0.00464064907282590954\n",
      "Episode Reward: 4.0\n",
      "Step 214 (325307) @ Episode 1268/10000, loss: 0.00175476656295359134\n",
      "Episode Reward: 1.0\n",
      "Step 298 (325605) @ Episode 1269/10000, loss: 0.00198319740593433486\n",
      "Episode Reward: 2.0\n",
      "Step 297 (325902) @ Episode 1270/10000, loss: 0.00257774116471409863\n",
      "Episode Reward: 2.0\n",
      "Step 597 (326499) @ Episode 1271/10000, loss: 0.00082700169878080496\n",
      "Episode Reward: 7.0\n",
      "Step 579 (327078) @ Episode 1272/10000, loss: 0.01061136461794376453\n",
      "Episode Reward: 6.0\n",
      "Step 224 (327302) @ Episode 1273/10000, loss: 0.0013022387865930796\n",
      "Episode Reward: 1.0\n",
      "Step 293 (327595) @ Episode 1274/10000, loss: 0.0018145391950383782\n",
      "Episode Reward: 3.0\n",
      "Step 374 (327969) @ Episode 1275/10000, loss: 0.0061777918599545956\n",
      "Episode Reward: 4.0\n",
      "Step 317 (328286) @ Episode 1276/10000, loss: 0.0026718478184193373\n",
      "Episode Reward: 3.0\n",
      "Step 562 (328848) @ Episode 1277/10000, loss: 0.0041607939638197425\n",
      "Episode Reward: 6.0\n",
      "Step 382 (329230) @ Episode 1278/10000, loss: 0.00093199254479259254\n",
      "Episode Reward: 4.0\n",
      "Step 297 (329527) @ Episode 1279/10000, loss: 0.00284024933353066446\n",
      "Episode Reward: 2.0\n",
      "Step 440 (329967) @ Episode 1280/10000, loss: 0.00142295437399297954\n",
      "Episode Reward: 4.0\n",
      "Step 32 (329999) @ Episode 1281/10000, loss: 0.0024334553163498645\n",
      "Copied model parameters to target network.\n",
      "Step 412 (330379) @ Episode 1281/10000, loss: 0.0059727923944592482\n",
      "Episode Reward: 4.0\n",
      "Step 210 (330589) @ Episode 1282/10000, loss: 0.0096750156953930856\n",
      "Episode Reward: 1.0\n",
      "Step 263 (330852) @ Episode 1283/10000, loss: 0.0019350370857864618\n",
      "Episode Reward: 2.0\n",
      "Step 294 (331146) @ Episode 1284/10000, loss: 0.0028007954824715853\n",
      "Episode Reward: 2.0\n",
      "Step 413 (331559) @ Episode 1285/10000, loss: 0.0010850386461243033\n",
      "Episode Reward: 4.0\n",
      "Step 623 (332182) @ Episode 1286/10000, loss: 0.00045023142592981464\n",
      "Episode Reward: 8.0\n",
      "Step 260 (332442) @ Episode 1287/10000, loss: 0.0067969723604619554\n",
      "Episode Reward: 2.0\n",
      "Step 545 (332987) @ Episode 1288/10000, loss: 0.0012518884614109993\n",
      "Episode Reward: 7.0\n",
      "Step 503 (333490) @ Episode 1289/10000, loss: 0.00061436760006472474\n",
      "Episode Reward: 6.0\n",
      "Step 296 (333786) @ Episode 1290/10000, loss: 0.0114613967016339307\n",
      "Episode Reward: 2.0\n",
      "Step 416 (334202) @ Episode 1291/10000, loss: 0.00137736019678413875\n",
      "Episode Reward: 5.0\n",
      "Step 278 (334480) @ Episode 1292/10000, loss: 0.0029159211553633213\n",
      "Episode Reward: 2.0\n",
      "Step 557 (335037) @ Episode 1293/10000, loss: 0.0017118563409894705\n",
      "Episode Reward: 6.0\n",
      "Step 343 (335380) @ Episode 1294/10000, loss: 0.0045368089340627192\n",
      "Episode Reward: 4.0\n",
      "Step 341 (335721) @ Episode 1295/10000, loss: 0.0005614763940684497\n",
      "Episode Reward: 4.0\n",
      "Step 468 (336189) @ Episode 1296/10000, loss: 0.00210796785540878777\n",
      "Episode Reward: 5.0\n",
      "Step 391 (336580) @ Episode 1297/10000, loss: 0.00621368363499641454\n",
      "Episode Reward: 4.0\n",
      "Step 439 (337019) @ Episode 1298/10000, loss: 0.00203613634221255876\n",
      "Episode Reward: 5.0\n",
      "Step 389 (337408) @ Episode 1299/10000, loss: 0.00195097608957439663\n",
      "Episode Reward: 4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 414 (337822) @ Episode 1300/10000, loss: 0.00119487708434462556\n",
      "Episode Reward: 3.0\n",
      "Step 368 (338190) @ Episode 1301/10000, loss: 0.00327220116741955344\n",
      "Episode Reward: 3.0\n",
      "Step 388 (338578) @ Episode 1302/10000, loss: 0.00185758690349757676\n",
      "Episode Reward: 4.0\n",
      "Step 367 (338945) @ Episode 1303/10000, loss: 0.00063016387866809964\n",
      "Episode Reward: 3.0\n",
      "Step 366 (339311) @ Episode 1304/10000, loss: 0.00179015786852687695\n",
      "Episode Reward: 4.0\n",
      "Step 217 (339528) @ Episode 1305/10000, loss: 0.00243457546457648287\n",
      "Episode Reward: 1.0\n",
      "Step 456 (339984) @ Episode 1306/10000, loss: 0.00213522021658718664\n",
      "Episode Reward: 6.0\n",
      "Step 15 (339999) @ Episode 1307/10000, loss: 0.0015721467789262533\n",
      "Copied model parameters to target network.\n",
      "Step 429 (340413) @ Episode 1307/10000, loss: 0.0041601005941629415\n",
      "Episode Reward: 7.0\n",
      "Step 427 (340840) @ Episode 1308/10000, loss: 0.0015791759360581636\n",
      "Episode Reward: 5.0\n",
      "Step 418 (341258) @ Episode 1309/10000, loss: 0.00200503086671233184\n",
      "Episode Reward: 5.0\n",
      "Step 559 (341817) @ Episode 1310/10000, loss: 0.00230374792590737346\n",
      "Episode Reward: 6.0\n",
      "Step 369 (342186) @ Episode 1311/10000, loss: 0.00442106137052178426\n",
      "Episode Reward: 3.0\n",
      "Step 559 (342745) @ Episode 1312/10000, loss: 0.00059444532962515955\n",
      "Episode Reward: 7.0\n",
      "Step 303 (343048) @ Episode 1313/10000, loss: 0.0013541670050472021\n",
      "Episode Reward: 2.0\n",
      "Step 513 (343561) @ Episode 1314/10000, loss: 0.00118065916467458156\n",
      "Episode Reward: 7.0\n",
      "Step 572 (344133) @ Episode 1315/10000, loss: 0.00241316296160221143\n",
      "Episode Reward: 7.0\n",
      "Step 353 (344486) @ Episode 1316/10000, loss: 0.0015109094092622468\n",
      "Episode Reward: 3.0\n",
      "Step 518 (345004) @ Episode 1317/10000, loss: 0.0051682889461517337\n",
      "Episode Reward: 6.0\n",
      "Step 555 (345559) @ Episode 1318/10000, loss: 0.00792135950177908144\n",
      "Episode Reward: 7.0\n",
      "Step 562 (346121) @ Episode 1319/10000, loss: 0.00124244880862534055\n",
      "Episode Reward: 6.0\n",
      "Step 260 (346381) @ Episode 1320/10000, loss: 0.0014637088170275092\n",
      "Episode Reward: 2.0\n",
      "Step 308 (346689) @ Episode 1321/10000, loss: 0.00220323121175169946\n",
      "Episode Reward: 3.0\n",
      "Step 467 (347156) @ Episode 1322/10000, loss: 0.00132542871870100534\n",
      "Episode Reward: 6.0\n",
      "Step 611 (347767) @ Episode 1323/10000, loss: 0.00133515044581145056\n",
      "Episode Reward: 11.0\n",
      "Step 348 (348115) @ Episode 1324/10000, loss: 0.0029165828600525856\n",
      "Episode Reward: 4.0\n",
      "Step 408 (348523) @ Episode 1325/10000, loss: 0.0014538372633978724\n",
      "Episode Reward: 5.0\n",
      "Step 387 (348910) @ Episode 1326/10000, loss: 0.0031768516637384898\n",
      "Episode Reward: 4.0\n",
      "Step 519 (349429) @ Episode 1327/10000, loss: 0.00467125605791807256\n",
      "Episode Reward: 9.0\n",
      "Step 488 (349917) @ Episode 1328/10000, loss: 0.0088730249553918847\n",
      "Episode Reward: 6.0\n",
      "Step 82 (349999) @ Episode 1329/10000, loss: 0.0064086480997502815\n",
      "Copied model parameters to target network.\n",
      "Step 426 (350343) @ Episode 1329/10000, loss: 0.0024643263313919306\n",
      "Episode Reward: 5.0\n",
      "Step 384 (350727) @ Episode 1330/10000, loss: 0.0022089839912950993\n",
      "Episode Reward: 3.0\n",
      "Step 746 (351473) @ Episode 1331/10000, loss: 0.0063381767831742766\n",
      "Episode Reward: 11.0\n",
      "Step 617 (352090) @ Episode 1332/10000, loss: 0.0038662112783640623\n",
      "Episode Reward: 7.0\n",
      "Step 417 (352507) @ Episode 1333/10000, loss: 0.0030455347150564194\n",
      "Episode Reward: 4.0\n",
      "Step 419 (352926) @ Episode 1334/10000, loss: 0.0027767512947320946\n",
      "Episode Reward: 4.0\n",
      "Step 530 (353456) @ Episode 1335/10000, loss: 0.0011917048832401633\n",
      "Episode Reward: 6.0\n",
      "Step 620 (354076) @ Episode 1336/10000, loss: 0.0019461188931018114\n",
      "Episode Reward: 9.0\n",
      "Step 504 (354580) @ Episode 1337/10000, loss: 0.0015077959978953004\n",
      "Episode Reward: 6.0\n",
      "Step 477 (355057) @ Episode 1338/10000, loss: 0.0024587155785411596\n",
      "Episode Reward: 5.0\n",
      "Step 534 (355591) @ Episode 1339/10000, loss: 0.0041048699058592328\n",
      "Episode Reward: 7.0\n",
      "Step 293 (355884) @ Episode 1340/10000, loss: 0.0047819679602980617\n",
      "Episode Reward: 2.0\n",
      "Step 461 (356345) @ Episode 1341/10000, loss: 0.0011990559287369251\n",
      "Episode Reward: 5.0\n",
      "Step 497 (356842) @ Episode 1342/10000, loss: 0.0062377038411796095\n",
      "Episode Reward: 6.0\n",
      "Step 366 (357208) @ Episode 1343/10000, loss: 0.0011138927657157183\n",
      "Episode Reward: 3.0\n",
      "Step 528 (357736) @ Episode 1344/10000, loss: 0.00857778824865818287\n",
      "Episode Reward: 6.0\n",
      "Step 458 (358194) @ Episode 1345/10000, loss: 0.0007058697519823909\n",
      "Episode Reward: 5.0\n",
      "Step 495 (358689) @ Episode 1346/10000, loss: 0.0104555459693074234\n",
      "Episode Reward: 6.0\n",
      "Step 365 (359054) @ Episode 1347/10000, loss: 0.0007830463582649827\n",
      "Episode Reward: 4.0\n",
      "Step 374 (359428) @ Episode 1348/10000, loss: 0.0018629108089953667\n",
      "Episode Reward: 4.0\n",
      "Step 571 (359999) @ Episode 1349/10000, loss: 0.0010794360423460603\n",
      "Copied model parameters to target network.\n",
      "Step 589 (360017) @ Episode 1349/10000, loss: 0.0025688153691589832\n",
      "Episode Reward: 8.0\n",
      "Step 394 (360411) @ Episode 1350/10000, loss: 0.0025008730590343475\n",
      "Episode Reward: 5.0\n",
      "Step 427 (360838) @ Episode 1351/10000, loss: 0.0048335930332541477\n",
      "Episode Reward: 4.0\n",
      "Step 327 (361165) @ Episode 1352/10000, loss: 0.0035681077279150486\n",
      "Episode Reward: 3.0\n",
      "Step 366 (361531) @ Episode 1353/10000, loss: 0.0042056194506585613\n",
      "Episode Reward: 4.0\n",
      "Step 333 (361864) @ Episode 1354/10000, loss: 0.0037994734011590484\n",
      "Episode Reward: 3.0\n",
      "Step 384 (362248) @ Episode 1355/10000, loss: 0.0020199816208332777\n",
      "Episode Reward: 5.0\n",
      "Step 393 (362641) @ Episode 1356/10000, loss: 0.0108978245407342918\n",
      "Episode Reward: 3.0\n",
      "Step 396 (363037) @ Episode 1357/10000, loss: 0.0032567710150033236\n",
      "Episode Reward: 5.0\n",
      "Step 519 (363556) @ Episode 1358/10000, loss: 0.0047248108312487625\n",
      "Episode Reward: 6.0\n",
      "Step 207 (363763) @ Episode 1359/10000, loss: 0.0024806414730846883\n",
      "Episode Reward: 1.0\n",
      "Step 529 (364292) @ Episode 1360/10000, loss: 0.0016226705629378557\n",
      "Episode Reward: 7.0\n",
      "Step 638 (364930) @ Episode 1361/10000, loss: 0.0037018680013716226\n",
      "Episode Reward: 9.0\n",
      "Step 420 (365350) @ Episode 1362/10000, loss: 0.0010442504426464438\n",
      "Episode Reward: 5.0\n",
      "Step 373 (365723) @ Episode 1363/10000, loss: 0.0110412538051605229\n",
      "Episode Reward: 4.0\n",
      "Step 510 (366233) @ Episode 1364/10000, loss: 0.0014756603632122278\n",
      "Episode Reward: 6.0\n",
      "Step 201 (366434) @ Episode 1365/10000, loss: 0.0010334259131923318\n",
      "Episode Reward: 1.0\n",
      "Step 612 (367046) @ Episode 1366/10000, loss: 0.0128407059237360954\n",
      "Episode Reward: 16.0\n",
      "Step 700 (367746) @ Episode 1367/10000, loss: 0.0027942652814090254\n",
      "Episode Reward: 8.0\n",
      "Step 458 (368204) @ Episode 1368/10000, loss: 0.00179893989115953456\n",
      "Episode Reward: 6.0\n",
      "Step 599 (368803) @ Episode 1369/10000, loss: 0.0023222540039569146\n",
      "Episode Reward: 8.0\n",
      "Step 406 (369209) @ Episode 1370/10000, loss: 0.0008972144569270313\n",
      "Episode Reward: 5.0\n",
      "Step 445 (369654) @ Episode 1371/10000, loss: 0.0012232617009431124\n",
      "Episode Reward: 5.0\n",
      "Step 345 (369999) @ Episode 1372/10000, loss: 0.0010232549393549562\n",
      "Copied model parameters to target network.\n",
      "Step 543 (370197) @ Episode 1372/10000, loss: 0.0027425519656389957\n",
      "Episode Reward: 7.0\n",
      "Step 430 (370627) @ Episode 1373/10000, loss: 0.0038822330534458164\n",
      "Episode Reward: 5.0\n",
      "Step 480 (371107) @ Episode 1374/10000, loss: 0.0067438585683703425\n",
      "Episode Reward: 6.0\n",
      "Step 394 (371501) @ Episode 1375/10000, loss: 0.0132559733465313912\n",
      "Episode Reward: 5.0\n",
      "Step 819 (372320) @ Episode 1376/10000, loss: 0.0024186079390347004\n",
      "Episode Reward: 13.0\n",
      "Step 464 (372784) @ Episode 1377/10000, loss: 0.0088254073634743693\n",
      "Episode Reward: 6.0\n",
      "Step 787 (373571) @ Episode 1378/10000, loss: 0.0013966510305181146\n",
      "Episode Reward: 13.0\n",
      "Step 527 (374098) @ Episode 1379/10000, loss: 0.0017761953640729193\n",
      "Episode Reward: 7.0\n",
      "Step 672 (374770) @ Episode 1380/10000, loss: 0.0024516123812645674\n",
      "Episode Reward: 9.0\n",
      "Step 510 (375280) @ Episode 1381/10000, loss: 0.0016211976762861013\n",
      "Episode Reward: 6.0\n",
      "Step 707 (375987) @ Episode 1382/10000, loss: 0.0022725663147866726\n",
      "Episode Reward: 11.0\n",
      "Step 452 (376439) @ Episode 1383/10000, loss: 0.0023942359257489443\n",
      "Episode Reward: 5.0\n",
      "Step 565 (377004) @ Episode 1384/10000, loss: 0.0021247719414532185\n",
      "Episode Reward: 6.0\n",
      "Step 429 (377433) @ Episode 1385/10000, loss: 0.0042911441996693612\n",
      "Episode Reward: 5.0\n",
      "Step 651 (378084) @ Episode 1386/10000, loss: 0.0020143969450145965\n",
      "Episode Reward: 16.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 469 (378553) @ Episode 1387/10000, loss: 0.0026032738387584686\n",
      "Episode Reward: 5.0\n",
      "Step 671 (379224) @ Episode 1388/10000, loss: 0.0053212093189358714\n",
      "Episode Reward: 9.0\n",
      "Step 411 (379635) @ Episode 1389/10000, loss: 0.0019756902474910024\n",
      "Episode Reward: 5.0\n",
      "Step 364 (379999) @ Episode 1390/10000, loss: 0.0015467565972357988\n",
      "Copied model parameters to target network.\n",
      "Step 572 (380207) @ Episode 1390/10000, loss: 0.0031689205206930637\n",
      "Episode Reward: 7.0\n",
      "Step 696 (380903) @ Episode 1391/10000, loss: 0.0025885389186441975\n",
      "Episode Reward: 11.0\n",
      "Step 252 (381155) @ Episode 1392/10000, loss: 0.0026996787637472153\n",
      "Episode Reward: 2.0\n",
      "Step 445 (381600) @ Episode 1393/10000, loss: 0.0038708273787051444\n",
      "Episode Reward: 6.0\n",
      "Step 547 (382147) @ Episode 1394/10000, loss: 0.0049079162999987657\n",
      "Episode Reward: 7.0\n",
      "Step 556 (382703) @ Episode 1395/10000, loss: 0.0015102063771337272\n",
      "Episode Reward: 7.0\n",
      "Step 717 (383420) @ Episode 1396/10000, loss: 0.0008341573411598802\n",
      "Episode Reward: 9.0\n",
      "Step 405 (383825) @ Episode 1397/10000, loss: 0.0016329627251252532\n",
      "Episode Reward: 6.0\n",
      "Step 679 (384504) @ Episode 1398/10000, loss: 0.0012875690590590239\n",
      "Episode Reward: 10.0\n",
      "Step 645 (385149) @ Episode 1399/10000, loss: 0.0010495879687368873\n",
      "Episode Reward: 8.0\n",
      "Step 559 (385708) @ Episode 1400/10000, loss: 0.00101648073177784684\n",
      "Episode Reward: 7.0\n",
      "Step 384 (386092) @ Episode 1401/10000, loss: 0.0057184235192835336\n",
      "Episode Reward: 4.0\n",
      "Step 369 (386461) @ Episode 1402/10000, loss: 0.0031608100980520251\n",
      "Episode Reward: 4.0\n",
      "Step 553 (387014) @ Episode 1403/10000, loss: 0.0017068765591830015\n",
      "Episode Reward: 7.0\n",
      "Step 429 (387443) @ Episode 1404/10000, loss: 0.0012965576024726033\n",
      "Episode Reward: 5.0\n",
      "Step 632 (388075) @ Episode 1405/10000, loss: 0.00113650388084352023\n",
      "Episode Reward: 8.0\n",
      "Step 479 (388554) @ Episode 1406/10000, loss: 0.00197691773064434537\n",
      "Episode Reward: 7.0\n",
      "Step 689 (389243) @ Episode 1407/10000, loss: 0.00782085023820400214\n",
      "Episode Reward: 10.0\n",
      "Step 668 (389911) @ Episode 1408/10000, loss: 0.00294535257853567663\n",
      "Episode Reward: 9.0\n",
      "Step 88 (389999) @ Episode 1409/10000, loss: 0.0017736181616783142\n",
      "Copied model parameters to target network.\n",
      "Step 465 (390376) @ Episode 1409/10000, loss: 0.0038467571139335632\n",
      "Episode Reward: 6.0\n",
      "Step 633 (391009) @ Episode 1410/10000, loss: 0.0060465335845947266\n",
      "Episode Reward: 10.0\n",
      "Step 619 (391628) @ Episode 1411/10000, loss: 0.00458931690081954574\n",
      "Episode Reward: 8.0\n",
      "Step 669 (392297) @ Episode 1412/10000, loss: 0.0016802481841295958\n",
      "Episode Reward: 12.0\n",
      "Step 865 (393162) @ Episode 1413/10000, loss: 0.0010936862090602517\n",
      "Episode Reward: 14.0\n",
      "Step 509 (393671) @ Episode 1414/10000, loss: 0.0026515233330428645\n",
      "Episode Reward: 6.0\n",
      "Step 603 (394274) @ Episode 1415/10000, loss: 0.0022741113789379597\n",
      "Episode Reward: 8.0\n",
      "Step 419 (394693) @ Episode 1416/10000, loss: 0.0032664402388036253\n",
      "Episode Reward: 4.0\n",
      "Step 551 (395244) @ Episode 1417/10000, loss: 0.0037022531032562256\n",
      "Episode Reward: 8.0\n",
      "Step 564 (395808) @ Episode 1418/10000, loss: 0.0046724402345716954\n",
      "Episode Reward: 7.0\n",
      "Step 655 (396463) @ Episode 1419/10000, loss: 0.0016995854675769806\n",
      "Episode Reward: 9.0\n",
      "Step 429 (396892) @ Episode 1420/10000, loss: 0.0015911204973235726\n",
      "Episode Reward: 6.0\n",
      "Step 519 (397411) @ Episode 1421/10000, loss: 0.0016970746219158173\n",
      "Episode Reward: 6.0\n",
      "Step 532 (397943) @ Episode 1422/10000, loss: 0.0016901977360248566\n",
      "Episode Reward: 8.0\n",
      "Step 587 (398530) @ Episode 1423/10000, loss: 0.0009716401109471917\n",
      "Episode Reward: 7.0\n",
      "Step 756 (399286) @ Episode 1424/10000, loss: 0.00190412509255111226\n",
      "Episode Reward: 13.0\n",
      "Step 713 (399999) @ Episode 1425/10000, loss: 0.0017099479446187615\n",
      "Copied model parameters to target network.\n",
      "Step 840 (400126) @ Episode 1425/10000, loss: 0.0196853186935186487\n",
      "Episode Reward: 15.0\n",
      "Step 950 (401076) @ Episode 1426/10000, loss: 0.0050125061534345157\n",
      "Episode Reward: 24.0\n",
      "Step 513 (401589) @ Episode 1427/10000, loss: 0.0061693610623478897\n",
      "Episode Reward: 8.0\n",
      "Step 582 (402171) @ Episode 1428/10000, loss: 0.0062854057177901277\n",
      "Episode Reward: 7.0\n",
      "Step 875 (403046) @ Episode 1429/10000, loss: 0.0056084925308823586\n",
      "Episode Reward: 22.0\n",
      "Step 776 (403822) @ Episode 1430/10000, loss: 0.0035006825346499685\n",
      "Episode Reward: 12.0\n",
      "Step 428 (404250) @ Episode 1431/10000, loss: 0.0058974479325115683\n",
      "Episode Reward: 6.0\n",
      "Step 573 (404823) @ Episode 1432/10000, loss: 0.0042710606940090665\n",
      "Episode Reward: 8.0\n",
      "Step 599 (405422) @ Episode 1433/10000, loss: 0.0044963634572923186\n",
      "Episode Reward: 10.0\n",
      "Step 712 (406134) @ Episode 1434/10000, loss: 0.0058727087453007798\n",
      "Episode Reward: 12.0\n",
      "Step 667 (406801) @ Episode 1435/10000, loss: 0.0029300262685865164\n",
      "Episode Reward: 17.0\n",
      "Step 1026 (407827) @ Episode 1436/10000, loss: 0.0071937507018446927\n",
      "Episode Reward: 18.0\n",
      "Step 617 (408444) @ Episode 1437/10000, loss: 0.0056923935189843182\n",
      "Episode Reward: 9.0\n",
      "Step 795 (409239) @ Episode 1438/10000, loss: 0.0024484586901962757\n",
      "Episode Reward: 16.0\n",
      "Step 613 (409852) @ Episode 1439/10000, loss: 0.00494181504473090236\n",
      "Episode Reward: 11.0\n",
      "Step 147 (409999) @ Episode 1440/10000, loss: 0.0043663261458277708\n",
      "Copied model parameters to target network.\n",
      "Step 649 (410501) @ Episode 1440/10000, loss: 0.0087496917694807055\n",
      "Episode Reward: 10.0\n",
      "Step 993 (411494) @ Episode 1441/10000, loss: 0.0024977095890790224\n",
      "Episode Reward: 20.0\n",
      "Step 702 (412196) @ Episode 1442/10000, loss: 0.0019056771416217089\n",
      "Episode Reward: 17.0\n",
      "Step 635 (412831) @ Episode 1443/10000, loss: 0.0038473464082926515\n",
      "Episode Reward: 10.0\n",
      "Step 759 (413590) @ Episode 1444/10000, loss: 0.0046865930780768394\n",
      "Episode Reward: 12.0\n",
      "Step 837 (414427) @ Episode 1445/10000, loss: 0.0030904531013220553\n",
      "Episode Reward: 19.0\n",
      "Step 750 (415177) @ Episode 1446/10000, loss: 0.00679124146699905474\n",
      "Episode Reward: 12.0\n",
      "Step 628 (415805) @ Episode 1447/10000, loss: 0.0014192592352628708\n",
      "Episode Reward: 8.0\n",
      "Step 654 (416459) @ Episode 1448/10000, loss: 0.00390524789690971375\n",
      "Episode Reward: 11.0\n",
      "Step 654 (417113) @ Episode 1449/10000, loss: 0.0013226740993559366\n",
      "Episode Reward: 13.0\n",
      "Step 783 (417896) @ Episode 1450/10000, loss: 0.0074701393023133282\n",
      "Episode Reward: 16.0\n",
      "Step 752 (418648) @ Episode 1451/10000, loss: 0.0215781014412641535\n",
      "Episode Reward: 14.0\n",
      "Step 742 (419390) @ Episode 1452/10000, loss: 0.00125130673404783443\n",
      "Episode Reward: 13.0\n",
      "Step 609 (419999) @ Episode 1453/10000, loss: 0.00157104223035275943\n",
      "Copied model parameters to target network.\n",
      "Step 771 (420161) @ Episode 1453/10000, loss: 0.0047798426821827894\n",
      "Episode Reward: 12.0\n",
      "Step 813 (420974) @ Episode 1454/10000, loss: 0.0017223109025508165\n",
      "Episode Reward: 17.0\n",
      "Step 734 (421708) @ Episode 1455/10000, loss: 0.0019267018651589751\n",
      "Episode Reward: 10.0\n",
      "Step 751 (422459) @ Episode 1456/10000, loss: 0.0073447860777378084\n",
      "Episode Reward: 15.0\n",
      "Step 869 (423328) @ Episode 1457/10000, loss: 0.0050699133425951288\n",
      "Episode Reward: 17.0\n",
      "Step 557 (423885) @ Episode 1458/10000, loss: 0.0014738633763045073\n",
      "Episode Reward: 8.0\n",
      "Step 743 (424628) @ Episode 1459/10000, loss: 0.0095722675323486336\n",
      "Episode Reward: 13.0\n",
      "Step 699 (425327) @ Episode 1460/10000, loss: 0.0010918611660599709\n",
      "Episode Reward: 14.0\n",
      "Step 633 (425960) @ Episode 1461/10000, loss: 0.0019549888093024492\n",
      "Episode Reward: 9.0\n",
      "Step 762 (426722) @ Episode 1462/10000, loss: 0.0035630036145448685\n",
      "Episode Reward: 11.0\n",
      "Step 1069 (427791) @ Episode 1463/10000, loss: 0.0052432748489081866\n",
      "Episode Reward: 19.0\n",
      "Step 593 (428384) @ Episode 1464/10000, loss: 0.0045014540664851665\n",
      "Episode Reward: 10.0\n",
      "Step 404 (428788) @ Episode 1465/10000, loss: 0.0015329342568293214\n",
      "Episode Reward: 5.0\n",
      "Step 584 (429372) @ Episode 1466/10000, loss: 0.0050437822937965393\n",
      "Episode Reward: 8.0\n",
      "Step 627 (429999) @ Episode 1467/10000, loss: 0.0015487574273720384\n",
      "Copied model parameters to target network.\n",
      "Step 1276 (430648) @ Episode 1467/10000, loss: 0.0015957538271322846\n",
      "Episode Reward: 28.0\n",
      "Step 674 (431322) @ Episode 1468/10000, loss: 0.0052079213783144953\n",
      "Episode Reward: 11.0\n",
      "Step 1219 (432541) @ Episode 1469/10000, loss: 0.0033028584439307454\n",
      "Episode Reward: 26.0\n",
      "Step 851 (433392) @ Episode 1470/10000, loss: 0.0189359076321125035\n",
      "Episode Reward: 13.0\n",
      "Step 906 (434298) @ Episode 1471/10000, loss: 0.0034625642001628876\n",
      "Episode Reward: 21.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 539 (434837) @ Episode 1472/10000, loss: 0.0098048290237784399\n",
      "Episode Reward: 6.0\n",
      "Step 846 (435683) @ Episode 1473/10000, loss: 0.0037377316039055586\n",
      "Episode Reward: 15.0\n",
      "Step 653 (436336) @ Episode 1474/10000, loss: 0.0025824371259659538\n",
      "Episode Reward: 10.0\n",
      "Step 902 (437238) @ Episode 1475/10000, loss: 0.0018755834316834807\n",
      "Episode Reward: 16.0\n",
      "Step 768 (438006) @ Episode 1476/10000, loss: 0.0021384425926953554\n",
      "Episode Reward: 15.0\n",
      "Step 909 (438915) @ Episode 1477/10000, loss: 0.0010404956992715597\n",
      "Episode Reward: 23.0\n",
      "Step 1069 (439984) @ Episode 1478/10000, loss: 0.0023577921092510223\n",
      "Episode Reward: 24.0\n",
      "Step 15 (439999) @ Episode 1479/10000, loss: 0.0040820525027811535\n",
      "Copied model parameters to target network.\n",
      "Step 919 (440903) @ Episode 1479/10000, loss: 0.0049704797565937048\n",
      "Episode Reward: 22.0\n",
      "Step 619 (441522) @ Episode 1480/10000, loss: 0.0065918201580643653\n",
      "Episode Reward: 8.0\n",
      "Step 895 (442417) @ Episode 1481/10000, loss: 0.0026228050701320175\n",
      "Episode Reward: 18.0\n",
      "Step 917 (443334) @ Episode 1482/10000, loss: 0.00504386797547340443\n",
      "Episode Reward: 17.0\n",
      "Step 710 (444044) @ Episode 1483/10000, loss: 0.0042737601324915898\n",
      "Episode Reward: 11.0\n",
      "Step 743 (444787) @ Episode 1484/10000, loss: 0.0076806792058050636\n",
      "Episode Reward: 17.0\n",
      "Step 1126 (445913) @ Episode 1485/10000, loss: 0.0034811117220669985\n",
      "Episode Reward: 24.0\n",
      "Step 941 (446854) @ Episode 1486/10000, loss: 0.00333358487114310267\n",
      "Episode Reward: 15.0\n",
      "Step 973 (447827) @ Episode 1487/10000, loss: 0.0005095185479149222\n",
      "Episode Reward: 17.0\n",
      "Step 624 (448451) @ Episode 1488/10000, loss: 0.0203726161271333775\n",
      "Episode Reward: 13.0\n",
      "Step 1193 (449644) @ Episode 1489/10000, loss: 0.0083087058737874034\n",
      "Episode Reward: 34.0\n",
      "Step 355 (449999) @ Episode 1490/10000, loss: 0.0077611072920262813\n",
      "Copied model parameters to target network.\n",
      "Step 799 (450443) @ Episode 1490/10000, loss: 0.0034304982982575893\n",
      "Episode Reward: 13.0\n",
      "Step 768 (451211) @ Episode 1491/10000, loss: 0.0031823248136788607\n",
      "Episode Reward: 14.0\n",
      "Step 869 (452080) @ Episode 1492/10000, loss: 0.0072984350845217705\n",
      "Episode Reward: 12.0\n",
      "Step 1061 (453141) @ Episode 1493/10000, loss: 0.0028821015730500224\n",
      "Episode Reward: 32.0\n",
      "Step 707 (453848) @ Episode 1494/10000, loss: 0.0013704604934901558\n",
      "Episode Reward: 12.0\n",
      "Step 1124 (454972) @ Episode 1495/10000, loss: 0.0194599088281393057\n",
      "Episode Reward: 23.0\n",
      "Step 647 (455619) @ Episode 1496/10000, loss: 0.0026397504843771458\n",
      "Episode Reward: 10.0\n",
      "Step 755 (456374) @ Episode 1497/10000, loss: 0.0056625972501933575\n",
      "Episode Reward: 16.0\n",
      "Step 968 (457342) @ Episode 1498/10000, loss: 0.0102061266079545028\n",
      "Episode Reward: 18.0\n",
      "Step 1239 (458581) @ Episode 1499/10000, loss: 0.0013874110300093893\n",
      "Episode Reward: 33.0\n",
      "Step 924 (459505) @ Episode 1500/10000, loss: 0.0016780750593170524\n",
      "Episode Reward: 19.0\n",
      "Step 494 (459999) @ Episode 1501/10000, loss: 0.0022586691193282604\n",
      "Copied model parameters to target network.\n",
      "Step 811 (460316) @ Episode 1501/10000, loss: 0.0031030394602566957\n",
      "Episode Reward: 13.0\n",
      "Step 1061 (461377) @ Episode 1502/10000, loss: 0.0038864351809024818\n",
      "Episode Reward: 22.0\n",
      "Step 743 (462120) @ Episode 1503/10000, loss: 0.0031713109929114585\n",
      "Episode Reward: 15.0\n",
      "Step 734 (462854) @ Episode 1504/10000, loss: 0.0021032455842942062\n",
      "Episode Reward: 12.0\n",
      "Step 857 (463711) @ Episode 1505/10000, loss: 0.0060446714051067837\n",
      "Episode Reward: 13.0\n",
      "Step 676 (464387) @ Episode 1506/10000, loss: 0.0019290506606921554\n",
      "Episode Reward: 12.0\n",
      "Step 1125 (465512) @ Episode 1507/10000, loss: 0.0020085866563022137\n",
      "Episode Reward: 25.0\n",
      "Step 746 (466258) @ Episode 1508/10000, loss: 0.0031342846341431142\n",
      "Episode Reward: 16.0\n",
      "Step 1258 (467516) @ Episode 1509/10000, loss: 0.0042963773012161255\n",
      "Episode Reward: 28.0\n",
      "Step 1019 (468535) @ Episode 1510/10000, loss: 0.0014276455622166395\n",
      "Episode Reward: 16.0\n",
      "Step 710 (469245) @ Episode 1511/10000, loss: 0.0038274056278169155\n",
      "Episode Reward: 12.0\n",
      "Step 754 (469999) @ Episode 1512/10000, loss: 0.0024084220640361312\n",
      "Copied model parameters to target network.\n",
      "Step 1177 (470422) @ Episode 1512/10000, loss: 0.0017417464405298233\n",
      "Episode Reward: 21.0\n",
      "Step 765 (471187) @ Episode 1513/10000, loss: 0.0075738541781902313\n",
      "Episode Reward: 13.0\n",
      "Step 912 (472099) @ Episode 1514/10000, loss: 0.0077633173204958448\n",
      "Episode Reward: 23.0\n",
      "Step 1066 (473165) @ Episode 1515/10000, loss: 0.0087141776457428936\n",
      "Episode Reward: 26.0\n",
      "Step 1062 (474227) @ Episode 1516/10000, loss: 0.0014242901233956218\n",
      "Episode Reward: 22.0\n",
      "Step 793 (475020) @ Episode 1517/10000, loss: 0.0020747832022607327\n",
      "Episode Reward: 13.0\n",
      "Step 1195 (476215) @ Episode 1518/10000, loss: 0.0029600644484162334\n",
      "Episode Reward: 28.0\n",
      "Step 1029 (477244) @ Episode 1519/10000, loss: 0.0008468696614727378\n",
      "Episode Reward: 22.0\n",
      "Step 1112 (478356) @ Episode 1520/10000, loss: 0.0030947537161409855\n",
      "Episode Reward: 24.0\n",
      "Step 1160 (479516) @ Episode 1521/10000, loss: 0.0027034147642552853\n",
      "Episode Reward: 25.0\n",
      "Step 483 (479999) @ Episode 1522/10000, loss: 0.00402657967060804456\n",
      "Copied model parameters to target network.\n",
      "Step 832 (480348) @ Episode 1522/10000, loss: 0.0020574650261551145\n",
      "Episode Reward: 16.0\n",
      "Step 1708 (482056) @ Episode 1523/10000, loss: 0.0019189898157492283\n",
      "Episode Reward: 49.0\n",
      "Step 1347 (483403) @ Episode 1524/10000, loss: 0.0083242170512676243\n",
      "Episode Reward: 37.0\n",
      "Step 784 (484187) @ Episode 1525/10000, loss: 0.0037085688672959805\n",
      "Episode Reward: 16.0\n",
      "Step 882 (485069) @ Episode 1526/10000, loss: 0.0026766012888401747\n",
      "Episode Reward: 15.0\n",
      "Step 741 (485810) @ Episode 1527/10000, loss: 0.0019834623672068124\n",
      "Episode Reward: 14.0\n",
      "Step 955 (486765) @ Episode 1528/10000, loss: 0.0025401560124009848\n",
      "Episode Reward: 23.0\n",
      "Step 779 (487544) @ Episode 1529/10000, loss: 0.0098837483674287868\n",
      "Episode Reward: 14.0\n",
      "Step 955 (488499) @ Episode 1530/10000, loss: 0.0030173885170370346\n",
      "Episode Reward: 26.0\n",
      "Step 1050 (489549) @ Episode 1531/10000, loss: 0.0018452263902872869\n",
      "Episode Reward: 19.0\n",
      "Step 450 (489999) @ Episode 1532/10000, loss: 0.0027915334794670343\n",
      "Copied model parameters to target network.\n",
      "Step 1179 (490728) @ Episode 1532/10000, loss: 0.0047606243751943113\n",
      "Episode Reward: 35.0\n",
      "Step 1104 (491832) @ Episode 1533/10000, loss: 0.0054906145669519974\n",
      "Episode Reward: 23.0\n",
      "Step 908 (492740) @ Episode 1534/10000, loss: 0.0014073558850213885\n",
      "Episode Reward: 19.0\n",
      "Step 759 (493499) @ Episode 1535/10000, loss: 0.0024860533885657787\n",
      "Episode Reward: 12.0\n",
      "Step 1521 (495020) @ Episode 1536/10000, loss: 0.0027247006073594093\n",
      "Episode Reward: 55.0\n",
      "Step 1459 (496479) @ Episode 1537/10000, loss: 0.0030072457157075405\n",
      "Episode Reward: 30.0\n",
      "Step 1228 (497707) @ Episode 1538/10000, loss: 0.0056780413724482064\n",
      "Episode Reward: 37.0\n",
      "Step 772 (498479) @ Episode 1539/10000, loss: 0.0013480596244335175\n",
      "Episode Reward: 14.0\n",
      "Step 974 (499453) @ Episode 1540/10000, loss: 0.0021685701794922357\n",
      "Episode Reward: 15.0\n",
      "Step 546 (499999) @ Episode 1541/10000, loss: 0.0013431056868284943\n",
      "Copied model parameters to target network.\n",
      "Step 974 (500427) @ Episode 1541/10000, loss: 0.0092692347243428235\n",
      "Episode Reward: 21.0\n",
      "Step 1112 (501539) @ Episode 1542/10000, loss: 0.0051943054422736174\n",
      "Episode Reward: 21.0\n",
      "Step 995 (502534) @ Episode 1543/10000, loss: 0.0024855514056980619\n",
      "Episode Reward: 23.0\n",
      "Step 873 (503407) @ Episode 1544/10000, loss: 0.0015446436591446413\n",
      "Episode Reward: 22.0\n",
      "Step 743 (504150) @ Episode 1545/10000, loss: 0.0021254527382552624\n",
      "Episode Reward: 18.0\n",
      "Step 1058 (505208) @ Episode 1546/10000, loss: 0.0026364321820437913\n",
      "Episode Reward: 27.0\n",
      "Step 1206 (506414) @ Episode 1547/10000, loss: 0.0042852791957557237\n",
      "Episode Reward: 21.0\n",
      "Step 859 (507273) @ Episode 1548/10000, loss: 0.0016416402067989115\n",
      "Episode Reward: 14.0\n",
      "Step 852 (508125) @ Episode 1549/10000, loss: 0.0039122058078646666\n",
      "Episode Reward: 24.0\n",
      "Step 732 (508857) @ Episode 1550/10000, loss: 0.0019201233517378569\n",
      "Episode Reward: 12.0\n",
      "Step 1142 (509999) @ Episode 1551/10000, loss: 0.0071845627389848239\n",
      "Copied model parameters to target network.\n",
      "Step 1177 (510034) @ Episode 1551/10000, loss: 0.0113589940592646675\n",
      "Episode Reward: 28.0\n",
      "Step 829 (510863) @ Episode 1552/10000, loss: 0.0026284239720553166\n",
      "Episode Reward: 14.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1289 (512152) @ Episode 1553/10000, loss: 0.0163921434432268147\n",
      "Episode Reward: 28.0\n",
      "Step 758 (512910) @ Episode 1554/10000, loss: 0.0038616999518126254\n",
      "Episode Reward: 13.0\n",
      "Step 911 (513821) @ Episode 1555/10000, loss: 0.0429050140082836155\n",
      "Episode Reward: 19.0\n",
      "Step 970 (514791) @ Episode 1556/10000, loss: 0.0032555747311562369\n",
      "Episode Reward: 21.0\n",
      "Step 609 (515400) @ Episode 1557/10000, loss: 0.0079911351203918465\n",
      "Episode Reward: 10.0\n",
      "Step 818 (516218) @ Episode 1558/10000, loss: 0.0226886235177516943\n",
      "Episode Reward: 13.0\n",
      "Step 1134 (517352) @ Episode 1559/10000, loss: 0.0044300416484475145\n",
      "Episode Reward: 21.0\n",
      "Step 1349 (518701) @ Episode 1560/10000, loss: 0.0027144760824739933\n",
      "Episode Reward: 29.0\n",
      "Step 1298 (519999) @ Episode 1561/10000, loss: 0.0026489978190511465\n",
      "Copied model parameters to target network.\n",
      "Step 1416 (520117) @ Episode 1561/10000, loss: 0.0016831562388688326\n",
      "Episode Reward: 42.0\n",
      "Step 981 (521098) @ Episode 1562/10000, loss: 0.0038303553592413664\n",
      "Episode Reward: 20.0\n",
      "Step 961 (522059) @ Episode 1563/10000, loss: 0.0050226640887558468\n",
      "Episode Reward: 20.0\n",
      "Step 1086 (523145) @ Episode 1564/10000, loss: 0.0038915737532079224\n",
      "Episode Reward: 20.0\n",
      "Step 1215 (524360) @ Episode 1565/10000, loss: 0.0021814063657075167\n",
      "Episode Reward: 29.0\n",
      "Step 1191 (525551) @ Episode 1566/10000, loss: 0.0047227675095200545\n",
      "Episode Reward: 24.0\n",
      "Step 931 (526482) @ Episode 1567/10000, loss: 0.0065693869255483156\n",
      "Episode Reward: 22.0\n",
      "Step 1105 (527587) @ Episode 1568/10000, loss: 0.0176498182117939859\n",
      "Episode Reward: 21.0\n",
      "Step 727 (528314) @ Episode 1569/10000, loss: 0.01753876544535169166\n",
      "Episode Reward: 11.0\n",
      "Step 1114 (529428) @ Episode 1570/10000, loss: 0.0022212429903447633\n",
      "Episode Reward: 27.0\n",
      "Step 571 (529999) @ Episode 1571/10000, loss: 0.0039061226416379213\n",
      "Copied model parameters to target network.\n",
      "Step 808 (530236) @ Episode 1571/10000, loss: 0.0021527027711272247\n",
      "Episode Reward: 18.0\n",
      "Step 767 (531003) @ Episode 1572/10000, loss: 0.0119557324796915057\n",
      "Episode Reward: 18.0\n",
      "Step 560 (531563) @ Episode 1573/10000, loss: 0.0007690096972510219\n",
      "Episode Reward: 9.0\n",
      "Step 999 (532562) @ Episode 1574/10000, loss: 0.0087694395333528528\n",
      "Episode Reward: 22.0\n",
      "Step 1379 (533941) @ Episode 1575/10000, loss: 0.0041390475817024717\n",
      "Episode Reward: 31.0\n",
      "Step 1016 (534957) @ Episode 1576/10000, loss: 0.0064116856083273895\n",
      "Episode Reward: 17.0\n",
      "Step 1041 (535998) @ Episode 1577/10000, loss: 0.0054380614310503012\n",
      "Episode Reward: 23.0\n",
      "Step 1381 (537379) @ Episode 1578/10000, loss: 0.0017445223638787866\n",
      "Episode Reward: 32.0\n",
      "Step 984 (538363) @ Episode 1579/10000, loss: 0.0060569671913981445\n",
      "Episode Reward: 21.0\n",
      "Step 797 (539160) @ Episode 1580/10000, loss: 0.0036848026793450117\n",
      "Episode Reward: 12.0\n",
      "Step 780 (539940) @ Episode 1581/10000, loss: 0.0030466006137430675\n",
      "Episode Reward: 26.0\n",
      "Step 59 (539999) @ Episode 1582/10000, loss: 0.0116965407505631456\n",
      "Copied model parameters to target network.\n",
      "Step 1123 (541063) @ Episode 1582/10000, loss: 0.0018186724046245217\n",
      "Episode Reward: 28.0\n",
      "Step 1079 (542142) @ Episode 1583/10000, loss: 0.0016115440521389246\n",
      "Episode Reward: 23.0\n",
      "Step 912 (543054) @ Episode 1584/10000, loss: 0.00356912659481167864\n",
      "Episode Reward: 20.0\n",
      "Step 937 (543991) @ Episode 1585/10000, loss: 0.0046948222443461426\n",
      "Episode Reward: 15.0\n",
      "Step 1307 (545298) @ Episode 1586/10000, loss: 0.0020934343338012695\n",
      "Episode Reward: 31.0\n",
      "Step 1455 (546753) @ Episode 1587/10000, loss: 0.0065132887102663524\n",
      "Episode Reward: 38.0\n",
      "Step 923 (547676) @ Episode 1588/10000, loss: 0.0009134915890172124\n",
      "Episode Reward: 21.0\n",
      "Step 1621 (549297) @ Episode 1589/10000, loss: 0.0063386550173163414\n",
      "Episode Reward: 47.0\n",
      "Step 702 (549999) @ Episode 1590/10000, loss: 0.0094549451023340235\n",
      "Copied model parameters to target network.\n",
      "Step 1102 (550399) @ Episode 1590/10000, loss: 0.0030508465133607388\n",
      "Episode Reward: 26.0\n",
      "Step 915 (551314) @ Episode 1591/10000, loss: 0.0025452417321503162\n",
      "Episode Reward: 16.0\n",
      "Step 884 (552198) @ Episode 1592/10000, loss: 0.0059537962079048166\n",
      "Episode Reward: 21.0\n",
      "Step 1018 (553216) @ Episode 1593/10000, loss: 0.0036393583286553623\n",
      "Episode Reward: 30.0\n",
      "Step 1607 (554823) @ Episode 1594/10000, loss: 0.0104656033217906955\n",
      "Episode Reward: 38.0\n",
      "Step 1119 (555942) @ Episode 1595/10000, loss: 0.0019370239460840821\n",
      "Episode Reward: 20.0\n",
      "Step 1268 (557210) @ Episode 1596/10000, loss: 0.0061042099259793762\n",
      "Episode Reward: 30.0\n",
      "Step 1222 (558432) @ Episode 1597/10000, loss: 0.0043723559938371182\n",
      "Episode Reward: 30.0\n",
      "Step 990 (559422) @ Episode 1598/10000, loss: 0.1590396910905838413\n",
      "Episode Reward: 17.0\n",
      "Step 577 (559999) @ Episode 1599/10000, loss: 0.0033171456307172775\n",
      "Copied model parameters to target network.\n",
      "Step 1629 (561051) @ Episode 1599/10000, loss: 0.0278503652662038881\n",
      "Episode Reward: 42.0\n",
      "Step 1031 (562082) @ Episode 1600/10000, loss: 0.0122184362262487413\n",
      "Episode Reward: 28.0\n",
      "Step 1497 (563579) @ Episode 1601/10000, loss: 0.0015188840916380286\n",
      "Episode Reward: 41.0\n",
      "Step 1143 (564722) @ Episode 1602/10000, loss: 0.0118428915739059458\n",
      "Episode Reward: 28.0\n",
      "Step 1095 (565817) @ Episode 1603/10000, loss: 0.0022909312974661595\n",
      "Episode Reward: 28.0\n",
      "Step 843 (566660) @ Episode 1604/10000, loss: 0.0007002119673416018\n",
      "Episode Reward: 13.0\n",
      "Step 1368 (568028) @ Episode 1605/10000, loss: 0.0015874460805207496\n",
      "Episode Reward: 43.0\n",
      "Step 1237 (569265) @ Episode 1606/10000, loss: 0.0017807116964831948\n",
      "Episode Reward: 36.0\n",
      "Step 734 (569999) @ Episode 1607/10000, loss: 0.0034974273294210434\n",
      "Copied model parameters to target network.\n",
      "Step 1312 (570577) @ Episode 1607/10000, loss: 0.0016807252541184425\n",
      "Episode Reward: 27.0\n",
      "Step 1340 (571917) @ Episode 1608/10000, loss: 0.0279130749404430476\n",
      "Episode Reward: 27.0\n",
      "Step 739 (572656) @ Episode 1609/10000, loss: 0.0009746025316417217\n",
      "Episode Reward: 13.0\n",
      "Step 886 (573542) @ Episode 1610/10000, loss: 0.0012301078531891108\n",
      "Episode Reward: 20.0\n",
      "Step 808 (574350) @ Episode 1611/10000, loss: 0.0035265230108052494\n",
      "Episode Reward: 13.0\n",
      "Step 795 (575145) @ Episode 1612/10000, loss: 0.00254644220694899564\n",
      "Episode Reward: 15.0\n",
      "Step 988 (576133) @ Episode 1613/10000, loss: 0.0019149951403960586\n",
      "Episode Reward: 24.0\n",
      "Step 1162 (577295) @ Episode 1614/10000, loss: 0.0016586665296927094\n",
      "Episode Reward: 21.0\n",
      "Step 831 (578126) @ Episode 1615/10000, loss: 0.0018743291730061173\n",
      "Episode Reward: 16.0\n",
      "Step 1408 (579534) @ Episode 1616/10000, loss: 0.0012268271530047064\n",
      "Episode Reward: 27.0\n",
      "Step 465 (579999) @ Episode 1617/10000, loss: 0.0025277840904891496\n",
      "Copied model parameters to target network.\n",
      "Step 1091 (580625) @ Episode 1617/10000, loss: 0.0042165815830230715\n",
      "Episode Reward: 27.0\n",
      "Step 635 (581260) @ Episode 1618/10000, loss: 0.0062036672607064259\n",
      "Episode Reward: 11.0\n",
      "Step 1137 (582397) @ Episode 1619/10000, loss: 0.0027828514575958259\n",
      "Episode Reward: 28.0\n",
      "Step 879 (583276) @ Episode 1620/10000, loss: 0.0037682671099901292\n",
      "Episode Reward: 19.0\n",
      "Step 1257 (584533) @ Episode 1621/10000, loss: 0.0021755392663180837\n",
      "Episode Reward: 34.0\n",
      "Step 1498 (586031) @ Episode 1622/10000, loss: 0.0042241360060870656\n",
      "Episode Reward: 33.0\n",
      "Step 1189 (587220) @ Episode 1623/10000, loss: 0.0019086140673607588\n",
      "Episode Reward: 27.0\n",
      "Step 983 (588203) @ Episode 1624/10000, loss: 0.0049200034700334079\n",
      "Episode Reward: 21.0\n",
      "Step 660 (588863) @ Episode 1625/10000, loss: 0.0019272251520305872\n",
      "Episode Reward: 21.0\n",
      "Step 883 (589746) @ Episode 1626/10000, loss: 0.0037897329311817884\n",
      "Episode Reward: 16.0\n",
      "Step 253 (589999) @ Episode 1627/10000, loss: 0.0066303806379437459\n",
      "Copied model parameters to target network.\n",
      "Step 792 (590538) @ Episode 1627/10000, loss: 0.0047819064930081374\n",
      "Episode Reward: 14.0\n",
      "Step 1020 (591558) @ Episode 1628/10000, loss: 0.0179683342576026967\n",
      "Episode Reward: 21.0\n",
      "Step 1791 (593349) @ Episode 1629/10000, loss: 0.0015289912698790433\n",
      "Episode Reward: 49.0\n",
      "Step 456 (593805) @ Episode 1630/10000, loss: 0.0015292569296434522\n",
      "Episode Reward: 7.0\n",
      "Step 806 (594611) @ Episode 1631/10000, loss: 0.0019992874003946783\n",
      "Episode Reward: 21.0\n",
      "Step 1046 (595657) @ Episode 1632/10000, loss: 0.0011058013187721372\n",
      "Episode Reward: 18.0\n",
      "Step 1074 (596731) @ Episode 1633/10000, loss: 0.0022758792620152235\n",
      "Episode Reward: 22.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 682 (597413) @ Episode 1634/10000, loss: 0.0019221814582124352\n",
      "Episode Reward: 12.0\n",
      "Step 657 (598070) @ Episode 1635/10000, loss: 0.0014899758389219642\n",
      "Episode Reward: 10.0\n",
      "Step 1247 (599317) @ Episode 1636/10000, loss: 0.00247520324774086485\n",
      "Episode Reward: 26.0\n",
      "Step 682 (599999) @ Episode 1637/10000, loss: 0.0019767540507018566\n",
      "Copied model parameters to target network.\n",
      "Step 1122 (600439) @ Episode 1637/10000, loss: 0.0036877698730677366\n",
      "Episode Reward: 19.0\n",
      "Step 1155 (601594) @ Episode 1638/10000, loss: 0.0070819430984556675\n",
      "Episode Reward: 23.0\n",
      "Step 1036 (602630) @ Episode 1639/10000, loss: 0.0016788436332717538\n",
      "Episode Reward: 18.0\n",
      "Step 1508 (604138) @ Episode 1640/10000, loss: 0.0027695633471012115\n",
      "Episode Reward: 34.0\n",
      "Step 1027 (605165) @ Episode 1641/10000, loss: 0.0017302155029028654\n",
      "Episode Reward: 18.0\n",
      "Step 1046 (606211) @ Episode 1642/10000, loss: 0.0084883514791727079\n",
      "Episode Reward: 17.0\n",
      "Step 1379 (607590) @ Episode 1643/10000, loss: 0.0022408491931855687\n",
      "Episode Reward: 41.0\n",
      "Step 664 (608254) @ Episode 1644/10000, loss: 0.0032843598164618015\n",
      "Episode Reward: 11.0\n",
      "Step 951 (609205) @ Episode 1645/10000, loss: 0.0023691956885159016\n",
      "Episode Reward: 20.0\n",
      "Step 794 (609999) @ Episode 1646/10000, loss: 0.0047332798130810266\n",
      "Copied model parameters to target network.\n",
      "Step 1246 (610451) @ Episode 1646/10000, loss: 0.0052795168012380644\n",
      "Episode Reward: 29.0\n",
      "Step 922 (611373) @ Episode 1647/10000, loss: 0.0018661834765225649\n",
      "Episode Reward: 17.0\n",
      "Step 1831 (613204) @ Episode 1648/10000, loss: 0.0018878137925639749\n",
      "Episode Reward: 55.0\n",
      "Step 704 (613908) @ Episode 1649/10000, loss: 0.0040814578533172617\n",
      "Episode Reward: 15.0\n",
      "Step 849 (614757) @ Episode 1650/10000, loss: 0.0033490494824945927\n",
      "Episode Reward: 18.0\n",
      "Step 798 (615555) @ Episode 1651/10000, loss: 0.0014024123083800077\n",
      "Episode Reward: 14.0\n",
      "Step 1190 (616745) @ Episode 1652/10000, loss: 0.0049757347442209727\n",
      "Episode Reward: 27.0\n",
      "Step 1393 (618138) @ Episode 1653/10000, loss: 0.0016632045153528452\n",
      "Episode Reward: 24.0\n",
      "Step 772 (618910) @ Episode 1654/10000, loss: 0.0011642901226878166\n",
      "Episode Reward: 13.0\n",
      "Step 960 (619870) @ Episode 1655/10000, loss: 0.0732277184724807753\n",
      "Episode Reward: 17.0\n",
      "Step 129 (619999) @ Episode 1656/10000, loss: 0.0021474030800163746\n",
      "Copied model parameters to target network.\n",
      "Step 885 (620755) @ Episode 1656/10000, loss: 0.0035881549119949346\n",
      "Episode Reward: 22.0\n",
      "Step 860 (621615) @ Episode 1657/10000, loss: 0.0041040242649614814\n",
      "Episode Reward: 16.0\n",
      "Step 1043 (622658) @ Episode 1658/10000, loss: 0.0045054694637656214\n",
      "Episode Reward: 24.0\n",
      "Step 1184 (623842) @ Episode 1659/10000, loss: 0.0013150029117241502\n",
      "Episode Reward: 23.0\n",
      "Step 1246 (625088) @ Episode 1660/10000, loss: 0.0034915586002171046\n",
      "Episode Reward: 28.0\n",
      "Step 780 (625868) @ Episode 1661/10000, loss: 0.0031691566109657288\n",
      "Episode Reward: 13.0\n",
      "Step 1297 (627165) @ Episode 1662/10000, loss: 0.0011047220323234797\n",
      "Episode Reward: 23.0\n",
      "Step 1428 (628593) @ Episode 1663/10000, loss: 0.0035118772648274983\n",
      "Episode Reward: 35.0\n",
      "Step 1035 (629628) @ Episode 1664/10000, loss: 0.0033125698100775485\n",
      "Episode Reward: 27.0\n",
      "Step 371 (629999) @ Episode 1665/10000, loss: 0.0013361962046474218\n",
      "Copied model parameters to target network.\n",
      "Step 1025 (630653) @ Episode 1665/10000, loss: 0.0042728194966912274\n",
      "Episode Reward: 24.0\n",
      "Step 733 (631386) @ Episode 1666/10000, loss: 0.0032372116111218934\n",
      "Episode Reward: 16.0\n",
      "Step 1237 (632623) @ Episode 1667/10000, loss: 0.0025831128004938364\n",
      "Episode Reward: 43.0\n",
      "Step 1123 (633746) @ Episode 1668/10000, loss: 0.0031190260779112577\n",
      "Episode Reward: 21.0\n",
      "Step 785 (634531) @ Episode 1669/10000, loss: 0.0009444871684536338\n",
      "Episode Reward: 15.0\n",
      "Step 652 (635183) @ Episode 1670/10000, loss: 0.0052777947857975966\n",
      "Episode Reward: 11.0\n",
      "Step 1064 (636247) @ Episode 1671/10000, loss: 0.0045772828161716466\n",
      "Episode Reward: 21.0\n",
      "Step 835 (637082) @ Episode 1672/10000, loss: 0.0009676545159891248\n",
      "Episode Reward: 16.0\n",
      "Step 929 (638011) @ Episode 1673/10000, loss: 0.0013868829701095828\n",
      "Episode Reward: 19.0\n",
      "Step 984 (638995) @ Episode 1674/10000, loss: 0.0032364793587476015\n",
      "Episode Reward: 17.0\n",
      "Step 964 (639959) @ Episode 1675/10000, loss: 0.0018026896286755898\n",
      "Episode Reward: 20.0\n",
      "Step 40 (639999) @ Episode 1676/10000, loss: 0.0012219173368066559\n",
      "Copied model parameters to target network.\n",
      "Step 765 (640724) @ Episode 1676/10000, loss: 0.0018241025973111397\n",
      "Episode Reward: 13.0\n",
      "Step 736 (641460) @ Episode 1677/10000, loss: 0.0029218611307442198\n",
      "Episode Reward: 11.0\n",
      "Step 791 (642251) @ Episode 1678/10000, loss: 0.0047862930223345767\n",
      "Episode Reward: 20.0\n",
      "Step 1125 (643376) @ Episode 1679/10000, loss: 0.0102075543254613888\n",
      "Episode Reward: 24.0\n",
      "Step 943 (644319) @ Episode 1680/10000, loss: 0.0047392304986715326\n",
      "Episode Reward: 17.0\n",
      "Step 742 (645061) @ Episode 1681/10000, loss: 0.0025634441990405324\n",
      "Episode Reward: 12.0\n",
      "Step 642 (645703) @ Episode 1682/10000, loss: 0.0063239149749279024\n",
      "Episode Reward: 11.0\n",
      "Step 703 (646406) @ Episode 1683/10000, loss: 0.0014505179133266217\n",
      "Episode Reward: 12.0\n",
      "Step 735 (647141) @ Episode 1684/10000, loss: 0.0038781422190368176\n",
      "Episode Reward: 20.0\n",
      "Step 949 (648090) @ Episode 1685/10000, loss: 0.0321615561842918417\n",
      "Episode Reward: 20.0\n",
      "Step 1392 (649482) @ Episode 1686/10000, loss: 0.0057248896919190887\n",
      "Episode Reward: 27.0\n",
      "Step 517 (649999) @ Episode 1687/10000, loss: 0.0023785966914147145\n",
      "Copied model parameters to target network.\n",
      "Step 768 (650250) @ Episode 1687/10000, loss: 0.0053366022184491163\n",
      "Episode Reward: 22.0\n",
      "Step 1002 (651252) @ Episode 1688/10000, loss: 0.026855492964386941\n",
      "Episode Reward: 19.0\n",
      "Step 799 (652051) @ Episode 1689/10000, loss: 0.0014043245464563376\n",
      "Episode Reward: 20.0\n",
      "Step 1310 (653361) @ Episode 1690/10000, loss: 0.0034020193852484226\n",
      "Episode Reward: 41.0\n",
      "Step 604 (653965) @ Episode 1691/10000, loss: 0.0323463007807731684\n",
      "Episode Reward: 12.0\n",
      "Step 908 (654873) @ Episode 1692/10000, loss: 0.0049804821610450745\n",
      "Episode Reward: 23.0\n",
      "Step 852 (655725) @ Episode 1693/10000, loss: 0.00351347774267196666\n",
      "Episode Reward: 21.0\n",
      "Step 918 (656643) @ Episode 1694/10000, loss: 0.00455532968044281655\n",
      "Episode Reward: 19.0\n",
      "Step 1198 (657841) @ Episode 1695/10000, loss: 0.0011920343386009336\n",
      "Episode Reward: 27.0\n",
      "Step 1482 (659323) @ Episode 1696/10000, loss: 0.0018770222086459398\n",
      "Episode Reward: 39.0\n",
      "Step 676 (659999) @ Episode 1697/10000, loss: 0.0011021622922271496\n",
      "Copied model parameters to target network.\n",
      "Step 819 (660142) @ Episode 1697/10000, loss: 0.0041782795451581486\n",
      "Episode Reward: 15.0\n",
      "Step 982 (661124) @ Episode 1698/10000, loss: 0.0015991914551705122\n",
      "Episode Reward: 15.0\n",
      "Step 946 (662070) @ Episode 1699/10000, loss: 0.0013602941762655973\n",
      "Episode Reward: 16.0\n",
      "Step 981 (663051) @ Episode 1700/10000, loss: 0.0017771485727280378\n",
      "Episode Reward: 24.0\n",
      "Step 1063 (664114) @ Episode 1701/10000, loss: 0.0015548070659860969\n",
      "Episode Reward: 19.0\n",
      "Step 1326 (665440) @ Episode 1702/10000, loss: 0.0147546334192156864\n",
      "Episode Reward: 26.0\n",
      "Step 840 (666280) @ Episode 1703/10000, loss: 0.0043515050783753395\n",
      "Episode Reward: 16.0\n",
      "Step 952 (667232) @ Episode 1704/10000, loss: 0.0033464306034147745\n",
      "Episode Reward: 18.0\n",
      "Step 918 (668150) @ Episode 1705/10000, loss: 0.0011508703464642167\n",
      "Episode Reward: 20.0\n",
      "Step 901 (669051) @ Episode 1706/10000, loss: 0.0048796893097460273\n",
      "Episode Reward: 14.0\n",
      "Step 948 (669999) @ Episode 1707/10000, loss: 0.0027554207481443887\n",
      "Copied model parameters to target network.\n",
      "Step 964 (670015) @ Episode 1707/10000, loss: 0.0040253424085676673\n",
      "Episode Reward: 19.0\n",
      "Step 1539 (671554) @ Episode 1708/10000, loss: 0.0018688427517190576\n",
      "Episode Reward: 38.0\n",
      "Step 1468 (673022) @ Episode 1709/10000, loss: 0.0035828344989567995\n",
      "Episode Reward: 31.0\n",
      "Step 1459 (674481) @ Episode 1710/10000, loss: 0.0022927827667444944\n",
      "Episode Reward: 27.0\n",
      "Step 783 (675264) @ Episode 1711/10000, loss: 0.0039073289372026924\n",
      "Episode Reward: 13.0\n",
      "Step 1193 (676457) @ Episode 1712/10000, loss: 0.0039929049089550974\n",
      "Episode Reward: 32.0\n",
      "Step 1077 (677534) @ Episode 1713/10000, loss: 0.0077005447819828993\n",
      "Episode Reward: 23.0\n",
      "Step 1307 (678841) @ Episode 1714/10000, loss: 0.0041813543066382416\n",
      "Episode Reward: 30.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 858 (679699) @ Episode 1715/10000, loss: 0.0014932194026187062\n",
      "Episode Reward: 14.0\n",
      "Step 300 (679999) @ Episode 1716/10000, loss: 0.0054189981892704962\n",
      "Copied model parameters to target network.\n",
      "Step 1224 (680923) @ Episode 1716/10000, loss: 0.0029944449197500944\n",
      "Episode Reward: 23.0\n",
      "Step 734 (681657) @ Episode 1717/10000, loss: 0.0042967810295522213\n",
      "Episode Reward: 15.0\n",
      "Step 1059 (682716) @ Episode 1718/10000, loss: 0.0024106397759169346\n",
      "Episode Reward: 22.0\n",
      "Step 1019 (683735) @ Episode 1719/10000, loss: 0.0013681527925655246\n",
      "Episode Reward: 16.0\n",
      "Step 785 (684520) @ Episode 1720/10000, loss: 0.0016901775961741805\n",
      "Episode Reward: 12.0\n",
      "Step 865 (685385) @ Episode 1721/10000, loss: 0.0290584508329629976\n",
      "Episode Reward: 15.0\n",
      "Step 1059 (686444) @ Episode 1722/10000, loss: 0.0133968535810709908\n",
      "Episode Reward: 20.0\n",
      "Step 1142 (687586) @ Episode 1723/10000, loss: 0.0027359973173588514\n",
      "Episode Reward: 26.0\n",
      "Step 1210 (688796) @ Episode 1724/10000, loss: 0.0010461814235895872\n",
      "Episode Reward: 24.0\n",
      "Step 931 (689727) @ Episode 1725/10000, loss: 0.0013533004093915224\n",
      "Episode Reward: 15.0\n",
      "Step 272 (689999) @ Episode 1726/10000, loss: 0.0019678932148963213\n",
      "Copied model parameters to target network.\n",
      "Step 1057 (690784) @ Episode 1726/10000, loss: 0.0022395579144358635\n",
      "Episode Reward: 22.0\n",
      "Step 975 (691759) @ Episode 1727/10000, loss: 0.0047484086826443676\n",
      "Episode Reward: 15.0\n",
      "Step 659 (692418) @ Episode 1728/10000, loss: 0.0040304348804056644\n",
      "Episode Reward: 11.0\n",
      "Step 905 (693323) @ Episode 1729/10000, loss: 0.0022612535394728184\n",
      "Episode Reward: 22.0\n",
      "Step 1069 (694392) @ Episode 1730/10000, loss: 0.0036407641600817447\n",
      "Episode Reward: 18.0\n",
      "Step 882 (695274) @ Episode 1731/10000, loss: 0.0033215098083019257\n",
      "Episode Reward: 19.0\n",
      "Step 1248 (696522) @ Episode 1732/10000, loss: 0.0053039812482893476\n",
      "Episode Reward: 32.0\n",
      "Step 1079 (697601) @ Episode 1733/10000, loss: 0.0023363886866718532\n",
      "Episode Reward: 30.0\n",
      "Step 777 (698378) @ Episode 1734/10000, loss: 0.0017419388750568032\n",
      "Episode Reward: 19.0\n",
      "Step 1091 (699469) @ Episode 1735/10000, loss: 0.0057669701054692275\n",
      "Episode Reward: 29.0\n",
      "Step 530 (699999) @ Episode 1736/10000, loss: 0.0023779878392815594\n",
      "Copied model parameters to target network.\n",
      "Step 1145 (700614) @ Episode 1736/10000, loss: 0.0021522413007915024\n",
      "Episode Reward: 23.0\n",
      "Step 1026 (701640) @ Episode 1737/10000, loss: 0.0023643907625228167\n",
      "Episode Reward: 26.0\n",
      "Step 823 (702463) @ Episode 1738/10000, loss: 0.0031528468243777757\n",
      "Episode Reward: 23.0\n",
      "Step 1297 (703760) @ Episode 1739/10000, loss: 0.0027449564076960087\n",
      "Episode Reward: 32.0\n",
      "Step 985 (704745) @ Episode 1740/10000, loss: 0.0069303736090660095\n",
      "Episode Reward: 19.0\n",
      "Step 755 (705500) @ Episode 1741/10000, loss: 0.0042030974291265014\n",
      "Episode Reward: 16.0\n",
      "Step 1029 (706529) @ Episode 1742/10000, loss: 0.0031436807475984097\n",
      "Episode Reward: 25.0\n",
      "Step 1077 (707606) @ Episode 1743/10000, loss: 0.0213856268674135228\n",
      "Episode Reward: 21.0\n",
      "Step 1494 (709100) @ Episode 1744/10000, loss: 0.0027585683856159456\n",
      "Episode Reward: 31.0\n",
      "Step 899 (709999) @ Episode 1745/10000, loss: 0.0097807766869664284\n",
      "Copied model parameters to target network.\n",
      "Step 1435 (710535) @ Episode 1745/10000, loss: 0.0118520027026534087\n",
      "Episode Reward: 41.0\n",
      "Step 647 (711182) @ Episode 1746/10000, loss: 0.0033915825188159943\n",
      "Episode Reward: 11.0\n",
      "Step 680 (711862) @ Episode 1747/10000, loss: 0.0030817815568298178\n",
      "Episode Reward: 12.0\n",
      "Step 799 (712661) @ Episode 1748/10000, loss: 0.0129535403102636347\n",
      "Episode Reward: 13.0\n",
      "Step 833 (713494) @ Episode 1749/10000, loss: 0.0025179123040288687\n",
      "Episode Reward: 13.0\n",
      "Step 1244 (714738) @ Episode 1750/10000, loss: 0.0063881068490445614\n",
      "Episode Reward: 26.0\n",
      "Step 766 (715504) @ Episode 1751/10000, loss: 0.0015293720643967393\n",
      "Episode Reward: 12.0\n",
      "Step 947 (716451) @ Episode 1752/10000, loss: 0.0329455956816673354\n",
      "Episode Reward: 17.0\n",
      "Step 1283 (717734) @ Episode 1753/10000, loss: 0.0426730066537857062\n",
      "Episode Reward: 30.0\n",
      "Step 1073 (718807) @ Episode 1754/10000, loss: 0.0027570901438593864\n",
      "Episode Reward: 24.0\n",
      "Step 784 (719591) @ Episode 1755/10000, loss: 0.0353629067540168767\n",
      "Episode Reward: 14.0\n",
      "Step 408 (719999) @ Episode 1756/10000, loss: 0.0035385801456868656\n",
      "Copied model parameters to target network.\n",
      "Step 1192 (720783) @ Episode 1756/10000, loss: 0.0028089012484997515\n",
      "Episode Reward: 23.0\n",
      "Step 911 (721694) @ Episode 1757/10000, loss: 0.0012662352528423077\n",
      "Episode Reward: 17.0\n",
      "Step 1148 (722842) @ Episode 1758/10000, loss: 0.0023864444810897117\n",
      "Episode Reward: 29.0\n",
      "Step 1260 (724102) @ Episode 1759/10000, loss: 0.0022158338688313964\n",
      "Episode Reward: 32.0\n",
      "Step 900 (725002) @ Episode 1760/10000, loss: 0.0018039045389741663\n",
      "Episode Reward: 16.0\n",
      "Step 920 (725922) @ Episode 1761/10000, loss: 0.0016243373975157738\n",
      "Episode Reward: 18.0\n",
      "Step 1142 (727064) @ Episode 1762/10000, loss: 0.0027310128789395094\n",
      "Episode Reward: 34.0\n",
      "Step 1028 (728092) @ Episode 1763/10000, loss: 0.0014330714475363493\n",
      "Episode Reward: 18.0\n",
      "Step 1126 (729218) @ Episode 1764/10000, loss: 0.0034420751035213474\n",
      "Episode Reward: 29.0\n",
      "Step 781 (729999) @ Episode 1765/10000, loss: 0.0071362974122166635\n",
      "Copied model parameters to target network.\n",
      "Step 849 (730067) @ Episode 1765/10000, loss: 0.0154773397371172975\n",
      "Episode Reward: 16.0\n",
      "Step 886 (730953) @ Episode 1766/10000, loss: 0.0024324173573404556\n",
      "Episode Reward: 23.0\n",
      "Step 1203 (732156) @ Episode 1767/10000, loss: 0.0019020326435565948\n",
      "Episode Reward: 26.0\n",
      "Step 1396 (733552) @ Episode 1768/10000, loss: 0.0023535061627626427\n",
      "Episode Reward: 28.0\n",
      "Step 716 (734268) @ Episode 1769/10000, loss: 0.0036066011525690556\n",
      "Episode Reward: 11.0\n",
      "Step 1040 (735308) @ Episode 1770/10000, loss: 0.0507306531071662907\n",
      "Episode Reward: 22.0\n",
      "Step 658 (735966) @ Episode 1771/10000, loss: 0.0018010608619078994\n",
      "Episode Reward: 10.0\n",
      "Step 1041 (737007) @ Episode 1772/10000, loss: 0.0020019193179905415\n",
      "Episode Reward: 19.0\n",
      "Step 599 (737606) @ Episode 1773/10000, loss: 0.0017053561750799417\n",
      "Episode Reward: 9.0\n",
      "Step 1032 (738638) @ Episode 1774/10000, loss: 0.0032669033389538527\n",
      "Episode Reward: 20.0\n",
      "Step 923 (739561) @ Episode 1775/10000, loss: 0.0027521271258592606\n",
      "Episode Reward: 17.0\n",
      "Step 438 (739999) @ Episode 1776/10000, loss: 0.0040175225585699084\n",
      "Copied model parameters to target network.\n",
      "Step 1106 (740667) @ Episode 1776/10000, loss: 0.0068155145272612577\n",
      "Episode Reward: 31.0\n",
      "Step 1381 (742048) @ Episode 1777/10000, loss: 0.0058671669103205297\n",
      "Episode Reward: 35.0\n",
      "Step 1049 (743097) @ Episode 1778/10000, loss: 0.0035615321248769764\n",
      "Episode Reward: 25.0\n",
      "Step 1178 (744275) @ Episode 1779/10000, loss: 0.0027973207179456955\n",
      "Episode Reward: 32.0\n",
      "Step 1275 (745550) @ Episode 1780/10000, loss: 0.0024541062302887442\n",
      "Episode Reward: 19.0\n",
      "Step 789 (746339) @ Episode 1781/10000, loss: 0.0053270435892045532\n",
      "Episode Reward: 13.0\n",
      "Step 1124 (747463) @ Episode 1782/10000, loss: 0.0040360800921916964\n",
      "Episode Reward: 28.0\n",
      "Step 876 (748339) @ Episode 1783/10000, loss: 0.0030747158452868463\n",
      "Episode Reward: 14.0\n",
      "Step 1147 (749486) @ Episode 1784/10000, loss: 0.0018819484394043684\n",
      "Episode Reward: 26.0\n",
      "Step 513 (749999) @ Episode 1785/10000, loss: 0.0016673650825396186\n",
      "Copied model parameters to target network.\n",
      "Step 1127 (750613) @ Episode 1785/10000, loss: 0.0066556842066347693\n",
      "Episode Reward: 25.0\n",
      "Step 916 (751529) @ Episode 1786/10000, loss: 0.0015358733944594864\n",
      "Episode Reward: 21.0\n",
      "Step 1192 (752721) @ Episode 1787/10000, loss: 0.0042131124064326294\n",
      "Episode Reward: 21.0\n",
      "Step 1111 (753832) @ Episode 1788/10000, loss: 0.0021619799081236124\n",
      "Episode Reward: 22.0\n",
      "Step 870 (754702) @ Episode 1789/10000, loss: 0.0034324780572205787\n",
      "Episode Reward: 15.0\n",
      "Step 655 (755357) @ Episode 1790/10000, loss: 0.0144747626036405564\n",
      "Episode Reward: 14.0\n",
      "Step 1093 (756450) @ Episode 1791/10000, loss: 0.0034941055346280336\n",
      "Episode Reward: 20.0\n",
      "Step 1149 (757599) @ Episode 1792/10000, loss: 0.0021572348196059465\n",
      "Episode Reward: 20.0\n",
      "Step 1273 (758872) @ Episode 1793/10000, loss: 0.0059138182550668726\n",
      "Episode Reward: 25.0\n",
      "Step 822 (759694) @ Episode 1794/10000, loss: 0.0039102076552808285\n",
      "Episode Reward: 12.0\n",
      "Step 305 (759999) @ Episode 1795/10000, loss: 0.0051432033069431783\n",
      "Copied model parameters to target network.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 916 (760610) @ Episode 1795/10000, loss: 0.0084247263148427015\n",
      "Episode Reward: 20.0\n",
      "Step 950 (761560) @ Episode 1796/10000, loss: 0.0033436431549489566\n",
      "Episode Reward: 16.0\n",
      "Step 987 (762547) @ Episode 1797/10000, loss: 0.0034669197630137205\n",
      "Episode Reward: 23.0\n",
      "Step 1580 (764127) @ Episode 1798/10000, loss: 0.0041090254671871669\n",
      "Episode Reward: 38.0\n",
      "Step 1130 (765257) @ Episode 1799/10000, loss: 0.0018393928185105324\n",
      "Episode Reward: 24.0\n",
      "Step 1062 (766319) @ Episode 1800/10000, loss: 0.0050334227271378046\n",
      "Episode Reward: 26.0\n",
      "Step 830 (767149) @ Episode 1801/10000, loss: 0.0034732979256659746\n",
      "Episode Reward: 19.0\n",
      "Step 918 (768067) @ Episode 1802/10000, loss: 0.0036747984122484922\n",
      "Episode Reward: 20.0\n",
      "Step 1121 (769188) @ Episode 1803/10000, loss: 0.0085425060242414477\n",
      "Episode Reward: 27.0\n",
      "Step 811 (769999) @ Episode 1804/10000, loss: 0.0010830946266651154\n",
      "Copied model parameters to target network.\n",
      "Step 993 (770181) @ Episode 1804/10000, loss: 0.0114474268630146987\n",
      "Episode Reward: 34.0\n",
      "Step 1151 (771332) @ Episode 1805/10000, loss: 0.0026079257950186735\n",
      "Episode Reward: 27.0\n",
      "Step 756 (772088) @ Episode 1806/10000, loss: 0.0078740483149886134\n",
      "Episode Reward: 14.0\n",
      "Step 990 (773078) @ Episode 1807/10000, loss: 0.0059260856360197078\n",
      "Episode Reward: 21.0\n",
      "Step 1190 (774268) @ Episode 1808/10000, loss: 0.0055653774179518223\n",
      "Episode Reward: 28.0\n",
      "Step 957 (775225) @ Episode 1809/10000, loss: 0.0043666115961968922\n",
      "Episode Reward: 26.0\n",
      "Step 1151 (776376) @ Episode 1810/10000, loss: 0.0015626264503225684\n",
      "Episode Reward: 31.0\n",
      "Step 1363 (777739) @ Episode 1811/10000, loss: 0.0027144558262079954\n",
      "Episode Reward: 33.0\n",
      "Step 1418 (779157) @ Episode 1812/10000, loss: 0.0021887682378292084\n",
      "Episode Reward: 35.0\n",
      "Step 842 (779999) @ Episode 1813/10000, loss: 0.0044071166776120665\n",
      "Copied model parameters to target network.\n",
      "Step 917 (780074) @ Episode 1813/10000, loss: 0.0047503607347607615\n",
      "Episode Reward: 16.0\n",
      "Step 1376 (781450) @ Episode 1814/10000, loss: 0.0051016970537602964\n",
      "Episode Reward: 33.0\n",
      "Step 971 (782421) @ Episode 1815/10000, loss: 0.0020273893605917692\n",
      "Episode Reward: 17.0\n",
      "Step 1061 (783482) @ Episode 1816/10000, loss: 0.0019607425201684237\n",
      "Episode Reward: 23.0\n",
      "Step 1236 (784718) @ Episode 1817/10000, loss: 0.0016674607759341598\n",
      "Episode Reward: 24.0\n",
      "Step 1068 (785786) @ Episode 1818/10000, loss: 0.0028381044976413256\n",
      "Episode Reward: 27.0\n",
      "Step 1076 (786862) @ Episode 1819/10000, loss: 0.0139371845871210165\n",
      "Episode Reward: 26.0\n",
      "Step 1156 (788018) @ Episode 1820/10000, loss: 0.0024678916670382023\n",
      "Episode Reward: 26.0\n",
      "Step 888 (788906) @ Episode 1821/10000, loss: 0.0092977583408355716\n",
      "Episode Reward: 17.0\n",
      "Step 927 (789833) @ Episode 1822/10000, loss: 0.0010798086877912283\n",
      "Episode Reward: 18.0\n",
      "Step 166 (789999) @ Episode 1823/10000, loss: 0.0042609050869941713\n",
      "Copied model parameters to target network.\n",
      "Step 1051 (790884) @ Episode 1823/10000, loss: 0.0020500060636550195\n",
      "Episode Reward: 18.0\n",
      "Step 764 (791648) @ Episode 1824/10000, loss: 0.0018412036588415504\n",
      "Episode Reward: 14.0\n",
      "Step 1069 (792717) @ Episode 1825/10000, loss: 0.0022112659644335512\n",
      "Episode Reward: 24.0\n",
      "Step 942 (793659) @ Episode 1826/10000, loss: 0.0053627826273441315\n",
      "Episode Reward: 23.0\n",
      "Step 746 (794405) @ Episode 1827/10000, loss: 0.0049631455913186077\n",
      "Episode Reward: 13.0\n",
      "Step 1124 (795529) @ Episode 1828/10000, loss: 0.0048070731572806835\n",
      "Episode Reward: 27.0\n",
      "Step 1348 (796877) @ Episode 1829/10000, loss: 0.0052720373496413235\n",
      "Episode Reward: 31.0\n",
      "Step 1372 (798249) @ Episode 1830/10000, loss: 0.0061118672601878644\n",
      "Episode Reward: 34.0\n",
      "Step 1367 (799616) @ Episode 1831/10000, loss: 0.0044023739174008375\n",
      "Episode Reward: 27.0\n",
      "Step 383 (799999) @ Episode 1832/10000, loss: 0.0027923001907765865\n",
      "Copied model parameters to target network.\n",
      "Step 764 (800380) @ Episode 1832/10000, loss: 0.0047280350700020795\n",
      "Episode Reward: 11.0\n",
      "Step 1116 (801496) @ Episode 1833/10000, loss: 0.0033187665976583958\n",
      "Episode Reward: 21.0\n",
      "Step 1457 (802953) @ Episode 1834/10000, loss: 0.0070238141342997556\n",
      "Episode Reward: 39.0\n",
      "Step 991 (803944) @ Episode 1835/10000, loss: 0.0035162873100489385\n",
      "Episode Reward: 17.0\n",
      "Step 1329 (805273) @ Episode 1836/10000, loss: 0.0027630759868770838\n",
      "Episode Reward: 25.0\n",
      "Step 1958 (807231) @ Episode 1837/10000, loss: 0.0013200864195823671\n",
      "Episode Reward: 51.0\n",
      "Step 1435 (808666) @ Episode 1838/10000, loss: 0.0095998840406537065\n",
      "Episode Reward: 38.0\n",
      "Step 1333 (809999) @ Episode 1839/10000, loss: 0.0058641363866627224\n",
      "Copied model parameters to target network.\n",
      "Step 1416 (810082) @ Episode 1839/10000, loss: 0.0069800270721316344\n",
      "Episode Reward: 47.0\n",
      "Step 1617 (811699) @ Episode 1840/10000, loss: 0.0026432087179273367\n",
      "Episode Reward: 33.0\n",
      "Step 867 (812566) @ Episode 1841/10000, loss: 0.0022264355793595314\n",
      "Episode Reward: 15.0\n",
      "Step 1415 (813981) @ Episode 1842/10000, loss: 0.0031528689432889223\n",
      "Episode Reward: 38.0\n",
      "Step 952 (814933) @ Episode 1843/10000, loss: 0.0042266319505870346\n",
      "Episode Reward: 16.0\n",
      "Step 764 (815697) @ Episode 1844/10000, loss: 0.0046897009015083313\n",
      "Episode Reward: 19.0\n",
      "Step 1230 (816927) @ Episode 1845/10000, loss: 0.0023913711775094277\n",
      "Episode Reward: 27.0\n",
      "Step 1268 (818195) @ Episode 1846/10000, loss: 0.0080711292102932935\n",
      "Episode Reward: 29.0\n",
      "Step 824 (819019) @ Episode 1847/10000, loss: 0.0106916027143597666\n",
      "Episode Reward: 12.0\n",
      "Step 930 (819949) @ Episode 1848/10000, loss: 0.0101768942549824718\n",
      "Episode Reward: 18.0\n",
      "Step 50 (819999) @ Episode 1849/10000, loss: 0.0038028236012905836\n",
      "Copied model parameters to target network.\n",
      "Step 743 (820692) @ Episode 1849/10000, loss: 0.0031629160512238746\n",
      "Episode Reward: 12.0\n",
      "Step 1174 (821866) @ Episode 1850/10000, loss: 0.0023409465793520212\n",
      "Episode Reward: 24.0\n",
      "Step 680 (822546) @ Episode 1851/10000, loss: 0.0030074492096900943\n",
      "Episode Reward: 12.0\n",
      "Step 855 (823401) @ Episode 1852/10000, loss: 0.0016051146667450666\n",
      "Episode Reward: 21.0\n",
      "Step 474 (823875) @ Episode 1853/10000, loss: 0.0030984610784798863\n",
      "Episode Reward: 7.0\n",
      "Step 1035 (824910) @ Episode 1854/10000, loss: 0.0269571803510189064\n",
      "Episode Reward: 22.0\n",
      "Step 491 (825401) @ Episode 1855/10000, loss: 0.0054877093061804772\n",
      "Episode Reward: 13.0\n",
      "Step 757 (826158) @ Episode 1856/10000, loss: 0.0364380553364753755\n",
      "Episode Reward: 16.0\n",
      "Step 885 (827043) @ Episode 1857/10000, loss: 0.0042999535799026496\n",
      "Episode Reward: 22.0\n",
      "Step 1118 (828161) @ Episode 1858/10000, loss: 0.0036553845275193453\n",
      "Episode Reward: 25.0\n",
      "Step 1396 (829557) @ Episode 1859/10000, loss: 0.0052501037716865543\n",
      "Episode Reward: 35.0\n",
      "Step 442 (829999) @ Episode 1860/10000, loss: 0.0017346031963825226\n",
      "Copied model parameters to target network.\n",
      "Step 754 (830311) @ Episode 1860/10000, loss: 0.0034136120229959492\n",
      "Episode Reward: 12.0\n",
      "Step 793 (831104) @ Episode 1861/10000, loss: 0.0062916120514273643\n",
      "Episode Reward: 20.0\n",
      "Step 1137 (832241) @ Episode 1862/10000, loss: 0.0014556518290191889\n",
      "Episode Reward: 30.0\n",
      "Step 831 (833072) @ Episode 1863/10000, loss: 0.0030541715677827597\n",
      "Episode Reward: 15.0\n",
      "Step 1167 (834239) @ Episode 1864/10000, loss: 0.0050873309373855595\n",
      "Episode Reward: 27.0\n",
      "Step 1059 (835298) @ Episode 1865/10000, loss: 0.0033265426754951477\n",
      "Episode Reward: 25.0\n",
      "Step 734 (836032) @ Episode 1866/10000, loss: 0.0021206000819802284\n",
      "Episode Reward: 15.0\n",
      "Step 1115 (837147) @ Episode 1867/10000, loss: 0.0066664619371294975\n",
      "Episode Reward: 26.0\n",
      "Step 1400 (838547) @ Episode 1868/10000, loss: 0.0048931869678199295\n",
      "Episode Reward: 48.0\n",
      "Step 885 (839432) @ Episode 1869/10000, loss: 0.0053558340296149256\n",
      "Episode Reward: 20.0\n",
      "Step 567 (839999) @ Episode 1870/10000, loss: 0.0021295265760272743\n",
      "Copied model parameters to target network.\n",
      "Step 1145 (840577) @ Episode 1870/10000, loss: 0.0060991104692220696\n",
      "Episode Reward: 25.0\n",
      "Step 1309 (841886) @ Episode 1871/10000, loss: 0.0055992584675550464\n",
      "Episode Reward: 30.0\n",
      "Step 1103 (842989) @ Episode 1872/10000, loss: 0.0081479838117957125\n",
      "Episode Reward: 26.0\n",
      "Step 666 (843655) @ Episode 1873/10000, loss: 0.0029376740567386155\n",
      "Episode Reward: 10.0\n",
      "Step 1004 (844659) @ Episode 1874/10000, loss: 0.008363319560885438\n",
      "Episode Reward: 18.0\n",
      "Step 935 (845594) @ Episode 1875/10000, loss: 0.0031929120887070894\n",
      "Episode Reward: 27.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 914 (846508) @ Episode 1876/10000, loss: 0.0072206915356218815\n",
      "Episode Reward: 23.0\n",
      "Step 1299 (847807) @ Episode 1877/10000, loss: 0.0149205010384321216\n",
      "Episode Reward: 30.0\n",
      "Step 1254 (849061) @ Episode 1878/10000, loss: 0.0078716678544878964\n",
      "Episode Reward: 27.0\n",
      "Step 938 (849999) @ Episode 1879/10000, loss: 0.0025603431276977062\n",
      "Copied model parameters to target network.\n",
      "Step 1260 (850321) @ Episode 1879/10000, loss: 0.0135816885158419613\n",
      "Episode Reward: 23.0\n",
      "Step 978 (851299) @ Episode 1880/10000, loss: 0.0037612752057611942\n",
      "Episode Reward: 23.0\n",
      "Step 1057 (852356) @ Episode 1881/10000, loss: 0.0064036822877824313\n",
      "Episode Reward: 25.0\n",
      "Step 1194 (853550) @ Episode 1882/10000, loss: 0.0038378234021365643\n",
      "Episode Reward: 23.0\n",
      "Step 910 (854460) @ Episode 1883/10000, loss: 0.0073105311021208764\n",
      "Episode Reward: 21.0\n",
      "Step 1091 (855551) @ Episode 1884/10000, loss: 0.0052929609082639225\n",
      "Episode Reward: 17.0\n",
      "Step 1009 (856560) @ Episode 1885/10000, loss: 0.0054805437102913862\n",
      "Episode Reward: 20.0\n",
      "Step 1095 (857655) @ Episode 1886/10000, loss: 0.0078879194334149368\n",
      "Episode Reward: 24.0\n",
      "Step 924 (858579) @ Episode 1887/10000, loss: 0.0017599798738956451\n",
      "Episode Reward: 21.0\n",
      "Step 1420 (859999) @ Episode 1888/10000, loss: 0.0049308594316244125\n",
      "Copied model parameters to target network.\n",
      "Step 1629 (860208) @ Episode 1888/10000, loss: 0.0023306903894990683\n",
      "Episode Reward: 57.0\n",
      "Step 825 (861033) @ Episode 1889/10000, loss: 0.0094361538067460065\n",
      "Episode Reward: 21.0\n",
      "Step 1139 (862172) @ Episode 1890/10000, loss: 0.0026453046593815095\n",
      "Episode Reward: 18.0\n",
      "Step 799 (862971) @ Episode 1891/10000, loss: 0.0065717576071619993\n",
      "Episode Reward: 13.0\n",
      "Step 946 (863917) @ Episode 1892/10000, loss: 0.0357947275042533964\n",
      "Episode Reward: 17.0\n",
      "Step 985 (864902) @ Episode 1893/10000, loss: 0.0421942211687564855\n",
      "Episode Reward: 19.0\n",
      "Step 1326 (866228) @ Episode 1894/10000, loss: 0.0054912096820771693\n",
      "Episode Reward: 29.0\n",
      "Step 1231 (867459) @ Episode 1895/10000, loss: 0.0042086718603968627\n",
      "Episode Reward: 26.0\n",
      "Step 999 (868458) @ Episode 1896/10000, loss: 0.0056512756273150445\n",
      "Episode Reward: 23.0\n",
      "Step 1541 (869999) @ Episode 1897/10000, loss: 0.0051548602059483535\n",
      "Copied model parameters to target network.\n",
      "Step 1609 (870067) @ Episode 1897/10000, loss: 0.0345665477216243746\n",
      "Episode Reward: 48.0\n",
      "Step 1095 (871162) @ Episode 1898/10000, loss: 0.0105722546577453617\n",
      "Episode Reward: 28.0\n",
      "Step 1153 (872315) @ Episode 1899/10000, loss: 0.0063687204383313667\n",
      "Episode Reward: 23.0\n",
      "Step 1428 (873743) @ Episode 1900/10000, loss: 0.0086570754647254943\n",
      "Episode Reward: 35.0\n",
      "Step 953 (874696) @ Episode 1901/10000, loss: 0.0031777559779584408\n",
      "Episode Reward: 17.0\n",
      "Step 1469 (876165) @ Episode 1902/10000, loss: 0.0051060034893453123\n",
      "Episode Reward: 36.0\n",
      "Step 983 (877148) @ Episode 1903/10000, loss: 0.0123453615233302125\n",
      "Episode Reward: 29.0\n",
      "Step 1268 (878416) @ Episode 1904/10000, loss: 0.0063297040760517122\n",
      "Episode Reward: 39.0\n",
      "Step 690 (879106) @ Episode 1905/10000, loss: 0.0082391556352376948\n",
      "Episode Reward: 15.0\n",
      "Step 893 (879999) @ Episode 1906/10000, loss: 0.0065244249999523166\n",
      "Copied model parameters to target network.\n",
      "Step 1172 (880278) @ Episode 1906/10000, loss: 0.0183852948248386455\n",
      "Episode Reward: 26.0\n",
      "Step 923 (881201) @ Episode 1907/10000, loss: 0.0023401896469295025\n",
      "Episode Reward: 18.0\n",
      "Step 891 (882092) @ Episode 1908/10000, loss: 0.0073243090882897384\n",
      "Episode Reward: 14.0\n",
      "Step 802 (882894) @ Episode 1909/10000, loss: 0.0048890970647335057\n",
      "Episode Reward: 26.0\n",
      "Step 1198 (884092) @ Episode 1910/10000, loss: 0.0032109036110341556\n",
      "Episode Reward: 21.0\n",
      "Step 1602 (885694) @ Episode 1911/10000, loss: 0.0057439175434410578\n",
      "Episode Reward: 50.0\n",
      "Step 1165 (886859) @ Episode 1912/10000, loss: 0.0156528018414974236\n",
      "Episode Reward: 31.0\n",
      "Step 1444 (888303) @ Episode 1913/10000, loss: 0.0057144351303577425\n",
      "Episode Reward: 32.0\n",
      "Step 946 (889249) @ Episode 1914/10000, loss: 0.0098814396187663083\n",
      "Episode Reward: 17.0\n",
      "Step 750 (889999) @ Episode 1915/10000, loss: 0.0043705338612198835\n",
      "Copied model parameters to target network.\n",
      "Step 1086 (890335) @ Episode 1915/10000, loss: 0.0029268648941069846\n",
      "Episode Reward: 23.0\n",
      "Step 906 (891241) @ Episode 1916/10000, loss: 0.0061640357598662388\n",
      "Episode Reward: 22.0\n",
      "Step 679 (891920) @ Episode 1917/10000, loss: 0.0028723052237182856\n",
      "Episode Reward: 11.0\n",
      "Step 890 (892810) @ Episode 1918/10000, loss: 0.0192767400294542374\n",
      "Episode Reward: 16.0\n",
      "Step 1062 (893872) @ Episode 1919/10000, loss: 0.0102828275412321094\n",
      "Episode Reward: 25.0\n",
      "Step 1355 (895227) @ Episode 1920/10000, loss: 0.0053910873830318453\n",
      "Episode Reward: 30.0\n",
      "Step 1001 (896228) @ Episode 1921/10000, loss: 0.009141555055975914\n",
      "Episode Reward: 25.0\n",
      "Step 859 (897087) @ Episode 1922/10000, loss: 0.0376507230103015967\n",
      "Episode Reward: 14.0\n",
      "Step 907 (897994) @ Episode 1923/10000, loss: 0.0088829305022954946\n",
      "Episode Reward: 22.0\n",
      "Step 697 (898691) @ Episode 1924/10000, loss: 0.0041143642738461494\n",
      "Episode Reward: 10.0\n",
      "Step 848 (899539) @ Episode 1925/10000, loss: 0.0026099199894815683\n",
      "Episode Reward: 18.0\n",
      "Step 460 (899999) @ Episode 1926/10000, loss: 0.0022871713154017925\n",
      "Copied model parameters to target network.\n",
      "Step 1220 (900759) @ Episode 1926/10000, loss: 0.0035147399175912147\n",
      "Episode Reward: 22.0\n",
      "Step 1082 (901841) @ Episode 1927/10000, loss: 0.0033291347790509462\n",
      "Episode Reward: 32.0\n",
      "Step 896 (902737) @ Episode 1928/10000, loss: 0.0064760111272335056\n",
      "Episode Reward: 23.0\n",
      "Step 1157 (903894) @ Episode 1929/10000, loss: 0.0037397383712232113\n",
      "Episode Reward: 23.0\n",
      "Step 1080 (904974) @ Episode 1930/10000, loss: 0.0024085857439786196\n",
      "Episode Reward: 23.0\n",
      "Step 1041 (906015) @ Episode 1931/10000, loss: 0.0035894662141799927\n",
      "Episode Reward: 26.0\n",
      "Step 1229 (907244) @ Episode 1932/10000, loss: 0.0818813890218734727\n",
      "Episode Reward: 30.0\n",
      "Step 1378 (908622) @ Episode 1933/10000, loss: 0.0050711194053292274\n",
      "Episode Reward: 39.0\n",
      "Step 1181 (909803) @ Episode 1934/10000, loss: 0.0025221365503966815\n",
      "Episode Reward: 24.0\n",
      "Step 196 (909999) @ Episode 1935/10000, loss: 0.0028309875633567577\n",
      "Copied model parameters to target network.\n",
      "Step 1286 (911089) @ Episode 1935/10000, loss: 0.0028387049678713083\n",
      "Episode Reward: 40.0\n",
      "Step 989 (912078) @ Episode 1936/10000, loss: 0.0059842420741915766\n",
      "Episode Reward: 19.0\n",
      "Step 860 (912938) @ Episode 1937/10000, loss: 0.0020173054654151257\n",
      "Episode Reward: 18.0\n",
      "Step 1054 (913992) @ Episode 1938/10000, loss: 0.0119452495127916344\n",
      "Episode Reward: 22.0\n",
      "Step 1177 (915169) @ Episode 1939/10000, loss: 0.0020588070619851354\n",
      "Episode Reward: 39.0\n",
      "Step 1190 (916359) @ Episode 1940/10000, loss: 0.0044612796045839795\n",
      "Episode Reward: 29.0\n",
      "Step 1323 (917682) @ Episode 1941/10000, loss: 0.0059762587770819667\n",
      "Episode Reward: 35.0\n",
      "Step 1137 (918819) @ Episode 1942/10000, loss: 0.0062538264319300655\n",
      "Episode Reward: 28.0\n",
      "Step 605 (919424) @ Episode 1943/10000, loss: 0.0017346948152408004\n",
      "Episode Reward: 9.0\n",
      "Step 575 (919999) @ Episode 1944/10000, loss: 0.0617595799267292383\n",
      "Copied model parameters to target network.\n",
      "Step 853 (920277) @ Episode 1944/10000, loss: 0.0034364226739853625\n",
      "Episode Reward: 14.0\n",
      "Step 1028 (921305) @ Episode 1945/10000, loss: 0.0035419655032455924\n",
      "Episode Reward: 32.0\n",
      "Step 1147 (922452) @ Episode 1946/10000, loss: 0.0124237714335322382\n",
      "Episode Reward: 24.0\n",
      "Step 1509 (923961) @ Episode 1947/10000, loss: 0.0057276478037238124\n",
      "Episode Reward: 40.0\n",
      "Step 1001 (924962) @ Episode 1948/10000, loss: 0.004441993311047554\n",
      "Episode Reward: 18.0\n",
      "Step 738 (925700) @ Episode 1949/10000, loss: 0.0048251571133732856\n",
      "Episode Reward: 16.0\n",
      "Step 1084 (926784) @ Episode 1950/10000, loss: 0.0051464256830513482\n",
      "Episode Reward: 30.0\n",
      "Step 841 (927625) @ Episode 1951/10000, loss: 0.0034888410009443767\n",
      "Episode Reward: 18.0\n",
      "Step 1302 (928927) @ Episode 1952/10000, loss: 0.0034113973379135133\n",
      "Episode Reward: 41.0\n",
      "Step 764 (929691) @ Episode 1953/10000, loss: 0.0032952011097222567\n",
      "Episode Reward: 19.0\n",
      "Step 308 (929999) @ Episode 1954/10000, loss: 0.0038012154400348663\n",
      "Copied model parameters to target network.\n",
      "Step 501 (930192) @ Episode 1954/10000, loss: 0.0505664125084877066\n",
      "Episode Reward: 6.0\n",
      "Step 1627 (931819) @ Episode 1955/10000, loss: 0.0035793862771242857\n",
      "Episode Reward: 59.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 719 (932538) @ Episode 1956/10000, loss: 0.0381977409124374485\n",
      "Episode Reward: 15.0\n",
      "Step 790 (933328) @ Episode 1957/10000, loss: 0.0057833031751215466\n",
      "Episode Reward: 17.0\n",
      "Step 984 (934312) @ Episode 1958/10000, loss: 0.0026305085048079497\n",
      "Episode Reward: 17.0\n",
      "Step 723 (935035) @ Episode 1959/10000, loss: 0.0034573555458337074\n",
      "Episode Reward: 14.0\n",
      "Step 1084 (936119) @ Episode 1960/10000, loss: 0.0469688549637794588\n",
      "Episode Reward: 24.0\n",
      "Step 978 (937097) @ Episode 1961/10000, loss: 0.0024473376106470823\n",
      "Episode Reward: 20.0\n",
      "Step 1411 (938508) @ Episode 1962/10000, loss: 0.0040070144459605226\n",
      "Episode Reward: 23.0\n",
      "Step 997 (939505) @ Episode 1963/10000, loss: 0.0040412773378193386\n",
      "Episode Reward: 23.0\n",
      "Step 494 (939999) @ Episode 1964/10000, loss: 0.0017068965826183558\n",
      "Copied model parameters to target network.\n",
      "Step 875 (940380) @ Episode 1964/10000, loss: 0.0088702207431197175\n",
      "Episode Reward: 16.0\n",
      "Step 691 (941071) @ Episode 1965/10000, loss: 0.0043635279871523384\n",
      "Episode Reward: 10.0\n",
      "Step 942 (942013) @ Episode 1966/10000, loss: 0.0014050999889150262\n",
      "Episode Reward: 20.0\n",
      "Step 1383 (943396) @ Episode 1967/10000, loss: 0.0086848977953195573\n",
      "Episode Reward: 31.0\n",
      "Step 1336 (944732) @ Episode 1968/10000, loss: 0.0158892180770635665\n",
      "Episode Reward: 30.0\n",
      "Step 991 (945723) @ Episode 1969/10000, loss: 0.0040563596412539487\n",
      "Episode Reward: 29.0\n",
      "Step 918 (946641) @ Episode 1970/10000, loss: 0.0017480335664004087\n",
      "Episode Reward: 30.0\n",
      "Step 844 (947485) @ Episode 1971/10000, loss: 0.0046126497909426694\n",
      "Episode Reward: 13.0\n",
      "Step 741 (948226) @ Episode 1972/10000, loss: 0.0050154775381088265\n",
      "Episode Reward: 13.0\n",
      "Step 1261 (949487) @ Episode 1973/10000, loss: 0.0200505089014768685\n",
      "Episode Reward: 28.0\n",
      "Step 512 (949999) @ Episode 1974/10000, loss: 0.0081833070144057275\n",
      "Copied model parameters to target network.\n",
      "Step 1041 (950528) @ Episode 1974/10000, loss: 0.0055789323523640635\n",
      "Episode Reward: 23.0\n",
      "Step 1375 (951903) @ Episode 1975/10000, loss: 0.0089627252891659744\n",
      "Episode Reward: 30.0\n",
      "Step 1183 (953086) @ Episode 1976/10000, loss: 0.0115731609985232357\n",
      "Episode Reward: 20.0\n",
      "Step 1745 (954831) @ Episode 1977/10000, loss: 0.0087875816971063614\n",
      "Episode Reward: 47.0\n",
      "Step 944 (955775) @ Episode 1978/10000, loss: 0.0137663213536143365\n",
      "Episode Reward: 20.0\n",
      "Step 988 (956763) @ Episode 1979/10000, loss: 0.0026178688276559114\n",
      "Episode Reward: 28.0\n",
      "Step 1657 (958420) @ Episode 1980/10000, loss: 0.0047512534074485355\n",
      "Episode Reward: 34.0\n",
      "Step 1322 (959742) @ Episode 1981/10000, loss: 0.0128668770194053656\n",
      "Episode Reward: 25.0\n",
      "Step 257 (959999) @ Episode 1982/10000, loss: 0.0034604452084749937\n",
      "Copied model parameters to target network.\n",
      "Step 730 (960472) @ Episode 1982/10000, loss: 0.0239773150533437736\n",
      "Episode Reward: 16.0\n",
      "Step 1146 (961618) @ Episode 1983/10000, loss: 0.0042865066789090636\n",
      "Episode Reward: 31.0\n",
      "Step 1212 (962830) @ Episode 1984/10000, loss: 0.0077060712501406678\n",
      "Episode Reward: 28.0\n",
      "Step 1054 (963884) @ Episode 1985/10000, loss: 0.0038160267286002636\n",
      "Episode Reward: 20.0\n",
      "Step 1057 (964941) @ Episode 1986/10000, loss: 0.0046786395832896237\n",
      "Episode Reward: 19.0\n",
      "Step 919 (965860) @ Episode 1987/10000, loss: 0.0033212997950613598\n",
      "Episode Reward: 16.0\n",
      "Step 968 (966828) @ Episode 1988/10000, loss: 0.0027678776532411575\n",
      "Episode Reward: 20.0\n",
      "Step 541 (967369) @ Episode 1989/10000, loss: 0.0055726310238242154\n",
      "Episode Reward: 10.0\n",
      "Step 1026 (968395) @ Episode 1990/10000, loss: 0.0032355473376810555\n",
      "Episode Reward: 31.0\n",
      "Step 366 (968761) @ Episode 1991/10000, loss: 0.0254259705543518076\n",
      "Episode Reward: 4.0\n",
      "Step 801 (969562) @ Episode 1992/10000, loss: 0.0166319347918033624\n",
      "Episode Reward: 16.0\n",
      "Step 437 (969999) @ Episode 1993/10000, loss: 0.0129043459892272954\n",
      "Copied model parameters to target network.\n",
      "Step 644 (970206) @ Episode 1993/10000, loss: 0.0247172415256500246\n",
      "Episode Reward: 12.0\n",
      "Step 962 (971168) @ Episode 1994/10000, loss: 0.0026510150637477636\n",
      "Episode Reward: 20.0\n",
      "Step 1129 (972297) @ Episode 1995/10000, loss: 0.0054469606839120394\n",
      "Episode Reward: 22.0\n",
      "Step 768 (973065) @ Episode 1996/10000, loss: 0.0039554890245199254\n",
      "Episode Reward: 17.0\n",
      "Step 1075 (974140) @ Episode 1997/10000, loss: 0.0113142775371670725\n",
      "Episode Reward: 21.0\n",
      "Step 795 (974935) @ Episode 1998/10000, loss: 0.0037216388154774904\n",
      "Episode Reward: 13.0\n",
      "Step 980 (975915) @ Episode 1999/10000, loss: 0.0049394015222787866\n",
      "Episode Reward: 23.0\n",
      "Step 1130 (977045) @ Episode 2000/10000, loss: 0.0030460164416581392\n",
      "Episode Reward: 19.0\n",
      "Step 1645 (978690) @ Episode 2001/10000, loss: 0.0070315627381205564\n",
      "Episode Reward: 32.0\n",
      "Step 435 (979125) @ Episode 2002/10000, loss: 0.0077552413567900663"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1140cd79757e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m                                     \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                                     ser_coef=128):\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_rewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEpisode Reward: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_rewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/secondary_experience_replay/SER.py\u001b[0m in \u001b[0;36mdeep_q_learning\u001b[0;34m(sess, env, q_estimator, target_estimator, state_processor, num_episodes, experiment_dir, replay_memory_size, replay_memory_init_size, update_target_estimator_every, discount_factor, epsilon_start, epsilon_end, epsilon_decay_steps, batch_size, ser_coef, record_video_every)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Perform gradient descent update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mstates_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/secondary_experience_replay/SER.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, sess, s, a, y)\u001b[0m\n\u001b[1;32m    385\u001b[0m         summaries, global_step, _, loss = sess.run(\n\u001b[1;32m    386\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             feed_dict)\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_writer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import psutil\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from SER import StateProcessor, Estimator, ModelParametersCopier, make_epsilon_greedy_policy, deep_q_learning\n",
    "\n",
    "from reinforcementlearning.lib import plotting\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "env = gym.envs.make(\"Breakout-v0\")\n",
    "\n",
    "VALID_ACTIONS = [0, 1, 2, 3]\n",
    "\n",
    "# training\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Where we save our checkpoints and graphs\n",
    "experiment_dir = os.path.abspath(\"./experiments_ser128/{}\".format(env.spec.id))\n",
    "\n",
    "# Create a glboal step variable\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "# Create estimators\n",
    "q_estimator = Estimator(scope=\"q_estimator\", summaries_dir=experiment_dir)\n",
    "target_estimator = Estimator(scope=\"target_q\")\n",
    "\n",
    "# State processor\n",
    "state_processor = StateProcessor()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Run it!\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for t, stats in deep_q_learning(sess,\n",
    "                                    env,\n",
    "                                    q_estimator=q_estimator,\n",
    "                                    target_estimator=target_estimator,\n",
    "                                    state_processor=state_processor,\n",
    "                                    experiment_dir=experiment_dir,\n",
    "                                    num_episodes=10000,\n",
    "                                    replay_memory_size=500000,\n",
    "                                    replay_memory_init_size=50000,\n",
    "                                    update_target_estimator_every=10000,\n",
    "                                    epsilon_start=1.0,\n",
    "                                    epsilon_end=0.1,\n",
    "                                    epsilon_decay_steps=500000,\n",
    "                                    discount_factor=0.99,\n",
    "                                    batch_size=40,\n",
    "                                    ser_coef=128):\n",
    "        results.append(stats.episode_rewards[-1])\n",
    "        print(\"\\nEpisode Reward: {}\".format(stats.episode_rewards[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {'Reward':  stats.episode_rewards}\n",
    "df = pd.DataFrame (data)\n",
    "\n",
    "rolling_mean = df.Reward.rolling(window=50).mean()\n",
    "\n",
    "plt.plot(df.index, df.Reward, label='SER123 Reward')\n",
    "plt.plot(df.index, rolling_mean, label='SER123 MA Reward', color='orange')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "df.to_csv('output_SER128.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
