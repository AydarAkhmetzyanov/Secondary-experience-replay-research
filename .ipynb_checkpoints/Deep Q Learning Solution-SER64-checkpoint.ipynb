{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:298: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:314: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:320: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:341: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:345: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:346: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:349: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:350: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:351: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:305: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:272: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:404: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:114: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Populating replay memory...\n",
      "WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:163: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "\n",
      "Copied model parameters to target network.\n",
      "Step 420 (420) @ Episode 1/10000, loss: 6.957542063901201e-057WARNING:tensorflow:From /Users/aydarakhmetzyanov/Documents/secondary_experience_replay/SER.py:244: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "\n",
      "Episode Reward: 5.0\n",
      "Step 243 (663) @ Episode 2/10000, loss: 3.592764915083535e-055\n",
      "Episode Reward: 1.0\n",
      "Step 166 (829) @ Episode 3/10000, loss: 0.00010200069664278999\n",
      "Episode Reward: 0.0\n",
      "Step 180 (1009) @ Episode 4/10000, loss: 0.02502456866204738654\n",
      "Episode Reward: 0.0\n",
      "Step 224 (1233) @ Episode 5/10000, loss: 0.00011568274203455076\n",
      "Episode Reward: 1.0\n",
      "Step 174 (1407) @ Episode 6/10000, loss: 0.00078478117939084778\n",
      "Episode Reward: 0.0\n",
      "Step 237 (1644) @ Episode 7/10000, loss: 0.02559291943907737755\n",
      "Episode Reward: 1.0\n",
      "Step 169 (1813) @ Episode 8/10000, loss: 0.00016695211525075138\n",
      "Episode Reward: 0.0\n",
      "Step 379 (2192) @ Episode 9/10000, loss: 0.02504759095609188747\n",
      "Episode Reward: 4.0\n",
      "Step 261 (2453) @ Episode 10/10000, loss: 6.257811037357897e-053\n",
      "Episode Reward: 2.0\n",
      "Step 173 (2626) @ Episode 11/10000, loss: 0.02518584765493869894\n",
      "Episode Reward: 0.0\n",
      "Step 242 (2868) @ Episode 12/10000, loss: 0.02396774478256702487\n",
      "Episode Reward: 1.0\n",
      "Step 230 (3098) @ Episode 13/10000, loss: 0.00059449218679219483\n",
      "Episode Reward: 1.0\n",
      "Step 188 (3286) @ Episode 14/10000, loss: 0.02464706078171739044\n",
      "Episode Reward: 0.0\n",
      "Step 246 (3532) @ Episode 15/10000, loss: 0.04779819771647453855\n",
      "Episode Reward: 1.0\n",
      "Step 211 (3743) @ Episode 16/10000, loss: 0.00012398161925375462\n",
      "Episode Reward: 1.0\n",
      "Step 254 (3997) @ Episode 17/10000, loss: 7.031911081867293e-056\n",
      "Episode Reward: 1.0\n",
      "Step 233 (4230) @ Episode 18/10000, loss: 0.02533488906919956274\n",
      "Episode Reward: 1.0\n",
      "Step 270 (4500) @ Episode 19/10000, loss: 9.979332389775664e-058\n",
      "Episode Reward: 2.0\n",
      "Step 245 (4745) @ Episode 20/10000, loss: 0.00042351597221568227\n",
      "Episode Reward: 1.0\n",
      "Step 363 (5108) @ Episode 21/10000, loss: 0.00021191663108766086\n",
      "Episode Reward: 3.0\n",
      "Step 251 (5359) @ Episode 22/10000, loss: 0.02487241663038730652\n",
      "Episode Reward: 1.0\n",
      "Step 235 (5594) @ Episode 23/10000, loss: 0.40066561102867126464\n",
      "Episode Reward: 1.0\n",
      "Step 231 (5825) @ Episode 24/10000, loss: 0.00040668892324902117\n",
      "Episode Reward: 1.0\n",
      "Step 162 (5987) @ Episode 25/10000, loss: 0.02432795241475105375\n",
      "Episode Reward: 0.0\n",
      "Step 313 (6300) @ Episode 26/10000, loss: 0.00038991295150481164\n",
      "Episode Reward: 3.0\n",
      "Step 335 (6635) @ Episode 27/10000, loss: 0.00013363121252041314\n",
      "Episode Reward: 3.0\n",
      "Step 262 (6897) @ Episode 28/10000, loss: 0.00145863392390310764\n",
      "Episode Reward: 2.0\n",
      "Step 239 (7136) @ Episode 29/10000, loss: 0.00025894228019751617\n",
      "Episode Reward: 1.0\n",
      "Step 274 (7410) @ Episode 30/10000, loss: 0.00051250332035124377\n",
      "Episode Reward: 2.0\n",
      "Step 296 (7706) @ Episode 31/10000, loss: 0.00012837832036893815\n",
      "Episode Reward: 2.0\n",
      "Step 254 (7960) @ Episode 32/10000, loss: 0.00012300520029384643\n",
      "Episode Reward: 1.0\n",
      "Step 262 (8222) @ Episode 33/10000, loss: 0.00024362499243579805\n",
      "Episode Reward: 2.0\n",
      "Step 241 (8463) @ Episode 34/10000, loss: 8.606829214841127e-055\n",
      "Episode Reward: 1.0\n",
      "Step 335 (8798) @ Episode 35/10000, loss: 8.38657288113609e-0545\n",
      "Episode Reward: 3.0\n",
      "Step 248 (9046) @ Episode 36/10000, loss: 0.00021377197117544713\n",
      "Episode Reward: 1.0\n",
      "Step 177 (9223) @ Episode 37/10000, loss: 0.00054730329429730776\n",
      "Episode Reward: 0.0\n",
      "Step 235 (9458) @ Episode 38/10000, loss: 0.00029990728944540024\n",
      "Episode Reward: 1.0\n",
      "Step 253 (9711) @ Episode 39/10000, loss: 0.00033543485915288334\n",
      "Episode Reward: 1.0\n",
      "Step 288 (9999) @ Episode 40/10000, loss: 0.00058248441200703382\n",
      "Copied model parameters to target network.\n",
      "Step 297 (10008) @ Episode 40/10000, loss: 0.00053011131240054973\n",
      "Episode Reward: 2.0\n",
      "Step 428 (10436) @ Episode 41/10000, loss: 0.00633582565933466724\n",
      "Episode Reward: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 237 (10673) @ Episode 42/10000, loss: 0.00454899156466126425\n",
      "Episode Reward: 1.0\n",
      "Step 338 (11011) @ Episode 43/10000, loss: 0.02395303733646869767\n",
      "Episode Reward: 3.0\n",
      "Step 336 (11347) @ Episode 44/10000, loss: 0.00079848116729408562\n",
      "Episode Reward: 3.0\n",
      "Step 378 (11725) @ Episode 45/10000, loss: 0.00078899634536355735\n",
      "Episode Reward: 3.0\n",
      "Step 276 (12001) @ Episode 46/10000, loss: 0.00047149526653811336\n",
      "Episode Reward: 2.0\n",
      "Step 275 (12276) @ Episode 47/10000, loss: 0.00014063245907891542\n",
      "Episode Reward: 2.0\n",
      "Step 253 (12529) @ Episode 48/10000, loss: 0.00015228916890919209\n",
      "Episode Reward: 1.0\n",
      "Step 257 (12786) @ Episode 49/10000, loss: 0.02252919599413871843\n",
      "Episode Reward: 1.0\n",
      "Step 243 (13029) @ Episode 50/10000, loss: 0.00017951747577171773\n",
      "Episode Reward: 1.0\n",
      "Step 172 (13201) @ Episode 51/10000, loss: 0.00065227673621848235\n",
      "Episode Reward: 0.0\n",
      "Step 169 (13370) @ Episode 52/10000, loss: 0.00033871151390485466\n",
      "Episode Reward: 0.0\n",
      "Step 234 (13604) @ Episode 53/10000, loss: 0.00022880083997733894\n",
      "Episode Reward: 1.0\n",
      "Step 249 (13853) @ Episode 54/10000, loss: 0.00060349749401211747\n",
      "Episode Reward: 1.0\n",
      "Step 165 (14018) @ Episode 55/10000, loss: 0.00014536664821207523\n",
      "Episode Reward: 0.0\n",
      "Step 425 (14443) @ Episode 56/10000, loss: 0.00026268939836882055\n",
      "Episode Reward: 5.0\n",
      "Step 171 (14614) @ Episode 57/10000, loss: 0.00121376046445220798\n",
      "Episode Reward: 0.0\n",
      "Step 269 (14883) @ Episode 58/10000, loss: 0.04722473770380026117\n",
      "Episode Reward: 2.0\n",
      "Step 183 (15066) @ Episode 59/10000, loss: 0.00023292288824450225\n",
      "Episode Reward: 0.0\n",
      "Step 281 (15347) @ Episode 60/10000, loss: 0.00023076543584465983\n",
      "Episode Reward: 2.0\n",
      "Step 167 (15514) @ Episode 61/10000, loss: 0.00019439213792793453\n",
      "Episode Reward: 0.0\n",
      "Step 285 (15799) @ Episode 62/10000, loss: 0.00024574459530413155\n",
      "Episode Reward: 2.0\n",
      "Step 172 (15971) @ Episode 63/10000, loss: 0.00051019253442063936\n",
      "Episode Reward: 0.0\n",
      "Step 171 (16142) @ Episode 64/10000, loss: 0.02102397009730339386\n",
      "Episode Reward: 0.0\n",
      "Step 177 (16319) @ Episode 65/10000, loss: 0.00051896891091018921\n",
      "Episode Reward: 0.0\n",
      "Step 402 (16721) @ Episode 66/10000, loss: 0.00157319009304046636\n",
      "Episode Reward: 4.0\n",
      "Step 268 (16989) @ Episode 67/10000, loss: 0.00030743237584829336\n",
      "Episode Reward: 2.0\n",
      "Step 333 (17322) @ Episode 68/10000, loss: 0.00115422729868441826\n",
      "Episode Reward: 3.0\n",
      "Step 332 (17654) @ Episode 69/10000, loss: 0.00118966936133801947\n",
      "Episode Reward: 3.0\n",
      "Step 172 (17826) @ Episode 70/10000, loss: 0.00029812310822308064\n",
      "Episode Reward: 0.0\n",
      "Step 208 (18034) @ Episode 71/10000, loss: 0.03164920955896377637\n",
      "Episode Reward: 1.0\n",
      "Step 376 (18410) @ Episode 72/10000, loss: 0.00789676606655120814\n",
      "Episode Reward: 4.0\n",
      "Step 176 (18586) @ Episode 73/10000, loss: 0.00076730322325602178\n",
      "Episode Reward: 0.0\n",
      "Step 281 (18867) @ Episode 74/10000, loss: 0.00030560060986317694\n",
      "Episode Reward: 2.0\n",
      "Step 269 (19136) @ Episode 75/10000, loss: 0.00022296965471468866\n",
      "Episode Reward: 2.0\n",
      "Step 176 (19312) @ Episode 76/10000, loss: 0.00050396390724927193\n",
      "Episode Reward: 0.0\n",
      "Step 281 (19593) @ Episode 77/10000, loss: 0.00424127047881484105\n",
      "Episode Reward: 2.0\n",
      "Step 177 (19770) @ Episode 78/10000, loss: 0.02595115266740322736\n",
      "Episode Reward: 0.0\n",
      "Step 229 (19999) @ Episode 79/10000, loss: 0.02136390097439289773\n",
      "Copied model parameters to target network.\n",
      "Step 290 (20060) @ Episode 79/10000, loss: 0.02568397484719753334\n",
      "Episode Reward: 2.0\n",
      "Step 249 (20309) @ Episode 80/10000, loss: 0.00197087647393345837\n",
      "Episode Reward: 1.0\n",
      "Step 344 (20653) @ Episode 81/10000, loss: 0.00133223575539886955\n",
      "Episode Reward: 3.0\n",
      "Step 280 (20933) @ Episode 82/10000, loss: 0.00295651657506823547\n",
      "Episode Reward: 2.0\n",
      "Step 248 (21181) @ Episode 83/10000, loss: 0.00106537307146936666\n",
      "Episode Reward: 1.0\n",
      "Step 171 (21352) @ Episode 84/10000, loss: 0.00042798416689038277\n",
      "Episode Reward: 0.0\n",
      "Step 265 (21617) @ Episode 85/10000, loss: 0.00846457853913307203\n",
      "Episode Reward: 2.0\n",
      "Step 229 (21846) @ Episode 86/10000, loss: 0.00019971113943029195\n",
      "Episode Reward: 1.0\n",
      "Step 186 (22032) @ Episode 87/10000, loss: 0.00035743118496611714\n",
      "Episode Reward: 0.0\n",
      "Step 191 (22223) @ Episode 88/10000, loss: 0.00374966789968311837\n",
      "Episode Reward: 0.0\n",
      "Step 171 (22394) @ Episode 89/10000, loss: 0.00533815193921327634\n",
      "Episode Reward: 0.0\n",
      "Step 368 (22762) @ Episode 90/10000, loss: 0.00038206003955565393\n",
      "Episode Reward: 3.0\n",
      "Step 183 (22945) @ Episode 91/10000, loss: 0.00298112980090081765\n",
      "Episode Reward: 0.0\n",
      "Step 214 (23159) @ Episode 92/10000, loss: 0.00078720878809690483\n",
      "Episode Reward: 1.0\n",
      "Step 207 (23366) @ Episode 93/10000, loss: 0.00303156999871134765\n",
      "Episode Reward: 1.0\n",
      "Step 323 (23689) @ Episode 94/10000, loss: 0.00813592784106731493\n",
      "Episode Reward: 3.0\n",
      "Step 268 (23957) @ Episode 95/10000, loss: 0.00080004858318716295\n",
      "Episode Reward: 2.0\n",
      "Step 222 (24179) @ Episode 96/10000, loss: 0.00065956386970356117\n",
      "Episode Reward: 1.0\n",
      "Step 269 (24448) @ Episode 97/10000, loss: 0.00072309805545955925\n",
      "Episode Reward: 2.0\n",
      "Step 315 (24763) @ Episode 98/10000, loss: 0.00223563914187252526\n",
      "Episode Reward: 3.0\n",
      "Step 160 (24923) @ Episode 99/10000, loss: 0.00044102541869506246\n",
      "Episode Reward: 0.0\n",
      "Step 168 (25091) @ Episode 100/10000, loss: 0.00028682773699983954\n",
      "Episode Reward: 0.0\n",
      "Step 266 (25357) @ Episode 101/10000, loss: 0.00652040774002671244\n",
      "Episode Reward: 2.0\n",
      "Step 313 (25670) @ Episode 102/10000, loss: 0.00091940199490636594\n",
      "Episode Reward: 3.0\n",
      "Step 174 (25844) @ Episode 103/10000, loss: 0.00118553976062685255\n",
      "Episode Reward: 0.0\n",
      "Step 188 (26032) @ Episode 104/10000, loss: 0.00057562626898288733\n",
      "Episode Reward: 0.0\n",
      "Step 389 (26421) @ Episode 105/10000, loss: 0.00019068192341364923\n",
      "Episode Reward: 4.0\n",
      "Step 275 (26696) @ Episode 106/10000, loss: 0.00107808015309274272\n",
      "Episode Reward: 2.0\n",
      "Step 247 (26943) @ Episode 107/10000, loss: 0.00281862216070294455\n",
      "Episode Reward: 2.0\n",
      "Step 177 (27120) @ Episode 108/10000, loss: 0.00119301676750183193\n",
      "Episode Reward: 0.0\n",
      "Step 309 (27429) @ Episode 109/10000, loss: 0.00094061269192025074\n",
      "Episode Reward: 2.0\n",
      "Step 202 (27631) @ Episode 110/10000, loss: 0.00050633057253435253\n",
      "Episode Reward: 0.0\n",
      "Step 367 (27998) @ Episode 111/10000, loss: 0.00016532497829757636\n",
      "Episode Reward: 3.0\n",
      "Step 177 (28175) @ Episode 112/10000, loss: 0.00023397376935463472\n",
      "Episode Reward: 0.0\n",
      "Step 242 (28417) @ Episode 113/10000, loss: 0.00011430610902607441\n",
      "Episode Reward: 2.0\n",
      "Step 303 (28720) @ Episode 114/10000, loss: 0.00027558440342545513\n",
      "Episode Reward: 2.0\n",
      "Step 328 (29048) @ Episode 115/10000, loss: 0.00086120236665010457\n",
      "Episode Reward: 3.0\n",
      "Step 162 (29210) @ Episode 116/10000, loss: 0.00030130497179925448\n",
      "Episode Reward: 0.0\n",
      "Step 173 (29383) @ Episode 117/10000, loss: 0.00035210762871429324\n",
      "Episode Reward: 0.0\n",
      "Step 169 (29552) @ Episode 118/10000, loss: 0.00083369936328381306\n",
      "Episode Reward: 0.0\n",
      "Step 419 (29971) @ Episode 119/10000, loss: 0.00018178528989665212\n",
      "Episode Reward: 4.0\n",
      "Step 28 (29999) @ Episode 120/10000, loss: 9.454211976844817e-057\n",
      "Copied model parameters to target network.\n",
      "Step 174 (30145) @ Episode 120/10000, loss: 0.00027993894764222205\n",
      "Episode Reward: 0.0\n",
      "Step 316 (30461) @ Episode 121/10000, loss: 0.00186807627324014943\n",
      "Episode Reward: 3.0\n",
      "Step 265 (30726) @ Episode 122/10000, loss: 0.00053623010171577334\n",
      "Episode Reward: 2.0\n",
      "Step 170 (30896) @ Episode 123/10000, loss: 0.00152821897063404326\n",
      "Episode Reward: 0.0\n",
      "Step 191 (31087) @ Episode 124/10000, loss: 0.00021219707559794188\n",
      "Episode Reward: 0.0\n",
      "Step 341 (31428) @ Episode 125/10000, loss: 0.00017725196084938943\n",
      "Episode Reward: 3.0\n",
      "Step 175 (31603) @ Episode 126/10000, loss: 0.00178739894181489945\n",
      "Episode Reward: 0.0\n",
      "Step 368 (31971) @ Episode 127/10000, loss: 0.00046292628394439816\n",
      "Episode Reward: 3.0\n",
      "Step 171 (32142) @ Episode 128/10000, loss: 0.00015713798347860575\n",
      "Episode Reward: 0.0\n",
      "Step 183 (32325) @ Episode 129/10000, loss: 0.00200623669661581517\n",
      "Episode Reward: 0.0\n",
      "Step 396 (32721) @ Episode 130/10000, loss: 0.00068778602872043856\n",
      "Episode Reward: 4.0\n",
      "Step 229 (32950) @ Episode 131/10000, loss: 0.00105426576919853696\n",
      "Episode Reward: 1.0\n",
      "Step 167 (33117) @ Episode 132/10000, loss: 0.00099952437449246644\n",
      "Episode Reward: 0.0\n",
      "Step 272 (33389) @ Episode 133/10000, loss: 0.00452445680275559435\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 177 (33566) @ Episode 134/10000, loss: 0.00047234538942575455\n",
      "Episode Reward: 0.0\n",
      "Step 167 (33733) @ Episode 135/10000, loss: 0.00134482106659561453\n",
      "Episode Reward: 0.0\n",
      "Step 398 (34131) @ Episode 136/10000, loss: 0.00037387543125078084\n",
      "Episode Reward: 4.0\n",
      "Step 302 (34433) @ Episode 137/10000, loss: 0.00014298036694526672\n",
      "Episode Reward: 2.0\n",
      "Step 163 (34596) @ Episode 138/10000, loss: 0.00131155294366180964\n",
      "Episode Reward: 0.0\n",
      "Step 182 (34778) @ Episode 139/10000, loss: 0.00568882096558809392\n",
      "Episode Reward: 0.0\n",
      "Step 300 (35078) @ Episode 140/10000, loss: 0.00018922863819170743\n",
      "Episode Reward: 2.0\n",
      "Step 275 (35353) @ Episode 141/10000, loss: 0.00033560147858224813\n",
      "Episode Reward: 2.0\n",
      "Step 216 (35569) @ Episode 142/10000, loss: 0.00032426312100142244\n",
      "Episode Reward: 1.0\n",
      "Step 287 (35856) @ Episode 143/10000, loss: 0.00207465561106801033\n",
      "Episode Reward: 2.0\n",
      "Step 279 (36135) @ Episode 144/10000, loss: 0.00118223158642649655\n",
      "Episode Reward: 2.0\n",
      "Step 243 (36378) @ Episode 145/10000, loss: 0.00069909414742141967\n",
      "Episode Reward: 1.0\n",
      "Step 218 (36596) @ Episode 146/10000, loss: 0.00042448783642612455\n",
      "Episode Reward: 1.0\n",
      "Step 377 (36973) @ Episode 147/10000, loss: 0.00133566500153392557\n",
      "Episode Reward: 3.0\n",
      "Step 359 (37332) @ Episode 148/10000, loss: 0.00019662264094222337\n",
      "Episode Reward: 3.0\n",
      "Step 169 (37501) @ Episode 149/10000, loss: 0.00088205019710585472\n",
      "Episode Reward: 0.0\n",
      "Step 437 (37938) @ Episode 150/10000, loss: 0.00016269533080048868\n",
      "Episode Reward: 5.0\n",
      "Step 166 (38104) @ Episode 151/10000, loss: 0.00040671863825991752\n",
      "Episode Reward: 0.0\n",
      "Step 369 (38473) @ Episode 152/10000, loss: 0.00107623939402401453\n",
      "Episode Reward: 4.0\n",
      "Step 353 (38826) @ Episode 153/10000, loss: 0.00065101060317829253\n",
      "Episode Reward: 3.0\n",
      "Step 182 (39008) @ Episode 154/10000, loss: 5.7985704188467935e-05\n",
      "Episode Reward: 0.0\n",
      "Step 270 (39278) @ Episode 155/10000, loss: 0.00015070743393152952\n",
      "Episode Reward: 2.0\n",
      "Step 166 (39444) @ Episode 156/10000, loss: 0.00091382337268441924\n",
      "Episode Reward: 0.0\n",
      "Step 252 (39696) @ Episode 157/10000, loss: 0.00037691864417865877\n",
      "Episode Reward: 1.0\n",
      "Step 218 (39914) @ Episode 158/10000, loss: 0.00015865683963056654\n",
      "Episode Reward: 1.0\n",
      "Step 85 (39999) @ Episode 159/10000, loss: 0.00043105822987854486\n",
      "Copied model parameters to target network.\n",
      "Step 192 (40106) @ Episode 159/10000, loss: 0.00161431799642741687\n",
      "Episode Reward: 0.0\n",
      "Step 362 (40468) @ Episode 160/10000, loss: 0.00023531874467153102\n",
      "Episode Reward: 4.0\n",
      "Step 220 (40688) @ Episode 161/10000, loss: 0.00188647804316133267\n",
      "Episode Reward: 1.0\n",
      "Step 251 (40939) @ Episode 162/10000, loss: 0.00032955763163045054\n",
      "Episode Reward: 1.0\n",
      "Step 417 (41356) @ Episode 163/10000, loss: 0.00484254863113164935\n",
      "Episode Reward: 4.0\n",
      "Step 217 (41573) @ Episode 164/10000, loss: 0.00260994071140885351\n",
      "Episode Reward: 1.0\n",
      "Step 180 (41753) @ Episode 165/10000, loss: 0.00139142596162855635\n",
      "Episode Reward: 0.0\n",
      "Step 176 (41929) @ Episode 166/10000, loss: 0.00032593315700069073\n",
      "Episode Reward: 0.0\n",
      "Step 184 (42113) @ Episode 167/10000, loss: 0.00102360290475189699\n",
      "Episode Reward: 0.0\n",
      "Step 231 (42344) @ Episode 168/10000, loss: 0.00083770556375384336\n",
      "Episode Reward: 1.0\n",
      "Step 260 (42604) @ Episode 169/10000, loss: 0.00046052294783294297\n",
      "Episode Reward: 2.0\n",
      "Step 316 (42920) @ Episode 170/10000, loss: 0.00027319445507600904\n",
      "Episode Reward: 2.0\n",
      "Step 264 (43184) @ Episode 171/10000, loss: 0.00034404415055178106\n",
      "Episode Reward: 1.0\n",
      "Step 164 (43348) @ Episode 172/10000, loss: 0.00019330721988808364\n",
      "Episode Reward: 0.0\n",
      "Step 237 (43585) @ Episode 173/10000, loss: 0.00063306151423603317\n",
      "Episode Reward: 1.0\n",
      "Step 358 (43943) @ Episode 174/10000, loss: 0.00017527797899674624\n",
      "Episode Reward: 3.0\n",
      "Step 236 (44179) @ Episode 175/10000, loss: 0.00097927986644208434\n",
      "Episode Reward: 1.0\n",
      "Step 224 (44403) @ Episode 176/10000, loss: 0.00404649041593074866\n",
      "Episode Reward: 1.0\n",
      "Step 261 (44664) @ Episode 177/10000, loss: 0.00243947049602866174\n",
      "Episode Reward: 2.0\n",
      "Step 182 (44846) @ Episode 178/10000, loss: 0.00358722987584769736\n",
      "Episode Reward: 0.0\n",
      "Step 218 (45064) @ Episode 179/10000, loss: 0.02858226932585239468\n",
      "Episode Reward: 1.0\n",
      "Step 335 (45399) @ Episode 180/10000, loss: 0.01335663534700870513\n",
      "Episode Reward: 3.0\n",
      "Step 180 (45579) @ Episode 181/10000, loss: 0.00110959319863468486\n",
      "Episode Reward: 0.0\n",
      "Step 234 (45813) @ Episode 182/10000, loss: 0.00105929258279502421\n",
      "Episode Reward: 1.0\n",
      "Step 210 (46023) @ Episode 183/10000, loss: 0.01194091420620679968\n",
      "Episode Reward: 1.0\n",
      "Step 255 (46278) @ Episode 184/10000, loss: 0.00262058130465447927\n",
      "Episode Reward: 1.0\n",
      "Step 237 (46515) @ Episode 185/10000, loss: 0.00053975166520103816\n",
      "Episode Reward: 1.0\n",
      "Step 366 (46881) @ Episode 186/10000, loss: 0.00082357804058119658\n",
      "Episode Reward: 3.0\n",
      "Step 310 (47191) @ Episode 187/10000, loss: 0.00038930945447646087\n",
      "Episode Reward: 3.0\n",
      "Step 413 (47604) @ Episode 188/10000, loss: 0.00085076194955036043\n",
      "Episode Reward: 4.0\n",
      "Step 173 (47777) @ Episode 189/10000, loss: 7.076525798765942e-055\n",
      "Episode Reward: 0.0\n",
      "Step 172 (47949) @ Episode 190/10000, loss: 0.00014352488506119698\n",
      "Episode Reward: 0.0\n",
      "Step 179 (48128) @ Episode 191/10000, loss: 0.00113874510861933235\n",
      "Episode Reward: 0.0\n",
      "Step 360 (48488) @ Episode 192/10000, loss: 0.00108424562495201834\n",
      "Episode Reward: 4.0\n",
      "Step 263 (48751) @ Episode 193/10000, loss: 0.00017058361845556647\n",
      "Episode Reward: 2.0\n",
      "Step 225 (48976) @ Episode 194/10000, loss: 0.00153506628703325994\n",
      "Episode Reward: 1.0\n",
      "Step 179 (49155) @ Episode 195/10000, loss: 0.00014290657418314368\n",
      "Episode Reward: 0.0\n",
      "Step 176 (49331) @ Episode 196/10000, loss: 0.00373749574646353762\n",
      "Episode Reward: 0.0\n",
      "Step 361 (49692) @ Episode 197/10000, loss: 0.00300086010247468959\n",
      "Episode Reward: 4.0\n",
      "Step 307 (49999) @ Episode 198/10000, loss: 8.62603192217648e-0515\n",
      "Copied model parameters to target network.\n",
      "Step 367 (50059) @ Episode 198/10000, loss: 0.00100526737514883286\n",
      "Episode Reward: 4.0\n",
      "Step 173 (50232) @ Episode 199/10000, loss: 0.00203328253701329235\n",
      "Episode Reward: 0.0\n",
      "Step 178 (50410) @ Episode 200/10000, loss: 0.00246502202935516834\n",
      "Episode Reward: 0.0\n",
      "Step 166 (50576) @ Episode 201/10000, loss: 0.00012717596837319434\n",
      "Episode Reward: 0.0\n",
      "Step 163 (50739) @ Episode 202/10000, loss: 0.00141063448973000052\n",
      "Episode Reward: 0.0\n",
      "Step 174 (50913) @ Episode 203/10000, loss: 0.00067819515243172657\n",
      "Episode Reward: 0.0\n",
      "Step 232 (51145) @ Episode 204/10000, loss: 0.00149690906982868992\n",
      "Episode Reward: 1.0\n",
      "Step 325 (51470) @ Episode 205/10000, loss: 0.00090691744117066267\n",
      "Episode Reward: 3.0\n",
      "Step 225 (51695) @ Episode 206/10000, loss: 0.00077032309491187337\n",
      "Episode Reward: 1.0\n",
      "Step 188 (51883) @ Episode 207/10000, loss: 0.00017626755288802087\n",
      "Episode Reward: 0.0\n",
      "Step 304 (52187) @ Episode 208/10000, loss: 0.00053438951727002863\n",
      "Episode Reward: 2.0\n",
      "Step 215 (52402) @ Episode 209/10000, loss: 0.00176605675369501116\n",
      "Episode Reward: 1.0\n",
      "Step 291 (52693) @ Episode 210/10000, loss: 0.00075006124097853963\n",
      "Episode Reward: 2.0\n",
      "Step 269 (52962) @ Episode 211/10000, loss: 0.00021246561664156616\n",
      "Episode Reward: 2.0\n",
      "Step 240 (53202) @ Episode 212/10000, loss: 0.00014170554641168565\n",
      "Episode Reward: 1.0\n",
      "Step 210 (53412) @ Episode 213/10000, loss: 0.00073487305780872763\n",
      "Episode Reward: 1.0\n",
      "Step 240 (53652) @ Episode 214/10000, loss: 0.00026737287407740959\n",
      "Episode Reward: 1.0\n",
      "Step 184 (53836) @ Episode 215/10000, loss: 0.00025936728343367577\n",
      "Episode Reward: 0.0\n",
      "Step 167 (54003) @ Episode 216/10000, loss: 0.00028426796779967844\n",
      "Episode Reward: 0.0\n",
      "Step 299 (54302) @ Episode 217/10000, loss: 0.00051718053873628383\n",
      "Episode Reward: 2.0\n",
      "Step 367 (54669) @ Episode 218/10000, loss: 0.00053380907047539956\n",
      "Episode Reward: 4.0\n",
      "Step 359 (55028) @ Episode 219/10000, loss: 0.00022403123148251325\n",
      "Episode Reward: 3.0\n",
      "Step 298 (55326) @ Episode 220/10000, loss: 0.00020366287208162248\n",
      "Episode Reward: 2.0\n",
      "Step 300 (55626) @ Episode 221/10000, loss: 0.00015555336722172797\n",
      "Episode Reward: 2.0\n",
      "Step 173 (55799) @ Episode 222/10000, loss: 0.00014021736569702625\n",
      "Episode Reward: 0.0\n",
      "Step 273 (56072) @ Episode 223/10000, loss: 0.00061552971601486217\n",
      "Episode Reward: 2.0\n",
      "Step 283 (56355) @ Episode 224/10000, loss: 0.00013997922360431403\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 238 (56593) @ Episode 225/10000, loss: 0.00217863311991095548\n",
      "Episode Reward: 1.0\n",
      "Step 374 (56967) @ Episode 226/10000, loss: 7.177166116889566e-056\n",
      "Episode Reward: 3.0\n",
      "Step 285 (57252) @ Episode 227/10000, loss: 0.00039016478694975376\n",
      "Episode Reward: 2.0\n",
      "Step 298 (57550) @ Episode 228/10000, loss: 0.00136398593895137327\n",
      "Episode Reward: 2.0\n",
      "Step 232 (57782) @ Episode 229/10000, loss: 0.00019460721523500983\n",
      "Episode Reward: 1.0\n",
      "Step 177 (57959) @ Episode 230/10000, loss: 6.313798076007515e-053\n",
      "Episode Reward: 0.0\n",
      "Step 347 (58306) @ Episode 231/10000, loss: 0.00011784055095631629\n",
      "Episode Reward: 3.0\n",
      "Step 287 (58593) @ Episode 232/10000, loss: 0.00191057962365448477\n",
      "Episode Reward: 2.0\n",
      "Step 239 (58832) @ Episode 233/10000, loss: 0.00136389432009309534\n",
      "Episode Reward: 1.0\n",
      "Step 270 (59102) @ Episode 234/10000, loss: 0.00024770497111603621\n",
      "Episode Reward: 2.0\n",
      "Step 262 (59364) @ Episode 235/10000, loss: 0.00036403501871973276\n",
      "Episode Reward: 1.0\n",
      "Step 174 (59538) @ Episode 236/10000, loss: 0.00625737151131033955\n",
      "Episode Reward: 0.0\n",
      "Step 172 (59710) @ Episode 237/10000, loss: 0.00013626013242173943\n",
      "Episode Reward: 0.0\n",
      "Step 218 (59928) @ Episode 238/10000, loss: 0.00015888751659076668\n",
      "Episode Reward: 1.0\n",
      "Step 71 (59999) @ Episode 239/10000, loss: 0.00010030481644207612\n",
      "Copied model parameters to target network.\n",
      "Step 331 (60259) @ Episode 239/10000, loss: 0.06542430818080902557\n",
      "Episode Reward: 4.0\n",
      "Step 270 (60529) @ Episode 240/10000, loss: 0.00213048281148076065\n",
      "Episode Reward: 2.0\n",
      "Step 189 (60718) @ Episode 241/10000, loss: 0.00072355708107352263\n",
      "Episode Reward: 0.0\n",
      "Step 176 (60894) @ Episode 242/10000, loss: 0.00046495013521052897\n",
      "Episode Reward: 0.0\n",
      "Step 168 (61062) @ Episode 243/10000, loss: 0.00164592673536390077\n",
      "Episode Reward: 0.0\n",
      "Step 216 (61278) @ Episode 244/10000, loss: 0.00053476367611438047\n",
      "Episode Reward: 1.0\n",
      "Step 158 (61436) @ Episode 245/10000, loss: 0.00173279305454343566\n",
      "Episode Reward: 0.0\n",
      "Step 188 (61624) @ Episode 246/10000, loss: 0.00066916918149217964\n",
      "Episode Reward: 0.0\n",
      "Step 277 (61901) @ Episode 247/10000, loss: 0.00048913096543401484\n",
      "Episode Reward: 2.0\n",
      "Step 267 (62168) @ Episode 248/10000, loss: 0.00284878280945122244\n",
      "Episode Reward: 2.0\n",
      "Step 230 (62398) @ Episode 249/10000, loss: 0.00076411134796217085\n",
      "Episode Reward: 1.0\n",
      "Step 221 (62619) @ Episode 250/10000, loss: 0.00053456646855920555\n",
      "Episode Reward: 1.0\n",
      "Step 178 (62797) @ Episode 251/10000, loss: 0.00078230549115687614\n",
      "Episode Reward: 0.0\n",
      "Step 233 (63030) @ Episode 252/10000, loss: 0.00029113865457475185\n",
      "Episode Reward: 1.0\n",
      "Step 240 (63270) @ Episode 253/10000, loss: 8.4935876657255e-05352\n",
      "Episode Reward: 1.0\n",
      "Step 168 (63438) @ Episode 254/10000, loss: 0.00035747679066844285\n",
      "Episode Reward: 0.0\n",
      "Step 239 (63677) @ Episode 255/10000, loss: 0.00017467964789830148\n",
      "Episode Reward: 1.0\n",
      "Step 158 (63835) @ Episode 256/10000, loss: 0.00224297470413148417\n",
      "Episode Reward: 0.0\n",
      "Step 356 (64191) @ Episode 257/10000, loss: 6.888364441692829e-052\n",
      "Episode Reward: 3.0\n",
      "Step 212 (64403) @ Episode 258/10000, loss: 0.00025146405096165836\n",
      "Episode Reward: 1.0\n",
      "Step 443 (64846) @ Episode 259/10000, loss: 0.00125217100139707334\n",
      "Episode Reward: 4.0\n",
      "Step 267 (65113) @ Episode 260/10000, loss: 0.00025100458879023796\n",
      "Episode Reward: 2.0\n",
      "Step 200 (65313) @ Episode 261/10000, loss: 0.00058348895981907842\n",
      "Episode Reward: 1.0\n",
      "Step 334 (65647) @ Episode 262/10000, loss: 0.00102584878914058255\n",
      "Episode Reward: 3.0\n",
      "Step 291 (65938) @ Episode 263/10000, loss: 0.00054969883058220154\n",
      "Episode Reward: 2.0\n",
      "Step 167 (66105) @ Episode 264/10000, loss: 0.00048265871009789407\n",
      "Episode Reward: 0.0\n",
      "Step 201 (66306) @ Episode 265/10000, loss: 0.00091747072292491795\n",
      "Episode Reward: 1.0\n",
      "Step 208 (66514) @ Episode 266/10000, loss: 5.5253061873372644e-05\n",
      "Episode Reward: 1.0\n",
      "Step 289 (66803) @ Episode 267/10000, loss: 0.00375889171846210968\n",
      "Episode Reward: 1.0\n",
      "Step 184 (66987) @ Episode 268/10000, loss: 0.00118780974298715674\n",
      "Episode Reward: 0.0\n",
      "Step 172 (67159) @ Episode 269/10000, loss: 0.00010344116162741557\n",
      "Episode Reward: 0.0\n",
      "Step 214 (67373) @ Episode 270/10000, loss: 9.250819857697934e-053\n",
      "Episode Reward: 1.0\n",
      "Step 165 (67538) @ Episode 271/10000, loss: 0.00050707545597106227\n",
      "Episode Reward: 0.0\n",
      "Step 339 (67877) @ Episode 272/10000, loss: 0.00010544434189796448\n",
      "Episode Reward: 3.0\n",
      "Step 180 (68057) @ Episode 273/10000, loss: 0.00010015349835157394\n",
      "Episode Reward: 0.0\n",
      "Step 279 (68336) @ Episode 274/10000, loss: 0.00056102208327502016\n",
      "Episode Reward: 2.0\n",
      "Step 317 (68653) @ Episode 275/10000, loss: 0.00088214856805279858\n",
      "Episode Reward: 3.0\n",
      "Step 284 (68937) @ Episode 276/10000, loss: 0.00017258567095268518\n",
      "Episode Reward: 2.0\n",
      "Step 212 (69149) @ Episode 277/10000, loss: 9.898045391310006e-053\n",
      "Episode Reward: 1.0\n",
      "Step 204 (69353) @ Episode 278/10000, loss: 0.00054181524319574244\n",
      "Episode Reward: 1.0\n",
      "Step 163 (69516) @ Episode 279/10000, loss: 0.00381667912006378178\n",
      "Episode Reward: 0.0\n",
      "Step 178 (69694) @ Episode 280/10000, loss: 0.00076209660619497328\n",
      "Episode Reward: 0.0\n",
      "Step 240 (69934) @ Episode 281/10000, loss: 0.00010762204328784719\n",
      "Episode Reward: 1.0\n",
      "Step 65 (69999) @ Episode 282/10000, loss: 0.00017175616812892258\n",
      "Copied model parameters to target network.\n",
      "Step 232 (70166) @ Episode 282/10000, loss: 0.00101189396809786562\n",
      "Episode Reward: 1.0\n",
      "Step 315 (70481) @ Episode 283/10000, loss: 0.00103411660529673173\n",
      "Episode Reward: 3.0\n",
      "Step 337 (70818) @ Episode 284/10000, loss: 0.00105480127967894086\n",
      "Episode Reward: 3.0\n",
      "Step 176 (70994) @ Episode 285/10000, loss: 0.00428576115518808492\n",
      "Episode Reward: 0.0\n",
      "Step 404 (71398) @ Episode 286/10000, loss: 0.00029411533614620566\n",
      "Episode Reward: 3.0\n",
      "Step 242 (71640) @ Episode 287/10000, loss: 0.00083318213000893595\n",
      "Episode Reward: 1.0\n",
      "Step 298 (71938) @ Episode 288/10000, loss: 0.00022277212701737885\n",
      "Episode Reward: 2.0\n",
      "Step 206 (72144) @ Episode 289/10000, loss: 0.00216511567123234273\n",
      "Episode Reward: 1.0\n",
      "Step 284 (72428) @ Episode 290/10000, loss: 0.00108660385012626658\n",
      "Episode Reward: 2.0\n",
      "Step 277 (72705) @ Episode 291/10000, loss: 0.00177835545036941776\n",
      "Episode Reward: 2.0\n",
      "Step 215 (72920) @ Episode 292/10000, loss: 0.00089395866962149746\n",
      "Episode Reward: 1.0\n",
      "Step 229 (73149) @ Episode 293/10000, loss: 0.00558522948995232635\n",
      "Episode Reward: 1.0\n",
      "Step 242 (73391) @ Episode 294/10000, loss: 0.00033278675982728686\n",
      "Episode Reward: 1.0\n",
      "Step 172 (73563) @ Episode 295/10000, loss: 0.00044204285950399935\n",
      "Episode Reward: 0.0\n",
      "Step 312 (73875) @ Episode 296/10000, loss: 0.00173835235182195954\n",
      "Episode Reward: 3.0\n",
      "Step 411 (74286) @ Episode 297/10000, loss: 7.204902067314833e-055\n",
      "Episode Reward: 4.0\n",
      "Step 287 (74573) @ Episode 298/10000, loss: 0.00013703954755328596\n",
      "Episode Reward: 2.0\n",
      "Step 174 (74747) @ Episode 299/10000, loss: 0.00264042313210666266\n",
      "Episode Reward: 0.0\n",
      "Step 238 (74985) @ Episode 300/10000, loss: 0.00054336182074621323\n",
      "Episode Reward: 1.0\n",
      "Step 203 (75188) @ Episode 301/10000, loss: 0.00203715404495596953\n",
      "Episode Reward: 1.0\n",
      "Step 180 (75368) @ Episode 302/10000, loss: 0.00038562755798920995\n",
      "Episode Reward: 0.0\n",
      "Step 257 (75625) @ Episode 303/10000, loss: 0.00025111553259193897\n",
      "Episode Reward: 2.0\n",
      "Step 235 (75860) @ Episode 304/10000, loss: 0.00157663726713508376\n",
      "Episode Reward: 2.0\n",
      "Step 166 (76026) @ Episode 305/10000, loss: 0.00013418165326584135\n",
      "Episode Reward: 0.0\n",
      "Step 192 (76218) @ Episode 306/10000, loss: 0.00021812514751218265\n",
      "Episode Reward: 0.0\n",
      "Step 175 (76393) @ Episode 307/10000, loss: 0.00047918077325448394\n",
      "Episode Reward: 0.0\n",
      "Step 266 (76659) @ Episode 308/10000, loss: 0.00032889255089685323\n",
      "Episode Reward: 2.0\n",
      "Step 200 (76859) @ Episode 309/10000, loss: 0.00193053972907364376\n",
      "Episode Reward: 1.0\n",
      "Step 184 (77043) @ Episode 310/10000, loss: 0.00117610371671617033\n",
      "Episode Reward: 0.0\n",
      "Step 238 (77281) @ Episode 311/10000, loss: 0.00079604610800743124\n",
      "Episode Reward: 1.0\n",
      "Step 172 (77453) @ Episode 312/10000, loss: 0.00018729378643911332\n",
      "Episode Reward: 0.0\n",
      "Step 249 (77702) @ Episode 313/10000, loss: 0.00018018750415649265\n",
      "Episode Reward: 1.0\n",
      "Step 210 (77912) @ Episode 314/10000, loss: 0.00114223803393542773\n",
      "Episode Reward: 1.0\n",
      "Step 321 (78233) @ Episode 315/10000, loss: 0.00039015081711113453\n",
      "Episode Reward: 3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 323 (78556) @ Episode 316/10000, loss: 8.948079630499706e-054\n",
      "Episode Reward: 3.0\n",
      "Step 179 (78735) @ Episode 317/10000, loss: 0.00017801733338274062\n",
      "Episode Reward: 0.0\n",
      "Step 239 (78974) @ Episode 318/10000, loss: 0.00040635064942762256\n",
      "Episode Reward: 1.0\n",
      "Step 247 (79221) @ Episode 319/10000, loss: 0.00053886062232777487\n",
      "Episode Reward: 1.0\n",
      "Step 226 (79447) @ Episode 320/10000, loss: 7.202826964203268e-053\n",
      "Episode Reward: 1.0\n",
      "Step 165 (79612) @ Episode 321/10000, loss: 0.00028594135073944926\n",
      "Episode Reward: 0.0\n",
      "Step 234 (79846) @ Episode 322/10000, loss: 0.00083017593715339973\n",
      "Episode Reward: 1.0\n",
      "Step 153 (79999) @ Episode 323/10000, loss: 0.00059301167493686088\n",
      "Copied model parameters to target network.\n",
      "Step 253 (80099) @ Episode 323/10000, loss: 0.00048633720143698156\n",
      "Episode Reward: 1.0\n",
      "Step 198 (80297) @ Episode 324/10000, loss: 0.00021751338499598205\n",
      "Episode Reward: 1.0\n",
      "Step 183 (80480) @ Episode 325/10000, loss: 0.00209409696981310842\n",
      "Episode Reward: 0.0\n",
      "Step 401 (80881) @ Episode 326/10000, loss: 0.00508094578981399523\n",
      "Episode Reward: 4.0\n",
      "Step 301 (81182) @ Episode 327/10000, loss: 0.00374565506353974343\n",
      "Episode Reward: 2.0\n",
      "Step 227 (81409) @ Episode 328/10000, loss: 0.00028814232791773975\n",
      "Episode Reward: 1.0\n",
      "Step 461 (81870) @ Episode 329/10000, loss: 0.00044124518171884125\n",
      "Episode Reward: 5.0\n",
      "Step 245 (82115) @ Episode 330/10000, loss: 0.00106358376797288666\n",
      "Episode Reward: 2.0\n",
      "Step 395 (82510) @ Episode 331/10000, loss: 0.00207625632174313074\n",
      "Episode Reward: 4.0\n",
      "Step 377 (82887) @ Episode 332/10000, loss: 0.00039742793887853626\n",
      "Episode Reward: 4.0\n",
      "Step 332 (83219) @ Episode 333/10000, loss: 0.00076269131386652595\n",
      "Episode Reward: 3.0\n",
      "Step 349 (83568) @ Episode 334/10000, loss: 0.00185378675814718114\n",
      "Episode Reward: 3.0\n",
      "Step 409 (83977) @ Episode 335/10000, loss: 0.00113172945566475488\n",
      "Episode Reward: 4.0\n",
      "Step 303 (84280) @ Episode 336/10000, loss: 0.00037205364787951114\n",
      "Episode Reward: 2.0\n",
      "Step 266 (84546) @ Episode 337/10000, loss: 0.00139230198692530464\n",
      "Episode Reward: 2.0\n",
      "Step 331 (84877) @ Episode 338/10000, loss: 0.00147782033309340487\n",
      "Episode Reward: 3.0\n",
      "Step 294 (85171) @ Episode 339/10000, loss: 0.00098400318529456858\n",
      "Episode Reward: 2.0\n",
      "Step 186 (85357) @ Episode 340/10000, loss: 0.00012279751535970718\n",
      "Episode Reward: 0.0\n",
      "Step 246 (85603) @ Episode 341/10000, loss: 6.775620568078011e-055\n",
      "Episode Reward: 1.0\n",
      "Step 174 (85777) @ Episode 342/10000, loss: 0.00034603269887156785\n",
      "Episode Reward: 0.0\n",
      "Step 168 (85945) @ Episode 343/10000, loss: 0.00010656115046003833\n",
      "Episode Reward: 0.0\n",
      "Step 195 (86140) @ Episode 344/10000, loss: 0.00020688054792117327\n",
      "Episode Reward: 0.0\n",
      "Step 507 (86647) @ Episode 345/10000, loss: 5.245338979875669e-054\n",
      "Episode Reward: 6.0\n",
      "Step 174 (86821) @ Episode 346/10000, loss: 0.00053097202908247713\n",
      "Episode Reward: 0.0\n",
      "Step 189 (87010) @ Episode 347/10000, loss: 0.00414146250113844976\n",
      "Episode Reward: 0.0\n",
      "Step 172 (87182) @ Episode 348/10000, loss: 8.754206646699458e-057\n",
      "Episode Reward: 0.0\n",
      "Step 175 (87357) @ Episode 349/10000, loss: 0.00062453263672068727\n",
      "Episode Reward: 0.0\n",
      "Step 275 (87632) @ Episode 350/10000, loss: 0.00051933381473645572\n",
      "Episode Reward: 2.0\n",
      "Step 185 (87817) @ Episode 351/10000, loss: 0.00117902306374162445\n",
      "Episode Reward: 0.0\n",
      "Step 233 (88050) @ Episode 352/10000, loss: 0.00080267339944839486\n",
      "Episode Reward: 1.0\n",
      "Step 168 (88218) @ Episode 353/10000, loss: 0.00325444596819579668\n",
      "Episode Reward: 0.0\n",
      "Step 175 (88393) @ Episode 354/10000, loss: 0.00039268317050300546\n",
      "Episode Reward: 0.0\n",
      "Step 312 (88705) @ Episode 355/10000, loss: 0.00075491308234632027\n",
      "Episode Reward: 2.0\n",
      "Step 206 (88911) @ Episode 356/10000, loss: 0.00364551576785743244\n",
      "Episode Reward: 1.0\n",
      "Step 370 (89281) @ Episode 357/10000, loss: 0.00027191051049157977\n",
      "Episode Reward: 3.0\n",
      "Step 295 (89576) @ Episode 358/10000, loss: 0.00021400573314167564\n",
      "Episode Reward: 2.0\n",
      "Step 170 (89746) @ Episode 359/10000, loss: 0.00039697828469797975\n",
      "Episode Reward: 0.0\n",
      "Step 253 (89999) @ Episode 360/10000, loss: 0.00076295470353215936\n",
      "Copied model parameters to target network.\n",
      "Step 397 (90143) @ Episode 360/10000, loss: 0.00126309297047555456\n",
      "Episode Reward: 4.0\n",
      "Step 284 (90427) @ Episode 361/10000, loss: 0.00930806435644626635\n",
      "Episode Reward: 2.0\n",
      "Step 346 (90773) @ Episode 362/10000, loss: 0.00246387114748358732\n",
      "Episode Reward: 3.0\n",
      "Step 181 (90954) @ Episode 363/10000, loss: 0.00068353407550603157\n",
      "Episode Reward: 0.0\n",
      "Step 241 (91195) @ Episode 364/10000, loss: 0.00145093700848519826\n",
      "Episode Reward: 1.0\n",
      "Step 176 (91371) @ Episode 365/10000, loss: 0.00017086286970879883\n",
      "Episode Reward: 0.0\n",
      "Step 179 (91550) @ Episode 366/10000, loss: 0.00754333520308136965\n",
      "Episode Reward: 0.0\n",
      "Step 395 (91945) @ Episode 367/10000, loss: 0.00112584256567060954\n",
      "Episode Reward: 5.0\n",
      "Step 183 (92128) @ Episode 368/10000, loss: 0.00015476296539418493\n",
      "Episode Reward: 0.0\n",
      "Step 655 (92783) @ Episode 369/10000, loss: 0.00064314936753362427\n",
      "Episode Reward: 8.0\n",
      "Step 266 (93049) @ Episode 370/10000, loss: 0.00477548269554972656\n",
      "Episode Reward: 2.0\n",
      "Step 227 (93276) @ Episode 371/10000, loss: 0.00101386662572622326\n",
      "Episode Reward: 1.0\n",
      "Step 258 (93534) @ Episode 372/10000, loss: 0.00036705256206914783\n",
      "Episode Reward: 2.0\n",
      "Step 169 (93703) @ Episode 373/10000, loss: 0.00664633279666304616\n",
      "Episode Reward: 0.0\n",
      "Step 217 (93920) @ Episode 374/10000, loss: 0.00176226720213890087\n",
      "Episode Reward: 1.0\n",
      "Step 207 (94127) @ Episode 375/10000, loss: 0.00110302097164094456\n",
      "Episode Reward: 1.0\n",
      "Step 183 (94310) @ Episode 376/10000, loss: 0.00105887057725340134\n",
      "Episode Reward: 0.0\n",
      "Step 276 (94586) @ Episode 377/10000, loss: 0.00083370960783213384\n",
      "Episode Reward: 2.0\n",
      "Step 304 (94890) @ Episode 378/10000, loss: 0.00120360753498971463\n",
      "Episode Reward: 2.0\n",
      "Step 171 (95061) @ Episode 379/10000, loss: 0.00047356792492792013\n",
      "Episode Reward: 0.0\n",
      "Step 184 (95245) @ Episode 380/10000, loss: 0.00032749969977885485\n",
      "Episode Reward: 0.0\n",
      "Step 532 (95777) @ Episode 381/10000, loss: 0.00018155222642235458\n",
      "Episode Reward: 6.0\n",
      "Step 207 (95984) @ Episode 382/10000, loss: 0.00266330433078110236\n",
      "Episode Reward: 1.0\n",
      "Step 363 (96347) @ Episode 383/10000, loss: 0.00126758846454322342\n",
      "Episode Reward: 3.0\n",
      "Step 330 (96677) @ Episode 384/10000, loss: 0.00130026089027524076\n",
      "Episode Reward: 3.0\n",
      "Step 170 (96847) @ Episode 385/10000, loss: 0.00030828034505248073\n",
      "Episode Reward: 0.0\n",
      "Step 279 (97126) @ Episode 386/10000, loss: 0.00032660638680681586\n",
      "Episode Reward: 2.0\n",
      "Step 351 (97477) @ Episode 387/10000, loss: 7.465910312021151e-052\n",
      "Episode Reward: 4.0\n",
      "Step 333 (97810) @ Episode 388/10000, loss: 0.00021584711794275793\n",
      "Episode Reward: 3.0\n",
      "Step 167 (97977) @ Episode 389/10000, loss: 0.00221129693090915775\n",
      "Episode Reward: 0.0\n",
      "Step 336 (98313) @ Episode 390/10000, loss: 0.00026490335585549474\n",
      "Episode Reward: 3.0\n",
      "Step 176 (98489) @ Episode 391/10000, loss: 0.00048025613068602987\n",
      "Episode Reward: 0.0\n",
      "Step 206 (98695) @ Episode 392/10000, loss: 0.00011126021854579449\n",
      "Episode Reward: 1.0\n",
      "Step 293 (98988) @ Episode 393/10000, loss: 0.00012800007243640725\n",
      "Episode Reward: 2.0\n",
      "Step 177 (99165) @ Episode 394/10000, loss: 0.00067218684125691657\n",
      "Episode Reward: 0.0\n",
      "Step 210 (99375) @ Episode 395/10000, loss: 0.00015988234372343868\n",
      "Episode Reward: 1.0\n",
      "Step 163 (99538) @ Episode 396/10000, loss: 0.00061857659602537755\n",
      "Episode Reward: 0.0\n",
      "Step 173 (99711) @ Episode 397/10000, loss: 0.00018230667046736926\n",
      "Episode Reward: 0.0\n",
      "Step 288 (99999) @ Episode 398/10000, loss: 0.00026829744456335955\n",
      "Copied model parameters to target network.\n",
      "Step 338 (100049) @ Episode 398/10000, loss: 0.2158396691083908069\n",
      "Episode Reward: 3.0\n",
      "Step 172 (100221) @ Episode 399/10000, loss: 0.00579995010048151266\n",
      "Episode Reward: 0.0\n",
      "Step 173 (100394) @ Episode 400/10000, loss: 0.00204718858003616337\n",
      "Episode Reward: 0.0\n",
      "Step 316 (100710) @ Episode 401/10000, loss: 0.00184199272189289334\n",
      "Episode Reward: 2.0\n",
      "Step 162 (100872) @ Episode 402/10000, loss: 0.00036752969026565557\n",
      "Episode Reward: 0.0\n",
      "Step 200 (101072) @ Episode 403/10000, loss: 0.00032270784140564585\n",
      "Episode Reward: 1.0\n",
      "Step 277 (101349) @ Episode 404/10000, loss: 0.00052876333938911563\n",
      "Episode Reward: 2.0\n",
      "Step 172 (101521) @ Episode 405/10000, loss: 0.00027149039669893684\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 304 (101825) @ Episode 406/10000, loss: 0.00090742064639925967\n",
      "Episode Reward: 3.0\n",
      "Step 232 (102057) @ Episode 407/10000, loss: 0.00032797112362459396\n",
      "Episode Reward: 1.0\n",
      "Step 181 (102238) @ Episode 408/10000, loss: 0.00049312872579321272\n",
      "Episode Reward: 0.0\n",
      "Step 383 (102621) @ Episode 409/10000, loss: 0.00054842547979205856\n",
      "Episode Reward: 3.0\n",
      "Step 179 (102800) @ Episode 410/10000, loss: 0.00120012986008077867\n",
      "Episode Reward: 0.0\n",
      "Step 236 (103036) @ Episode 411/10000, loss: 0.00234911614097654864\n",
      "Episode Reward: 1.0\n",
      "Step 169 (103205) @ Episode 412/10000, loss: 0.00082276685861870654\n",
      "Episode Reward: 0.0\n",
      "Step 371 (103576) @ Episode 413/10000, loss: 0.00152784679085016253\n",
      "Episode Reward: 4.0\n",
      "Step 405 (103981) @ Episode 414/10000, loss: 0.00056665396550670277\n",
      "Episode Reward: 4.0\n",
      "Step 244 (104225) @ Episode 415/10000, loss: 0.00097458640811964873\n",
      "Episode Reward: 1.0\n",
      "Step 280 (104505) @ Episode 416/10000, loss: 0.00175046396907418974\n",
      "Episode Reward: 2.0\n",
      "Step 223 (104728) @ Episode 417/10000, loss: 0.00100797764025628573\n",
      "Episode Reward: 1.0\n",
      "Step 173 (104901) @ Episode 418/10000, loss: 0.00100797670893371168\n",
      "Episode Reward: 0.0\n",
      "Step 227 (105128) @ Episode 419/10000, loss: 0.00068215641658753166\n",
      "Episode Reward: 1.0\n",
      "Step 253 (105381) @ Episode 420/10000, loss: 0.00139537302311509854\n",
      "Episode Reward: 1.0\n",
      "Step 426 (105807) @ Episode 421/10000, loss: 0.00017265652422793216\n",
      "Episode Reward: 5.0\n",
      "Step 180 (105987) @ Episode 422/10000, loss: 0.00022101041395217189\n",
      "Episode Reward: 0.0\n",
      "Step 215 (106202) @ Episode 423/10000, loss: 0.00022406355128623545\n",
      "Episode Reward: 1.0\n",
      "Step 211 (106413) @ Episode 424/10000, loss: 0.00034297636011615396\n",
      "Episode Reward: 1.0\n",
      "Step 165 (106578) @ Episode 425/10000, loss: 0.00034588066046126187\n",
      "Episode Reward: 0.0\n",
      "Step 222 (106800) @ Episode 426/10000, loss: 0.00017762326751835644\n",
      "Episode Reward: 1.0\n",
      "Step 320 (107120) @ Episode 427/10000, loss: 0.00048118358245119453\n",
      "Episode Reward: 2.0\n",
      "Step 280 (107400) @ Episode 428/10000, loss: 0.00013344213948585093\n",
      "Episode Reward: 2.0\n",
      "Step 281 (107681) @ Episode 429/10000, loss: 0.00014345863019116223\n",
      "Episode Reward: 2.0\n",
      "Step 347 (108028) @ Episode 430/10000, loss: 0.00081555673386901625\n",
      "Episode Reward: 3.0\n",
      "Step 173 (108201) @ Episode 431/10000, loss: 0.00260061584413051626\n",
      "Episode Reward: 0.0\n",
      "Step 396 (108597) @ Episode 432/10000, loss: 0.00017075118375942112\n",
      "Episode Reward: 4.0\n",
      "Step 209 (108806) @ Episode 433/10000, loss: 0.00035112962359562516\n",
      "Episode Reward: 1.0\n",
      "Step 241 (109047) @ Episode 434/10000, loss: 0.00215232046321034433\n",
      "Episode Reward: 1.0\n",
      "Step 475 (109522) @ Episode 435/10000, loss: 0.00172204640693962577\n",
      "Episode Reward: 6.0\n",
      "Step 277 (109799) @ Episode 436/10000, loss: 0.00043351767817512155\n",
      "Episode Reward: 2.0\n",
      "Step 200 (109999) @ Episode 437/10000, loss: 0.00307619338855147364\n",
      "Copied model parameters to target network.\n",
      "Step 232 (110031) @ Episode 437/10000, loss: 0.0039481311105191717\n",
      "Episode Reward: 1.0\n",
      "Step 161 (110192) @ Episode 438/10000, loss: 0.0033705956302583218\n",
      "Episode Reward: 0.0\n",
      "Step 511 (110703) @ Episode 439/10000, loss: 0.00021432747598737478\n",
      "Episode Reward: 6.0\n",
      "Step 220 (110923) @ Episode 440/10000, loss: 0.00436570215970277885\n",
      "Episode Reward: 1.0\n",
      "Step 325 (111248) @ Episode 441/10000, loss: 0.00400288030505180476\n",
      "Episode Reward: 3.0\n",
      "Step 183 (111431) @ Episode 442/10000, loss: 0.00058681255904957659\n",
      "Episode Reward: 0.0\n",
      "Step 178 (111609) @ Episode 443/10000, loss: 0.00454332400113344243\n",
      "Episode Reward: 0.0\n",
      "Step 403 (112012) @ Episode 444/10000, loss: 0.00289856595918536285\n",
      "Episode Reward: 5.0\n",
      "Step 212 (112224) @ Episode 445/10000, loss: 0.00341557827778160574\n",
      "Episode Reward: 1.0\n",
      "Step 169 (112393) @ Episode 446/10000, loss: 0.00042885448783636093\n",
      "Episode Reward: 0.0\n",
      "Step 308 (112701) @ Episode 447/10000, loss: 0.00066493649501353516\n",
      "Episode Reward: 2.0\n",
      "Step 191 (112892) @ Episode 448/10000, loss: 0.00108202639967203143\n",
      "Episode Reward: 0.0\n",
      "Step 325 (113217) @ Episode 449/10000, loss: 0.00913554616272449517\n",
      "Episode Reward: 2.0\n",
      "Step 211 (113428) @ Episode 450/10000, loss: 0.00060303218197077514\n",
      "Episode Reward: 1.0\n",
      "Step 281 (113709) @ Episode 451/10000, loss: 0.00055423966841772287\n",
      "Episode Reward: 2.0\n",
      "Step 178 (113887) @ Episode 452/10000, loss: 0.00048695271834731103\n",
      "Episode Reward: 0.0\n",
      "Step 289 (114176) @ Episode 453/10000, loss: 0.00037207655259408057\n",
      "Episode Reward: 2.0\n",
      "Step 353 (114529) @ Episode 454/10000, loss: 0.00138033682014793164\n",
      "Episode Reward: 3.0\n",
      "Step 225 (114754) @ Episode 455/10000, loss: 0.00026675738627091057\n",
      "Episode Reward: 1.0\n",
      "Step 431 (115185) @ Episode 456/10000, loss: 0.00019261453417129815\n",
      "Episode Reward: 4.0\n",
      "Step 226 (115411) @ Episode 457/10000, loss: 0.00034882436739280824\n",
      "Episode Reward: 1.0\n",
      "Step 164 (115575) @ Episode 458/10000, loss: 0.00137974717654287828\n",
      "Episode Reward: 0.0\n",
      "Step 165 (115740) @ Episode 459/10000, loss: 0.00013910664711147547\n",
      "Episode Reward: 0.0\n",
      "Step 172 (115912) @ Episode 460/10000, loss: 0.00048949045594781646\n",
      "Episode Reward: 0.0\n",
      "Step 363 (116275) @ Episode 461/10000, loss: 0.00114826671779155737\n",
      "Episode Reward: 3.0\n",
      "Step 171 (116446) @ Episode 462/10000, loss: 0.00020675123960245483\n",
      "Episode Reward: 0.0\n",
      "Step 358 (116804) @ Episode 463/10000, loss: 0.00067827163729816685\n",
      "Episode Reward: 3.0\n",
      "Step 267 (117071) @ Episode 464/10000, loss: 0.00037979628541506827\n",
      "Episode Reward: 2.0\n",
      "Step 336 (117407) @ Episode 465/10000, loss: 0.00023359045735560358\n",
      "Episode Reward: 3.0\n",
      "Step 324 (117731) @ Episode 466/10000, loss: 0.00066895422060042624\n",
      "Episode Reward: 3.0\n",
      "Step 174 (117905) @ Episode 467/10000, loss: 0.00010761030716821551\n",
      "Episode Reward: 0.0\n",
      "Step 178 (118083) @ Episode 468/10000, loss: 0.00319005502387881345\n",
      "Episode Reward: 0.0\n",
      "Step 167 (118250) @ Episode 469/10000, loss: 0.00072162121068686256\n",
      "Episode Reward: 0.0\n",
      "Step 274 (118524) @ Episode 470/10000, loss: 0.00237585930153727533\n",
      "Episode Reward: 2.0\n",
      "Step 180 (118704) @ Episode 471/10000, loss: 0.00029579846886917953\n",
      "Episode Reward: 0.0\n",
      "Step 290 (118994) @ Episode 472/10000, loss: 0.00012422603322193027\n",
      "Episode Reward: 2.0\n",
      "Step 280 (119274) @ Episode 473/10000, loss: 0.00022973329760134227\n",
      "Episode Reward: 2.0\n",
      "Step 171 (119445) @ Episode 474/10000, loss: 0.00011469784658402205\n",
      "Episode Reward: 0.0\n",
      "Step 312 (119757) @ Episode 475/10000, loss: 0.00188374391291290522\n",
      "Episode Reward: 2.0\n",
      "Step 242 (119999) @ Episode 476/10000, loss: 0.00102177145890891553\n",
      "Copied model parameters to target network.\n",
      "Step 342 (120099) @ Episode 476/10000, loss: 0.02891011536121368477\n",
      "Episode Reward: 3.0\n",
      "Step 182 (120281) @ Episode 477/10000, loss: 0.00153688038699328994\n",
      "Episode Reward: 0.0\n",
      "Step 221 (120502) @ Episode 478/10000, loss: 0.00156116776634007755\n",
      "Episode Reward: 1.0\n",
      "Step 232 (120734) @ Episode 479/10000, loss: 0.00074935070006176834\n",
      "Episode Reward: 1.0\n",
      "Step 180 (120914) @ Episode 480/10000, loss: 0.00468475418165326156\n",
      "Episode Reward: 0.0\n",
      "Step 242 (121156) @ Episode 481/10000, loss: 0.00506762694567441975\n",
      "Episode Reward: 1.0\n",
      "Step 232 (121388) @ Episode 482/10000, loss: 0.00248009641654789457\n",
      "Episode Reward: 1.0\n",
      "Step 170 (121558) @ Episode 483/10000, loss: 0.00025634080520831055\n",
      "Episode Reward: 0.0\n",
      "Step 298 (121856) @ Episode 484/10000, loss: 0.00137667171657085425\n",
      "Episode Reward: 2.0\n",
      "Step 176 (122032) @ Episode 485/10000, loss: 0.00053107674466446042\n",
      "Episode Reward: 0.0\n",
      "Step 160 (122192) @ Episode 486/10000, loss: 0.00199051154777407654\n",
      "Episode Reward: 0.0\n",
      "Step 320 (122512) @ Episode 487/10000, loss: 0.00062212237389758236\n",
      "Episode Reward: 3.0\n",
      "Step 340 (122852) @ Episode 488/10000, loss: 0.00173275766428560027\n",
      "Episode Reward: 3.0\n",
      "Step 236 (123088) @ Episode 489/10000, loss: 0.00051909347530454456\n",
      "Episode Reward: 1.0\n",
      "Step 171 (123259) @ Episode 490/10000, loss: 0.00117656448855996136\n",
      "Episode Reward: 0.0\n",
      "Step 277 (123536) @ Episode 491/10000, loss: 0.00060658511938527237\n",
      "Episode Reward: 2.0\n",
      "Step 171 (123707) @ Episode 492/10000, loss: 0.00195716950111091143\n",
      "Episode Reward: 0.0\n",
      "Step 358 (124065) @ Episode 493/10000, loss: 0.00014818446652498096\n",
      "Episode Reward: 3.0\n",
      "Step 228 (124293) @ Episode 494/10000, loss: 0.00108858069870620976\n",
      "Episode Reward: 1.0\n",
      "Step 273 (124566) @ Episode 495/10000, loss: 0.00131555635016411543\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 201 (124767) @ Episode 496/10000, loss: 0.00024282411322928965\n",
      "Episode Reward: 1.0\n",
      "Step 159 (124926) @ Episode 497/10000, loss: 0.00109462987165898085\n",
      "Episode Reward: 0.0\n",
      "Step 344 (125270) @ Episode 498/10000, loss: 0.00028027160442434253\n",
      "Episode Reward: 3.0\n",
      "Step 177 (125447) @ Episode 499/10000, loss: 0.00111981423106044533\n",
      "Episode Reward: 0.0\n",
      "Step 159 (125606) @ Episode 500/10000, loss: 0.00122367497533559855\n",
      "Episode Reward: 0.0\n",
      "Step 377 (125983) @ Episode 501/10000, loss: 0.00028306580497883264\n",
      "Episode Reward: 3.0\n",
      "Step 244 (126227) @ Episode 502/10000, loss: 0.00088135403348132974\n",
      "Episode Reward: 1.0\n",
      "Step 240 (126467) @ Episode 503/10000, loss: 0.00095684529514983377\n",
      "Episode Reward: 2.0\n",
      "Step 236 (126703) @ Episode 504/10000, loss: 0.00092721619876101612\n",
      "Episode Reward: 1.0\n",
      "Step 276 (126979) @ Episode 505/10000, loss: 0.00464587844908237536\n",
      "Episode Reward: 2.0\n",
      "Step 276 (127255) @ Episode 506/10000, loss: 0.00021335059136617934\n",
      "Episode Reward: 2.0\n",
      "Step 298 (127553) @ Episode 507/10000, loss: 0.00015738190268166363\n",
      "Episode Reward: 2.0\n",
      "Step 169 (127722) @ Episode 508/10000, loss: 0.00073017895920202145\n",
      "Episode Reward: 0.0\n",
      "Step 218 (127940) @ Episode 509/10000, loss: 0.00111604621633887367\n",
      "Episode Reward: 1.0\n",
      "Step 171 (128111) @ Episode 510/10000, loss: 0.00200863322243094446\n",
      "Episode Reward: 0.0\n",
      "Step 412 (128523) @ Episode 511/10000, loss: 0.00242953328415751463\n",
      "Episode Reward: 4.0\n",
      "Step 243 (128766) @ Episode 512/10000, loss: 0.00065906782401725657\n",
      "Episode Reward: 1.0\n",
      "Step 279 (129045) @ Episode 513/10000, loss: 0.00131065375171601776\n",
      "Episode Reward: 2.0\n",
      "Step 169 (129214) @ Episode 514/10000, loss: 0.00037317638634704053\n",
      "Episode Reward: 0.0\n",
      "Step 254 (129468) @ Episode 515/10000, loss: 0.00119205994997173556\n",
      "Episode Reward: 2.0\n",
      "Step 272 (129740) @ Episode 516/10000, loss: 0.00053679721895605334\n",
      "Episode Reward: 2.0\n",
      "Step 230 (129970) @ Episode 517/10000, loss: 0.00144677958451211458\n",
      "Episode Reward: 1.0\n",
      "Step 29 (129999) @ Episode 518/10000, loss: 0.00034306803718209267\n",
      "Copied model parameters to target network.\n",
      "Step 450 (130420) @ Episode 518/10000, loss: 0.00433687213808298184\n",
      "Episode Reward: 5.0\n",
      "Step 211 (130631) @ Episode 519/10000, loss: 0.00329671055078506477\n",
      "Episode Reward: 1.0\n",
      "Step 227 (130858) @ Episode 520/10000, loss: 0.00090654118685051895\n",
      "Episode Reward: 1.0\n",
      "Step 207 (131065) @ Episode 521/10000, loss: 0.00199640844948589854\n",
      "Episode Reward: 1.0\n",
      "Step 346 (131411) @ Episode 522/10000, loss: 0.00711373239755630553\n",
      "Episode Reward: 4.0\n",
      "Step 172 (131583) @ Episode 523/10000, loss: 0.00038415167364291847\n",
      "Episode Reward: 0.0\n",
      "Step 432 (132015) @ Episode 524/10000, loss: 0.00049484253395348794\n",
      "Episode Reward: 5.0\n",
      "Step 168 (132183) @ Episode 525/10000, loss: 0.00036211364204064017\n",
      "Episode Reward: 0.0\n",
      "Step 272 (132455) @ Episode 526/10000, loss: 0.00034783189767040316\n",
      "Episode Reward: 2.0\n",
      "Step 500 (132955) @ Episode 527/10000, loss: 0.00198094779625535357\n",
      "Episode Reward: 6.0\n",
      "Step 330 (133285) @ Episode 528/10000, loss: 0.00064491824014112354\n",
      "Episode Reward: 3.0\n",
      "Step 265 (133550) @ Episode 529/10000, loss: 0.00032191601349040866\n",
      "Episode Reward: 2.0\n",
      "Step 285 (133835) @ Episode 530/10000, loss: 0.00082632218254730154\n",
      "Episode Reward: 2.0\n",
      "Step 403 (134238) @ Episode 531/10000, loss: 0.00078168621985241775\n",
      "Episode Reward: 4.0\n",
      "Step 184 (134422) @ Episode 532/10000, loss: 0.00134684948716312657\n",
      "Episode Reward: 0.0\n",
      "Step 308 (134730) @ Episode 533/10000, loss: 0.00042399129597470164\n",
      "Episode Reward: 2.0\n",
      "Step 210 (134940) @ Episode 534/10000, loss: 0.00064278265926986936\n",
      "Episode Reward: 1.0\n",
      "Step 233 (135173) @ Episode 535/10000, loss: 0.00172488798853009946\n",
      "Episode Reward: 1.0\n",
      "Step 326 (135499) @ Episode 536/10000, loss: 0.00105832447297871116\n",
      "Episode Reward: 3.0\n",
      "Step 240 (135739) @ Episode 537/10000, loss: 0.00054266781080514197\n",
      "Episode Reward: 1.0\n",
      "Step 240 (135979) @ Episode 538/10000, loss: 0.00122253177687525754\n",
      "Episode Reward: 1.0\n",
      "Step 357 (136336) @ Episode 539/10000, loss: 0.00059464515652507546\n",
      "Episode Reward: 4.0\n",
      "Step 234 (136570) @ Episode 540/10000, loss: 0.00033274447196163237\n",
      "Episode Reward: 1.0\n",
      "Step 230 (136800) @ Episode 541/10000, loss: 0.00171533529646694662\n",
      "Episode Reward: 1.0\n",
      "Step 260 (137060) @ Episode 542/10000, loss: 0.00089437683345749972\n",
      "Episode Reward: 2.0\n",
      "Step 167 (137227) @ Episode 543/10000, loss: 0.00039173947880044584\n",
      "Episode Reward: 0.0\n",
      "Step 170 (137397) @ Episode 544/10000, loss: 0.00213973689824342734\n",
      "Episode Reward: 0.0\n",
      "Step 176 (137573) @ Episode 545/10000, loss: 0.00037443108158186084\n",
      "Episode Reward: 0.0\n",
      "Step 299 (137872) @ Episode 546/10000, loss: 0.00176764687057584525\n",
      "Episode Reward: 2.0\n",
      "Step 223 (138095) @ Episode 547/10000, loss: 0.00036641111364588147\n",
      "Episode Reward: 1.0\n",
      "Step 342 (138437) @ Episode 548/10000, loss: 0.00045650420361198485\n",
      "Episode Reward: 3.0\n",
      "Step 173 (138610) @ Episode 549/10000, loss: 0.00116252934094518428\n",
      "Episode Reward: 0.0\n",
      "Step 236 (138846) @ Episode 550/10000, loss: 0.00020182125444989651\n",
      "Episode Reward: 1.0\n",
      "Step 243 (139089) @ Episode 551/10000, loss: 0.00079834292409941556\n",
      "Episode Reward: 1.0\n",
      "Step 173 (139262) @ Episode 552/10000, loss: 0.00019460009934846312\n",
      "Episode Reward: 0.0\n",
      "Step 306 (139568) @ Episode 553/10000, loss: 0.00032366137020289977\n",
      "Episode Reward: 3.0\n",
      "Step 233 (139801) @ Episode 554/10000, loss: 0.00045724073424935345\n",
      "Episode Reward: 1.0\n",
      "Step 198 (139999) @ Episode 555/10000, loss: 0.00051060284022241837\n",
      "Copied model parameters to target network.\n",
      "Step 287 (140088) @ Episode 555/10000, loss: 0.00226239045150578027\n",
      "Episode Reward: 2.0\n",
      "Step 200 (140288) @ Episode 556/10000, loss: 0.0006575848092325032\n",
      "Episode Reward: 1.0\n",
      "Step 177 (140465) @ Episode 557/10000, loss: 0.00062579422956332566\n",
      "Episode Reward: 0.0\n",
      "Step 337 (140802) @ Episode 558/10000, loss: 0.00233791721984744074\n",
      "Episode Reward: 3.0\n",
      "Step 231 (141033) @ Episode 559/10000, loss: 0.00056994345504790543\n",
      "Episode Reward: 1.0\n",
      "Step 233 (141266) @ Episode 560/10000, loss: 0.00145232328213751326\n",
      "Episode Reward: 1.0\n",
      "Step 166 (141432) @ Episode 561/10000, loss: 0.00043698740773834295\n",
      "Episode Reward: 0.0\n",
      "Step 207 (141639) @ Episode 562/10000, loss: 0.00150701438542455433\n",
      "Episode Reward: 1.0\n",
      "Step 160 (141799) @ Episode 563/10000, loss: 0.00107869575731456285\n",
      "Episode Reward: 0.0\n",
      "Step 169 (141968) @ Episode 564/10000, loss: 0.00241708941757679475\n",
      "Episode Reward: 0.0\n",
      "Step 215 (142183) @ Episode 565/10000, loss: 0.00017439352814108133\n",
      "Episode Reward: 1.0\n",
      "Step 293 (142476) @ Episode 566/10000, loss: 0.00057572853984311226\n",
      "Episode Reward: 2.0\n",
      "Step 208 (142684) @ Episode 567/10000, loss: 0.00565276946872472847\n",
      "Episode Reward: 1.0\n",
      "Step 278 (142962) @ Episode 568/10000, loss: 0.00603400077670812612\n",
      "Episode Reward: 2.0\n",
      "Step 162 (143124) @ Episode 569/10000, loss: 0.00102909863926470286\n",
      "Episode Reward: 0.0\n",
      "Step 188 (143312) @ Episode 570/10000, loss: 0.00098704535048455563\n",
      "Episode Reward: 0.0\n",
      "Step 215 (143527) @ Episode 571/10000, loss: 0.00272755604237318044\n",
      "Episode Reward: 1.0\n",
      "Step 171 (143698) @ Episode 572/10000, loss: 0.00050294620450586086\n",
      "Episode Reward: 0.0\n",
      "Step 236 (143934) @ Episode 573/10000, loss: 0.00036101340083405375\n",
      "Episode Reward: 1.0\n",
      "Step 399 (144333) @ Episode 574/10000, loss: 0.00272780796512961485\n",
      "Episode Reward: 4.0\n",
      "Step 225 (144558) @ Episode 575/10000, loss: 0.00092432613018900162\n",
      "Episode Reward: 1.0\n",
      "Step 268 (144826) @ Episode 576/10000, loss: 0.00070666725514456633\n",
      "Episode Reward: 2.0\n",
      "Step 269 (145095) @ Episode 577/10000, loss: 0.00303801242262125637\n",
      "Episode Reward: 2.0\n",
      "Step 322 (145417) @ Episode 578/10000, loss: 0.00126456632278859626\n",
      "Episode Reward: 3.0\n",
      "Step 224 (145641) @ Episode 579/10000, loss: 0.00016300940478686243\n",
      "Episode Reward: 1.0\n",
      "Step 279 (145920) @ Episode 580/10000, loss: 0.00011147820623591542\n",
      "Episode Reward: 2.0\n",
      "Step 169 (146089) @ Episode 581/10000, loss: 0.00061058963183313612\n",
      "Episode Reward: 0.0\n",
      "Step 174 (146263) @ Episode 582/10000, loss: 0.00176652148365974436\n",
      "Episode Reward: 0.0\n",
      "Step 232 (146495) @ Episode 583/10000, loss: 0.00018778925004880875\n",
      "Episode Reward: 1.0\n",
      "Step 231 (146726) @ Episode 584/10000, loss: 0.00079778535291552543\n",
      "Episode Reward: 1.0\n",
      "Step 172 (146898) @ Episode 585/10000, loss: 0.00174612854607403286\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 249 (147147) @ Episode 586/10000, loss: 0.00018832964997272938\n",
      "Episode Reward: 2.0\n",
      "Step 302 (147449) @ Episode 587/10000, loss: 0.00017658375145401806\n",
      "Episode Reward: 2.0\n",
      "Step 215 (147664) @ Episode 588/10000, loss: 0.00050591462058946495\n",
      "Episode Reward: 1.0\n",
      "Step 226 (147890) @ Episode 589/10000, loss: 0.00017488173034507784\n",
      "Episode Reward: 1.0\n",
      "Step 249 (148139) @ Episode 590/10000, loss: 0.00027619264437817037\n",
      "Episode Reward: 2.0\n",
      "Step 234 (148373) @ Episode 591/10000, loss: 0.00076740159420296557\n",
      "Episode Reward: 1.0\n",
      "Step 172 (148545) @ Episode 592/10000, loss: 0.00175533071160316475\n",
      "Episode Reward: 0.0\n",
      "Step 165 (148710) @ Episode 593/10000, loss: 0.00077354104723781357\n",
      "Episode Reward: 0.0\n",
      "Step 170 (148880) @ Episode 594/10000, loss: 0.00097348447889089585\n",
      "Episode Reward: 0.0\n",
      "Step 181 (149061) @ Episode 595/10000, loss: 0.00017495613428764045\n",
      "Episode Reward: 0.0\n",
      "Step 270 (149331) @ Episode 596/10000, loss: 0.00017537725216243416\n",
      "Episode Reward: 2.0\n",
      "Step 240 (149571) @ Episode 597/10000, loss: 0.00036685951636172837\n",
      "Episode Reward: 1.0\n",
      "Step 347 (149918) @ Episode 598/10000, loss: 0.00014379482308868321\n",
      "Episode Reward: 3.0\n",
      "Step 81 (149999) @ Episode 599/10000, loss: 0.00093558582011610275\n",
      "Copied model parameters to target network.\n",
      "Step 270 (150188) @ Episode 599/10000, loss: 0.00541152944788336756\n",
      "Episode Reward: 2.0\n",
      "Step 256 (150444) @ Episode 600/10000, loss: 0.00205034296959638635\n",
      "Episode Reward: 1.0\n",
      "Step 276 (150720) @ Episode 601/10000, loss: 0.00209454214200377467\n",
      "Episode Reward: 2.0\n",
      "Step 186 (150906) @ Episode 602/10000, loss: 0.00113929656799882654\n",
      "Episode Reward: 0.0\n",
      "Step 312 (151218) @ Episode 603/10000, loss: 0.00081931549357250334\n",
      "Episode Reward: 2.0\n",
      "Step 174 (151392) @ Episode 604/10000, loss: 0.00182679633144289265\n",
      "Episode Reward: 0.0\n",
      "Step 167 (151559) @ Episode 605/10000, loss: 0.00091009010793641214\n",
      "Episode Reward: 0.0\n",
      "Step 410 (151969) @ Episode 606/10000, loss: 0.00167600659187883142\n",
      "Episode Reward: 4.0\n",
      "Step 339 (152308) @ Episode 607/10000, loss: 0.00024242533254437149\n",
      "Episode Reward: 3.0\n",
      "Step 205 (152513) @ Episode 608/10000, loss: 0.00043288507731631497\n",
      "Episode Reward: 1.0\n",
      "Step 171 (152684) @ Episode 609/10000, loss: 0.00012669376155827194\n",
      "Episode Reward: 0.0\n",
      "Step 272 (152956) @ Episode 610/10000, loss: 0.00054073508363217126\n",
      "Episode Reward: 2.0\n",
      "Step 173 (153129) @ Episode 611/10000, loss: 0.00235836021602153784\n",
      "Episode Reward: 0.0\n",
      "Step 177 (153306) @ Episode 612/10000, loss: 0.00073205458465963613\n",
      "Episode Reward: 0.0\n",
      "Step 233 (153539) @ Episode 613/10000, loss: 0.00095342006534338966\n",
      "Episode Reward: 1.0\n",
      "Step 543 (154082) @ Episode 614/10000, loss: 0.00076373462798073893\n",
      "Episode Reward: 9.0\n",
      "Step 173 (154255) @ Episode 615/10000, loss: 0.0018811145564541226\n",
      "Episode Reward: 0.0\n",
      "Step 306 (154561) @ Episode 616/10000, loss: 0.00170133938081562526\n",
      "Episode Reward: 2.0\n",
      "Step 173 (154734) @ Episode 617/10000, loss: 0.00087213667575269943\n",
      "Episode Reward: 0.0\n",
      "Step 205 (154939) @ Episode 618/10000, loss: 0.00075562449637800463\n",
      "Episode Reward: 1.0\n",
      "Step 177 (155116) @ Episode 619/10000, loss: 0.00058277917560189963\n",
      "Episode Reward: 0.0\n",
      "Step 512 (155628) @ Episode 620/10000, loss: 0.00048621027963235974\n",
      "Episode Reward: 6.0\n",
      "Step 354 (155982) @ Episode 621/10000, loss: 0.00699013751000165967\n",
      "Episode Reward: 3.0\n",
      "Step 167 (156149) @ Episode 622/10000, loss: 0.0010691306088119745\n",
      "Episode Reward: 0.0\n",
      "Step 229 (156378) @ Episode 623/10000, loss: 0.00057738198665902023\n",
      "Episode Reward: 1.0\n",
      "Step 232 (156610) @ Episode 624/10000, loss: 0.00082603638293221596\n",
      "Episode Reward: 1.0\n",
      "Step 173 (156783) @ Episode 625/10000, loss: 0.00046591754653491084\n",
      "Episode Reward: 0.0\n",
      "Step 176 (156959) @ Episode 626/10000, loss: 0.00103710032999515534\n",
      "Episode Reward: 0.0\n",
      "Step 170 (157129) @ Episode 627/10000, loss: 0.00081354659050703054\n",
      "Episode Reward: 0.0\n",
      "Step 172 (157301) @ Episode 628/10000, loss: 0.00040075945435091853\n",
      "Episode Reward: 0.0\n",
      "Step 268 (157569) @ Episode 629/10000, loss: 0.00160043872892856627\n",
      "Episode Reward: 1.0\n",
      "Step 348 (157917) @ Episode 630/10000, loss: 0.00061119289603084336\n",
      "Episode Reward: 4.0\n",
      "Step 229 (158146) @ Episode 631/10000, loss: 0.00063942978158593186\n",
      "Episode Reward: 1.0\n",
      "Step 215 (158361) @ Episode 632/10000, loss: 0.00060145708266645676\n",
      "Episode Reward: 1.0\n",
      "Step 178 (158539) @ Episode 633/10000, loss: 0.00194277637638151657\n",
      "Episode Reward: 0.0\n",
      "Step 206 (158745) @ Episode 634/10000, loss: 0.00027037237305194146\n",
      "Episode Reward: 1.0\n",
      "Step 201 (158946) @ Episode 635/10000, loss: 0.00066170346690341835\n",
      "Episode Reward: 1.0\n",
      "Step 182 (159128) @ Episode 636/10000, loss: 0.00087093206821009524\n",
      "Episode Reward: 0.0\n",
      "Step 343 (159471) @ Episode 637/10000, loss: 0.00171537662390619528\n",
      "Episode Reward: 3.0\n",
      "Step 266 (159737) @ Episode 638/10000, loss: 0.00095882517052814367\n",
      "Episode Reward: 2.0\n",
      "Step 262 (159999) @ Episode 639/10000, loss: 0.00039626270881854522\n",
      "Copied model parameters to target network.\n",
      "Step 277 (160014) @ Episode 639/10000, loss: 0.0015168392565101385\n",
      "Episode Reward: 2.0\n",
      "Step 178 (160192) @ Episode 640/10000, loss: 0.00622933451086282784\n",
      "Episode Reward: 0.0\n",
      "Step 208 (160400) @ Episode 641/10000, loss: 0.00148203363642096525\n",
      "Episode Reward: 1.0\n",
      "Step 332 (160732) @ Episode 642/10000, loss: 0.00059667491586878914\n",
      "Episode Reward: 3.0\n",
      "Step 270 (161002) @ Episode 643/10000, loss: 0.00185925420373678274\n",
      "Episode Reward: 2.0\n",
      "Step 168 (161170) @ Episode 644/10000, loss: 0.00260559469461441046\n",
      "Episode Reward: 0.0\n",
      "Step 173 (161343) @ Episode 645/10000, loss: 0.00147837656550109396\n",
      "Episode Reward: 0.0\n",
      "Step 167 (161510) @ Episode 646/10000, loss: 0.00158902443945407872\n",
      "Episode Reward: 0.0\n",
      "Step 239 (161749) @ Episode 647/10000, loss: 0.00081078894436359417\n",
      "Episode Reward: 1.0\n",
      "Step 215 (161964) @ Episode 648/10000, loss: 0.00055501342285424473\n",
      "Episode Reward: 1.0\n",
      "Step 218 (162182) @ Episode 649/10000, loss: 0.00089715712238103154\n",
      "Episode Reward: 1.0\n",
      "Step 168 (162350) @ Episode 650/10000, loss: 0.00072338915197178724\n",
      "Episode Reward: 0.0\n",
      "Step 288 (162638) @ Episode 651/10000, loss: 0.00328756263479590445\n",
      "Episode Reward: 2.0\n",
      "Step 203 (162841) @ Episode 652/10000, loss: 0.00041666888864710927\n",
      "Episode Reward: 1.0\n",
      "Step 162 (163003) @ Episode 653/10000, loss: 0.00055048160720616583\n",
      "Episode Reward: 0.0\n",
      "Step 180 (163183) @ Episode 654/10000, loss: 0.00021197569731157273\n",
      "Episode Reward: 0.0\n",
      "Step 174 (163357) @ Episode 655/10000, loss: 0.00070351170143112544\n",
      "Episode Reward: 0.0\n",
      "Step 344 (163701) @ Episode 656/10000, loss: 0.00050417362945154314\n",
      "Episode Reward: 3.0\n",
      "Step 273 (163974) @ Episode 657/10000, loss: 0.00106280634645372634\n",
      "Episode Reward: 2.0\n",
      "Step 262 (164236) @ Episode 658/10000, loss: 0.00577881932258606425\n",
      "Episode Reward: 2.0\n",
      "Step 226 (164462) @ Episode 659/10000, loss: 0.00030893541406840086\n",
      "Episode Reward: 1.0\n",
      "Step 159 (164621) @ Episode 660/10000, loss: 0.00029768649255856876\n",
      "Episode Reward: 0.0\n",
      "Step 238 (164859) @ Episode 661/10000, loss: 0.00160927022807300164\n",
      "Episode Reward: 1.0\n",
      "Step 181 (165040) @ Episode 662/10000, loss: 0.00202134554274380234\n",
      "Episode Reward: 0.0\n",
      "Step 341 (165381) @ Episode 663/10000, loss: 0.00055249629076570274\n",
      "Episode Reward: 3.0\n",
      "Step 346 (165727) @ Episode 664/10000, loss: 0.00031940237386152154\n",
      "Episode Reward: 3.0\n",
      "Step 361 (166088) @ Episode 665/10000, loss: 0.00079611287219449883\n",
      "Episode Reward: 4.0\n",
      "Step 318 (166406) @ Episode 666/10000, loss: 0.00377382081933319573\n",
      "Episode Reward: 2.0\n",
      "Step 169 (166575) @ Episode 667/10000, loss: 0.00019968215201515704\n",
      "Episode Reward: 0.0\n",
      "Step 270 (166845) @ Episode 668/10000, loss: 0.00065680139232426884\n",
      "Episode Reward: 2.0\n",
      "Step 170 (167015) @ Episode 669/10000, loss: 0.00047748110955581078\n",
      "Episode Reward: 0.0\n",
      "Step 186 (167201) @ Episode 670/10000, loss: 0.00189373490866273643\n",
      "Episode Reward: 0.0\n",
      "Step 255 (167456) @ Episode 671/10000, loss: 0.00119578302837908273\n",
      "Episode Reward: 1.0\n",
      "Step 423 (167879) @ Episode 672/10000, loss: 0.00180843728594481955\n",
      "Episode Reward: 4.0\n",
      "Step 196 (168075) @ Episode 673/10000, loss: 0.00106278492603451017\n",
      "Episode Reward: 0.0\n",
      "Step 168 (168243) @ Episode 674/10000, loss: 0.00034065131330862645\n",
      "Episode Reward: 0.0\n",
      "Step 204 (168447) @ Episode 675/10000, loss: 0.00036645014188252395\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 309 (168756) @ Episode 676/10000, loss: 0.00117993494495749474\n",
      "Episode Reward: 2.0\n",
      "Step 215 (168971) @ Episode 677/10000, loss: 0.00172923097852617576\n",
      "Episode Reward: 1.0\n",
      "Step 192 (169163) @ Episode 678/10000, loss: 0.00230437004938721666\n",
      "Episode Reward: 0.0\n",
      "Step 203 (169366) @ Episode 679/10000, loss: 0.00076565984636545184\n",
      "Episode Reward: 1.0\n",
      "Step 179 (169545) @ Episode 680/10000, loss: 0.00121429329738020986\n",
      "Episode Reward: 0.0\n",
      "Step 174 (169719) @ Episode 681/10000, loss: 0.00040478195296600463\n",
      "Episode Reward: 0.0\n",
      "Step 260 (169979) @ Episode 682/10000, loss: 0.00113594485446810725\n",
      "Episode Reward: 2.0\n",
      "Step 20 (169999) @ Episode 683/10000, loss: 0.00018647588149178773\n",
      "Copied model parameters to target network.\n",
      "Step 172 (170151) @ Episode 683/10000, loss: 0.0017903133993968368\n",
      "Episode Reward: 0.0\n",
      "Step 306 (170457) @ Episode 684/10000, loss: 0.0007822502520866692\n",
      "Episode Reward: 2.0\n",
      "Step 242 (170699) @ Episode 685/10000, loss: 0.00042778361239470545\n",
      "Episode Reward: 1.0\n",
      "Step 287 (170986) @ Episode 686/10000, loss: 0.00534490542486315533\n",
      "Episode Reward: 2.0\n",
      "Step 284 (171270) @ Episode 687/10000, loss: 0.00208862102590501356\n",
      "Episode Reward: 2.0\n",
      "Step 211 (171481) @ Episode 688/10000, loss: 0.00052592402789741753\n",
      "Episode Reward: 1.0\n",
      "Step 232 (171713) @ Episode 689/10000, loss: 0.00301105459220707455\n",
      "Episode Reward: 1.0\n",
      "Step 215 (171928) @ Episode 690/10000, loss: 0.00101974268909543758\n",
      "Episode Reward: 1.0\n",
      "Step 340 (172268) @ Episode 691/10000, loss: 0.00030268338741734624\n",
      "Episode Reward: 3.0\n",
      "Step 207 (172475) @ Episode 692/10000, loss: 0.00104058708529919394\n",
      "Episode Reward: 1.0\n",
      "Step 203 (172678) @ Episode 693/10000, loss: 0.00130482995882630353\n",
      "Episode Reward: 1.0\n",
      "Step 209 (172887) @ Episode 694/10000, loss: 0.00031537300674244765\n",
      "Episode Reward: 1.0\n",
      "Step 167 (173054) @ Episode 695/10000, loss: 0.00041818144381977626\n",
      "Episode Reward: 0.0\n",
      "Step 164 (173218) @ Episode 696/10000, loss: 0.00101279455702751873\n",
      "Episode Reward: 0.0\n",
      "Step 180 (173398) @ Episode 697/10000, loss: 0.00092231464805081497\n",
      "Episode Reward: 0.0\n",
      "Step 210 (173608) @ Episode 698/10000, loss: 0.00099715404212474827\n",
      "Episode Reward: 1.0\n",
      "Step 215 (173823) @ Episode 699/10000, loss: 0.00102975696790963414\n",
      "Episode Reward: 1.0\n",
      "Step 440 (174263) @ Episode 700/10000, loss: 0.00232833856716752053\n",
      "Episode Reward: 5.0\n",
      "Step 223 (174486) @ Episode 701/10000, loss: 0.00025932310381904244\n",
      "Episode Reward: 1.0\n",
      "Step 166 (174652) @ Episode 702/10000, loss: 0.00119277776684612044\n",
      "Episode Reward: 0.0\n",
      "Step 174 (174826) @ Episode 703/10000, loss: 0.00087255483958870175\n",
      "Episode Reward: 0.0\n",
      "Step 264 (175090) @ Episode 704/10000, loss: 0.00031085551017895348\n",
      "Episode Reward: 2.0\n",
      "Step 170 (175260) @ Episode 705/10000, loss: 0.00049090629909187564\n",
      "Episode Reward: 0.0\n",
      "Step 317 (175577) @ Episode 706/10000, loss: 0.00119261327199637966\n",
      "Episode Reward: 3.0\n",
      "Step 182 (175759) @ Episode 707/10000, loss: 0.00044159041135571897\n",
      "Episode Reward: 0.0\n",
      "Step 446 (176205) @ Episode 708/10000, loss: 0.00059423141647130254\n",
      "Episode Reward: 5.0\n",
      "Step 176 (176381) @ Episode 709/10000, loss: 0.00150196405593305836\n",
      "Episode Reward: 0.0\n",
      "Step 216 (176597) @ Episode 710/10000, loss: 0.00036508589982986455\n",
      "Episode Reward: 1.0\n",
      "Step 389 (176986) @ Episode 711/10000, loss: 0.00217487150803208354\n",
      "Episode Reward: 4.0\n",
      "Step 174 (177160) @ Episode 712/10000, loss: 0.00057655537966638867\n",
      "Episode Reward: 0.0\n",
      "Step 184 (177344) @ Episode 713/10000, loss: 0.00054362788796424877\n",
      "Episode Reward: 0.0\n",
      "Step 233 (177577) @ Episode 714/10000, loss: 0.00302812806330621247\n",
      "Episode Reward: 1.0\n",
      "Step 270 (177847) @ Episode 715/10000, loss: 0.00018601627380121544\n",
      "Episode Reward: 2.0\n",
      "Step 332 (178179) @ Episode 716/10000, loss: 0.00038512420724146077\n",
      "Episode Reward: 3.0\n",
      "Step 371 (178550) @ Episode 717/10000, loss: 0.00042129756184294823\n",
      "Episode Reward: 3.0\n",
      "Step 182 (178732) @ Episode 718/10000, loss: 0.00035171513445675373\n",
      "Episode Reward: 0.0\n",
      "Step 206 (178938) @ Episode 719/10000, loss: 0.00019327360496390614\n",
      "Episode Reward: 1.0\n",
      "Step 204 (179142) @ Episode 720/10000, loss: 0.00081675394903868443\n",
      "Episode Reward: 1.0\n",
      "Step 273 (179415) @ Episode 721/10000, loss: 0.00041695722029544413\n",
      "Episode Reward: 2.0\n",
      "Step 208 (179623) @ Episode 722/10000, loss: 0.00258608208969235432\n",
      "Episode Reward: 1.0\n",
      "Step 208 (179831) @ Episode 723/10000, loss: 0.00369783863425254823\n",
      "Episode Reward: 1.0\n",
      "Step 168 (179999) @ Episode 724/10000, loss: 0.00077536341268569236\n",
      "Copied model parameters to target network.\n",
      "Step 245 (180076) @ Episode 724/10000, loss: 0.00435749720782041554\n",
      "Episode Reward: 2.0\n",
      "Step 257 (180333) @ Episode 725/10000, loss: 0.00047846586676314473\n",
      "Episode Reward: 1.0\n",
      "Step 293 (180626) @ Episode 726/10000, loss: 0.00189334398601204164\n",
      "Episode Reward: 2.0\n",
      "Step 165 (180791) @ Episode 727/10000, loss: 0.00115977926179766656\n",
      "Episode Reward: 0.0\n",
      "Step 429 (181220) @ Episode 728/10000, loss: 0.00101568130776286134\n",
      "Episode Reward: 4.0\n",
      "Step 175 (181395) @ Episode 729/10000, loss: 0.00068380107404664164\n",
      "Episode Reward: 0.0\n",
      "Step 318 (181713) @ Episode 730/10000, loss: 0.00127843348309397735\n",
      "Episode Reward: 3.0\n",
      "Step 238 (181951) @ Episode 731/10000, loss: 0.00039194384589791327\n",
      "Episode Reward: 1.0\n",
      "Step 168 (182119) @ Episode 732/10000, loss: 0.00018183136126026517\n",
      "Episode Reward: 0.0\n",
      "Step 307 (182426) @ Episode 733/10000, loss: 0.00225554290227592476\n",
      "Episode Reward: 2.0\n",
      "Step 208 (182634) @ Episode 734/10000, loss: 0.00190510530956089564\n",
      "Episode Reward: 1.0\n",
      "Step 180 (182814) @ Episode 735/10000, loss: 0.00054783129598945385\n",
      "Episode Reward: 0.0\n",
      "Step 173 (182987) @ Episode 736/10000, loss: 0.00650776922702789322\n",
      "Episode Reward: 0.0\n",
      "Step 178 (183165) @ Episode 737/10000, loss: 0.00178342463914304976\n",
      "Episode Reward: 0.0\n",
      "Step 232 (183397) @ Episode 738/10000, loss: 0.00089537276653572926\n",
      "Episode Reward: 1.0\n",
      "Step 232 (183629) @ Episode 739/10000, loss: 0.00082157290307804945\n",
      "Episode Reward: 1.0\n",
      "Step 272 (183901) @ Episode 740/10000, loss: 0.00023265866911970085\n",
      "Episode Reward: 2.0\n",
      "Step 224 (184125) @ Episode 741/10000, loss: 0.00032956147333607087\n",
      "Episode Reward: 1.0\n",
      "Step 169 (184294) @ Episode 742/10000, loss: 0.00125991157256066814\n",
      "Episode Reward: 0.0\n",
      "Step 205 (184499) @ Episode 743/10000, loss: 0.00106208119541406635\n",
      "Episode Reward: 1.0\n",
      "Step 177 (184676) @ Episode 744/10000, loss: 0.00163428322412073617\n",
      "Episode Reward: 0.0\n",
      "Step 183 (184859) @ Episode 745/10000, loss: 0.00010890150588238612\n",
      "Episode Reward: 0.0\n",
      "Step 206 (185065) @ Episode 746/10000, loss: 0.00104457919951528316\n",
      "Episode Reward: 1.0\n",
      "Step 179 (185244) @ Episode 747/10000, loss: 0.00014390583964996043\n",
      "Episode Reward: 0.0\n",
      "Step 168 (185412) @ Episode 748/10000, loss: 0.00027597416192293167\n",
      "Episode Reward: 0.0\n",
      "Step 161 (185573) @ Episode 749/10000, loss: 0.00288735865615308344\n",
      "Episode Reward: 0.0\n",
      "Step 209 (185782) @ Episode 750/10000, loss: 0.00122918258421123038\n",
      "Episode Reward: 1.0\n",
      "Step 256 (186038) @ Episode 751/10000, loss: 0.00054980628192424775\n",
      "Episode Reward: 2.0\n",
      "Step 251 (186289) @ Episode 752/10000, loss: 0.00065341364825144418\n",
      "Episode Reward: 2.0\n",
      "Step 167 (186456) @ Episode 753/10000, loss: 0.00059640040853992162\n",
      "Episode Reward: 0.0\n",
      "Step 244 (186700) @ Episode 754/10000, loss: 0.00074672891059890396\n",
      "Episode Reward: 1.0\n",
      "Step 178 (186878) @ Episode 755/10000, loss: 0.00065071927383542067\n",
      "Episode Reward: 0.0\n",
      "Step 156 (187034) @ Episode 756/10000, loss: 0.00029552041087299585\n",
      "Episode Reward: 0.0\n",
      "Step 242 (187276) @ Episode 757/10000, loss: 0.00115786492824554446\n",
      "Episode Reward: 1.0\n",
      "Step 303 (187579) @ Episode 758/10000, loss: 0.00080257875379174953\n",
      "Episode Reward: 3.0\n",
      "Step 178 (187757) @ Episode 759/10000, loss: 0.00031687071896158168\n",
      "Episode Reward: 0.0\n",
      "Step 211 (187968) @ Episode 760/10000, loss: 0.00021939568978268653\n",
      "Episode Reward: 1.0\n",
      "Step 205 (188173) @ Episode 761/10000, loss: 0.00163473305292427543\n",
      "Episode Reward: 1.0\n",
      "Step 250 (188423) @ Episode 762/10000, loss: 0.00031052209669724107\n",
      "Episode Reward: 2.0\n",
      "Step 246 (188669) @ Episode 763/10000, loss: 0.00242022704333066945\n",
      "Episode Reward: 1.0\n",
      "Step 171 (188840) @ Episode 764/10000, loss: 0.00021612286218442023\n",
      "Episode Reward: 0.0\n",
      "Step 176 (189016) @ Episode 765/10000, loss: 0.00173937960062175997\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 167 (189183) @ Episode 766/10000, loss: 0.00053785252384841444\n",
      "Episode Reward: 0.0\n",
      "Step 168 (189351) @ Episode 767/10000, loss: 0.00181852059904485945\n",
      "Episode Reward: 0.0\n",
      "Step 202 (189553) @ Episode 768/10000, loss: 0.00110690749716013674\n",
      "Episode Reward: 1.0\n",
      "Step 171 (189724) @ Episode 769/10000, loss: 0.00029115605866536546\n",
      "Episode Reward: 0.0\n",
      "Step 182 (189906) @ Episode 770/10000, loss: 0.00020399421919137245\n",
      "Episode Reward: 0.0\n",
      "Step 93 (189999) @ Episode 771/10000, loss: 0.00022125786927063018\n",
      "Copied model parameters to target network.\n",
      "Step 174 (190080) @ Episode 771/10000, loss: 0.0013058369513601065\n",
      "Episode Reward: 0.0\n",
      "Step 275 (190355) @ Episode 772/10000, loss: 0.00059674313524737953\n",
      "Episode Reward: 2.0\n",
      "Step 225 (190580) @ Episode 773/10000, loss: 0.00283659202978014954\n",
      "Episode Reward: 1.0\n",
      "Step 168 (190748) @ Episode 774/10000, loss: 0.00209036702290177357\n",
      "Episode Reward: 0.0\n",
      "Step 235 (190983) @ Episode 775/10000, loss: 0.00253089680336415774\n",
      "Episode Reward: 1.0\n",
      "Step 217 (191200) @ Episode 776/10000, loss: 0.00055791035993024715\n",
      "Episode Reward: 1.0\n",
      "Step 278 (191478) @ Episode 777/10000, loss: 0.00117250229232013233\n",
      "Episode Reward: 2.0\n",
      "Step 164 (191642) @ Episode 778/10000, loss: 0.00111291999928653243\n",
      "Episode Reward: 0.0\n",
      "Step 274 (191916) @ Episode 779/10000, loss: 0.00224067922681570057\n",
      "Episode Reward: 2.0\n",
      "Step 162 (192078) @ Episode 780/10000, loss: 0.00033841532422229654\n",
      "Episode Reward: 0.0\n",
      "Step 176 (192254) @ Episode 781/10000, loss: 0.00321460003033280375\n",
      "Episode Reward: 0.0\n",
      "Step 231 (192485) @ Episode 782/10000, loss: 0.00043201338849030435\n",
      "Episode Reward: 1.0\n",
      "Step 166 (192651) @ Episode 783/10000, loss: 0.00038849041447974747\n",
      "Episode Reward: 0.0\n",
      "Step 169 (192820) @ Episode 784/10000, loss: 0.00022822497703600675\n",
      "Episode Reward: 0.0\n",
      "Step 169 (192989) @ Episode 785/10000, loss: 0.00092706346185877923\n",
      "Episode Reward: 0.0\n",
      "Step 221 (193210) @ Episode 786/10000, loss: 0.00029589771293103695\n",
      "Episode Reward: 1.0\n",
      "Step 273 (193483) @ Episode 787/10000, loss: 0.00030946539482101805\n",
      "Episode Reward: 2.0\n",
      "Step 172 (193655) @ Episode 788/10000, loss: 0.00041796866571530776\n",
      "Episode Reward: 0.0\n",
      "Step 391 (194046) @ Episode 789/10000, loss: 0.00118701427709311255\n",
      "Episode Reward: 4.0\n",
      "Step 179 (194225) @ Episode 790/10000, loss: 0.00014584820019081235\n",
      "Episode Reward: 0.0\n",
      "Step 261 (194486) @ Episode 791/10000, loss: 0.00282163033261895275\n",
      "Episode Reward: 2.0\n",
      "Step 166 (194652) @ Episode 792/10000, loss: 0.00111460662446916198\n",
      "Episode Reward: 0.0\n",
      "Step 213 (194865) @ Episode 793/10000, loss: 0.00071164581459015613\n",
      "Episode Reward: 1.0\n",
      "Step 351 (195216) @ Episode 794/10000, loss: 0.00269142212346196175\n",
      "Episode Reward: 3.0\n",
      "Step 171 (195387) @ Episode 795/10000, loss: 0.00047207041643559934\n",
      "Episode Reward: 0.0\n",
      "Step 234 (195621) @ Episode 796/10000, loss: 0.00040976703166961675\n",
      "Episode Reward: 1.0\n",
      "Step 167 (195788) @ Episode 797/10000, loss: 0.00320319714955985552\n",
      "Episode Reward: 0.0\n",
      "Step 226 (196014) @ Episode 798/10000, loss: 0.00053078273776918653\n",
      "Episode Reward: 1.0\n",
      "Step 233 (196247) @ Episode 799/10000, loss: 0.00177640654146671343\n",
      "Episode Reward: 1.0\n",
      "Step 168 (196415) @ Episode 800/10000, loss: 0.00014527421444654465\n",
      "Episode Reward: 0.0\n",
      "Step 442 (196857) @ Episode 801/10000, loss: 0.00050106237176805734\n",
      "Episode Reward: 4.0\n",
      "Step 168 (197025) @ Episode 802/10000, loss: 0.00172073184512555697\n",
      "Episode Reward: 0.0\n",
      "Step 243 (197268) @ Episode 803/10000, loss: 0.00125024595763534393\n",
      "Episode Reward: 2.0\n",
      "Step 239 (197507) @ Episode 804/10000, loss: 0.00058559770695865155\n",
      "Episode Reward: 1.0\n",
      "Step 168 (197675) @ Episode 805/10000, loss: 0.00039305438986048145\n",
      "Episode Reward: 0.0\n",
      "Step 200 (197875) @ Episode 806/10000, loss: 0.00033704208908602595\n",
      "Episode Reward: 1.0\n",
      "Step 237 (198112) @ Episode 807/10000, loss: 0.00017487295554019515\n",
      "Episode Reward: 1.0\n",
      "Step 284 (198396) @ Episode 808/10000, loss: 0.00097733153961598875\n",
      "Episode Reward: 2.0\n",
      "Step 232 (198628) @ Episode 809/10000, loss: 0.00020182886510156095\n",
      "Episode Reward: 1.0\n",
      "Step 173 (198801) @ Episode 810/10000, loss: 0.00018449212075211108\n",
      "Episode Reward: 0.0\n",
      "Step 383 (199184) @ Episode 811/10000, loss: 0.00072265253402292738\n",
      "Episode Reward: 4.0\n",
      "Step 175 (199359) @ Episode 812/10000, loss: 0.00051644013728946457\n",
      "Episode Reward: 0.0\n",
      "Step 169 (199528) @ Episode 813/10000, loss: 0.00017496538930572575\n",
      "Episode Reward: 0.0\n",
      "Step 263 (199791) @ Episode 814/10000, loss: 0.00019342439190950245\n",
      "Episode Reward: 2.0\n",
      "Step 172 (199963) @ Episode 815/10000, loss: 0.00010893483704421669\n",
      "Episode Reward: 0.0\n",
      "Step 36 (199999) @ Episode 816/10000, loss: 0.00023428811982739717\n",
      "Copied model parameters to target network.\n",
      "Step 326 (200289) @ Episode 816/10000, loss: 0.00147908960934728384\n",
      "Episode Reward: 3.0\n",
      "Step 181 (200470) @ Episode 817/10000, loss: 0.00073203991632908586\n",
      "Episode Reward: 0.0\n",
      "Step 268 (200738) @ Episode 818/10000, loss: 0.00044136578799225395\n",
      "Episode Reward: 2.0\n",
      "Step 188 (200926) @ Episode 819/10000, loss: 0.00034954713191837075\n",
      "Episode Reward: 0.0\n",
      "Step 229 (201155) @ Episode 820/10000, loss: 0.00038282538298517466\n",
      "Episode Reward: 1.0\n",
      "Step 186 (201341) @ Episode 821/10000, loss: 0.00172881188336759816\n",
      "Episode Reward: 0.0\n",
      "Step 178 (201519) @ Episode 822/10000, loss: 0.00047108851140365005\n",
      "Episode Reward: 0.0\n",
      "Step 166 (201685) @ Episode 823/10000, loss: 0.00081677513662725695\n",
      "Episode Reward: 0.0\n",
      "Step 309 (201994) @ Episode 824/10000, loss: 0.00039865300641395156\n",
      "Episode Reward: 2.0\n",
      "Step 252 (202246) @ Episode 825/10000, loss: 0.00049537076847627766\n",
      "Episode Reward: 1.0\n",
      "Step 299 (202545) @ Episode 826/10000, loss: 0.00065053731668740513\n",
      "Episode Reward: 3.0\n",
      "Step 165 (202710) @ Episode 827/10000, loss: 0.00042306998511776333\n",
      "Episode Reward: 0.0\n",
      "Step 158 (202868) @ Episode 828/10000, loss: 0.00050453993026167154\n",
      "Episode Reward: 0.0\n",
      "Step 158 (203026) @ Episode 829/10000, loss: 0.00045937689719721675\n",
      "Episode Reward: 0.0\n",
      "Step 231 (203257) @ Episode 830/10000, loss: 0.00021778244990855455\n",
      "Episode Reward: 1.0\n",
      "Step 167 (203424) @ Episode 831/10000, loss: 0.00039424220449291175\n",
      "Episode Reward: 0.0\n",
      "Step 306 (203730) @ Episode 832/10000, loss: 0.00049972755368798975\n",
      "Episode Reward: 2.0\n",
      "Step 294 (204024) @ Episode 833/10000, loss: 0.00543058384209871347\n",
      "Episode Reward: 2.0\n",
      "Step 166 (204190) @ Episode 834/10000, loss: 0.00093975121853873133\n",
      "Episode Reward: 0.0\n",
      "Step 173 (204363) @ Episode 835/10000, loss: 0.00057523325085639953\n",
      "Episode Reward: 0.0\n",
      "Step 183 (204546) @ Episode 836/10000, loss: 0.00033408752642571926\n",
      "Episode Reward: 0.0\n",
      "Step 161 (204707) @ Episode 837/10000, loss: 0.00092190492432564525\n",
      "Episode Reward: 0.0\n",
      "Step 208 (204915) @ Episode 838/10000, loss: 0.00081721565220505567\n",
      "Episode Reward: 1.0\n",
      "Step 248 (205163) @ Episode 839/10000, loss: 0.00112280133180320262\n",
      "Episode Reward: 1.0\n",
      "Step 214 (205377) @ Episode 840/10000, loss: 0.00064264616230502726\n",
      "Episode Reward: 1.0\n",
      "Step 317 (205694) @ Episode 841/10000, loss: 0.00046563660725951195\n",
      "Episode Reward: 2.0\n",
      "Step 168 (205862) @ Episode 842/10000, loss: 0.00076187809463590388\n",
      "Episode Reward: 0.0\n",
      "Step 418 (206280) @ Episode 843/10000, loss: 0.00016958468768287645\n",
      "Episode Reward: 5.0\n",
      "Step 230 (206510) @ Episode 844/10000, loss: 0.00012213499576319014\n",
      "Episode Reward: 1.0\n",
      "Step 170 (206680) @ Episode 845/10000, loss: 0.00052901857998222113\n",
      "Episode Reward: 0.0\n",
      "Step 178 (206858) @ Episode 846/10000, loss: 0.00014161631406750538\n",
      "Episode Reward: 0.0\n",
      "Step 224 (207082) @ Episode 847/10000, loss: 0.00036358847864903515\n",
      "Episode Reward: 1.0\n",
      "Step 166 (207248) @ Episode 848/10000, loss: 0.00075100996764376767\n",
      "Episode Reward: 0.0\n",
      "Step 210 (207458) @ Episode 849/10000, loss: 0.00579923205077648285\n",
      "Episode Reward: 1.0\n",
      "Step 205 (207663) @ Episode 850/10000, loss: 0.00093880604254081857\n",
      "Episode Reward: 1.0\n",
      "Step 170 (207833) @ Episode 851/10000, loss: 0.00015587527013849467\n",
      "Episode Reward: 0.0\n",
      "Step 162 (207995) @ Episode 852/10000, loss: 0.00062594085466116674\n",
      "Episode Reward: 0.0\n",
      "Step 159 (208154) @ Episode 853/10000, loss: 0.00020309195679146796\n",
      "Episode Reward: 0.0\n",
      "Step 177 (208331) @ Episode 854/10000, loss: 0.00037944849464111037\n",
      "Episode Reward: 0.0\n",
      "Step 168 (208499) @ Episode 855/10000, loss: 0.00082760851364582787\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 247 (208746) @ Episode 856/10000, loss: 0.00034821423469111323\n",
      "Episode Reward: 1.0\n",
      "Step 160 (208906) @ Episode 857/10000, loss: 0.00085575616685673598\n",
      "Episode Reward: 0.0\n",
      "Step 238 (209144) @ Episode 858/10000, loss: 0.00044554570922628045\n",
      "Episode Reward: 1.0\n",
      "Step 165 (209309) @ Episode 859/10000, loss: 0.00036380381789058447\n",
      "Episode Reward: 0.0\n",
      "Step 177 (209486) @ Episode 860/10000, loss: 0.00025385155458934605\n",
      "Episode Reward: 0.0\n",
      "Step 160 (209646) @ Episode 861/10000, loss: 0.00048799579963088036\n",
      "Episode Reward: 0.0\n",
      "Step 182 (209828) @ Episode 862/10000, loss: 0.00094234739663079386\n",
      "Episode Reward: 0.0\n",
      "Step 171 (209999) @ Episode 863/10000, loss: 0.00069080432876944543\n",
      "Copied model parameters to target network.\n",
      "Step 203 (210031) @ Episode 863/10000, loss: 0.0017153812805190682\n",
      "Episode Reward: 1.0\n",
      "Step 167 (210198) @ Episode 864/10000, loss: 0.0009434145758859813\n",
      "Episode Reward: 0.0\n",
      "Step 222 (210420) @ Episode 865/10000, loss: 0.00070273416349664334\n",
      "Episode Reward: 1.0\n",
      "Step 356 (210776) @ Episode 866/10000, loss: 0.00263231643475592145\n",
      "Episode Reward: 3.0\n",
      "Step 347 (211123) @ Episode 867/10000, loss: 0.00120488554239273075\n",
      "Episode Reward: 3.0\n",
      "Step 366 (211489) @ Episode 868/10000, loss: 0.00053529388969764114\n",
      "Episode Reward: 3.0\n",
      "Step 199 (211688) @ Episode 869/10000, loss: 0.00161078968085348634\n",
      "Episode Reward: 1.0\n",
      "Step 236 (211924) @ Episode 870/10000, loss: 0.00115500588435679675\n",
      "Episode Reward: 1.0\n",
      "Step 200 (212124) @ Episode 871/10000, loss: 0.00042283575749024755\n",
      "Episode Reward: 1.0\n",
      "Step 384 (212508) @ Episode 872/10000, loss: 0.00120260124094784265\n",
      "Episode Reward: 4.0\n",
      "Step 212 (212720) @ Episode 873/10000, loss: 0.00054969388293102387\n",
      "Episode Reward: 1.0\n",
      "Step 169 (212889) @ Episode 874/10000, loss: 0.00042930414201691747\n",
      "Episode Reward: 0.0\n",
      "Step 282 (213171) @ Episode 875/10000, loss: 0.00035232320078648627\n",
      "Episode Reward: 2.0\n",
      "Step 167 (213338) @ Episode 876/10000, loss: 0.00072627223562449227\n",
      "Episode Reward: 0.0\n",
      "Step 233 (213571) @ Episode 877/10000, loss: 0.00044677144614979625\n",
      "Episode Reward: 1.0\n",
      "Step 372 (213943) @ Episode 878/10000, loss: 0.00024031594512052834\n",
      "Episode Reward: 3.0\n",
      "Step 185 (214128) @ Episode 879/10000, loss: 0.00032687882776372135\n",
      "Episode Reward: 0.0\n",
      "Step 264 (214392) @ Episode 880/10000, loss: 0.00017752230633050203\n",
      "Episode Reward: 2.0\n",
      "Step 406 (214798) @ Episode 881/10000, loss: 0.00088912417413666844\n",
      "Episode Reward: 4.0\n",
      "Step 166 (214964) @ Episode 882/10000, loss: 0.00103531649801880126\n",
      "Episode Reward: 0.0\n",
      "Step 206 (215170) @ Episode 883/10000, loss: 0.00028573311283253133\n",
      "Episode Reward: 1.0\n",
      "Step 211 (215381) @ Episode 884/10000, loss: 0.00047069546417333186\n",
      "Episode Reward: 1.0\n",
      "Step 161 (215542) @ Episode 885/10000, loss: 0.00045038983807899066\n",
      "Episode Reward: 0.0\n",
      "Step 238 (215780) @ Episode 886/10000, loss: 0.00077039137249812484\n",
      "Episode Reward: 1.0\n",
      "Step 402 (216182) @ Episode 887/10000, loss: 0.00055421300930902367\n",
      "Episode Reward: 4.0\n",
      "Step 161 (216343) @ Episode 888/10000, loss: 0.00044318725122138862\n",
      "Episode Reward: 0.0\n",
      "Step 256 (216599) @ Episode 889/10000, loss: 0.00130790693219751124\n",
      "Episode Reward: 2.0\n",
      "Step 316 (216915) @ Episode 890/10000, loss: 0.00069826684193685657\n",
      "Episode Reward: 2.0\n",
      "Step 206 (217121) @ Episode 891/10000, loss: 0.00169661524705588826\n",
      "Episode Reward: 1.0\n",
      "Step 176 (217297) @ Episode 892/10000, loss: 0.00046726627624593675\n",
      "Episode Reward: 0.0\n",
      "Step 366 (217663) @ Episode 893/10000, loss: 0.00018800763064064085\n",
      "Episode Reward: 3.0\n",
      "Step 369 (218032) @ Episode 894/10000, loss: 0.00131722167134284973\n",
      "Episode Reward: 3.0\n",
      "Step 239 (218271) @ Episode 895/10000, loss: 0.00042224829667247837\n",
      "Episode Reward: 1.0\n",
      "Step 322 (218593) @ Episode 896/10000, loss: 0.00027514045359566813\n",
      "Episode Reward: 3.0\n",
      "Step 171 (218764) @ Episode 897/10000, loss: 0.00019271110068075366\n",
      "Episode Reward: 0.0\n",
      "Step 205 (218969) @ Episode 898/10000, loss: 0.00039189224480651326\n",
      "Episode Reward: 1.0\n",
      "Step 187 (219156) @ Episode 899/10000, loss: 0.00044180010445415974\n",
      "Episode Reward: 0.0\n",
      "Step 239 (219395) @ Episode 900/10000, loss: 0.00018846236343961214\n",
      "Episode Reward: 2.0\n",
      "Step 209 (219604) @ Episode 901/10000, loss: 0.00031121380743570626\n",
      "Episode Reward: 1.0\n",
      "Step 245 (219849) @ Episode 902/10000, loss: 0.00058389164041727785\n",
      "Episode Reward: 1.0\n",
      "Step 150 (219999) @ Episode 903/10000, loss: 0.00033550540683791046\n",
      "Copied model parameters to target network.\n",
      "Step 168 (220017) @ Episode 903/10000, loss: 0.0009858919074758887\n",
      "Episode Reward: 0.0\n",
      "Step 163 (220180) @ Episode 904/10000, loss: 0.00122722145169973374\n",
      "Episode Reward: 0.0\n",
      "Step 291 (220471) @ Episode 905/10000, loss: 0.00174541771411895755\n",
      "Episode Reward: 2.0\n",
      "Step 169 (220640) @ Episode 906/10000, loss: 0.00088513304945081474\n",
      "Episode Reward: 0.0\n",
      "Step 175 (220815) @ Episode 907/10000, loss: 0.00069988577160984284\n",
      "Episode Reward: 0.0\n",
      "Step 240 (221055) @ Episode 908/10000, loss: 0.00023429510474670678\n",
      "Episode Reward: 1.0\n",
      "Step 167 (221222) @ Episode 909/10000, loss: 0.00088321417570114144\n",
      "Episode Reward: 0.0\n",
      "Step 194 (221416) @ Episode 910/10000, loss: 0.00060493778437376024\n",
      "Episode Reward: 0.0\n",
      "Step 205 (221621) @ Episode 911/10000, loss: 0.00161742023192346185\n",
      "Episode Reward: 1.0\n",
      "Step 173 (221794) @ Episode 912/10000, loss: 0.00022466853260993958\n",
      "Episode Reward: 0.0\n",
      "Step 235 (222029) @ Episode 913/10000, loss: 0.00137544830795377544\n",
      "Episode Reward: 1.0\n",
      "Step 191 (222220) @ Episode 914/10000, loss: 0.00173391553107649094\n",
      "Episode Reward: 0.0\n",
      "Step 173 (222393) @ Episode 915/10000, loss: 0.00021548620134126395\n",
      "Episode Reward: 0.0\n",
      "Step 169 (222562) @ Episode 916/10000, loss: 0.00049878749996423723\n",
      "Episode Reward: 0.0\n",
      "Step 167 (222729) @ Episode 917/10000, loss: 0.00084549223538488151\n",
      "Episode Reward: 0.0\n",
      "Step 204 (222933) @ Episode 918/10000, loss: 0.00101337092928588453\n",
      "Episode Reward: 1.0\n",
      "Step 168 (223101) @ Episode 919/10000, loss: 0.00057233450934290894\n",
      "Episode Reward: 0.0\n",
      "Step 203 (223304) @ Episode 920/10000, loss: 0.00034745354787446563\n",
      "Episode Reward: 1.0\n",
      "Step 270 (223574) @ Episode 921/10000, loss: 0.00279619731009006554\n",
      "Episode Reward: 2.0\n",
      "Step 246 (223820) @ Episode 922/10000, loss: 0.00029168633045628667\n",
      "Episode Reward: 1.0\n",
      "Step 303 (224123) @ Episode 923/10000, loss: 0.00035320647293701774\n",
      "Episode Reward: 2.0\n",
      "Step 180 (224303) @ Episode 924/10000, loss: 0.00088844925630837686\n",
      "Episode Reward: 0.0\n",
      "Step 174 (224477) @ Episode 925/10000, loss: 0.00020990664779674262\n",
      "Episode Reward: 0.0\n",
      "Step 341 (224818) @ Episode 926/10000, loss: 0.00116218230687081814\n",
      "Episode Reward: 3.0\n",
      "Step 164 (224982) @ Episode 927/10000, loss: 0.00119020906277000903\n",
      "Episode Reward: 0.0\n",
      "Step 210 (225192) @ Episode 928/10000, loss: 0.00060473894700407986\n",
      "Episode Reward: 1.0\n",
      "Step 275 (225467) @ Episode 929/10000, loss: 0.00045490972115658224\n",
      "Episode Reward: 2.0\n",
      "Step 246 (225713) @ Episode 930/10000, loss: 0.00121806655079126367\n",
      "Episode Reward: 1.0\n",
      "Step 212 (225925) @ Episode 931/10000, loss: 0.00051115540554746992\n",
      "Episode Reward: 1.0\n",
      "Step 170 (226095) @ Episode 932/10000, loss: 0.00035257023409940364\n",
      "Episode Reward: 0.0\n",
      "Step 205 (226300) @ Episode 933/10000, loss: 0.00117774633690714845\n",
      "Episode Reward: 1.0\n",
      "Step 167 (226467) @ Episode 934/10000, loss: 0.00093714258400723347\n",
      "Episode Reward: 0.0\n",
      "Step 182 (226649) @ Episode 935/10000, loss: 0.00049214682076126344\n",
      "Episode Reward: 0.0\n",
      "Step 284 (226933) @ Episode 936/10000, loss: 0.00385128706693649333\n",
      "Episode Reward: 2.0\n",
      "Step 170 (227103) @ Episode 937/10000, loss: 0.00083341391291469346\n",
      "Episode Reward: 0.0\n",
      "Step 177 (227280) @ Episode 938/10000, loss: 0.00048603684990666807\n",
      "Episode Reward: 0.0\n",
      "Step 169 (227449) @ Episode 939/10000, loss: 0.00228755408897995954\n",
      "Episode Reward: 0.0\n",
      "Step 210 (227659) @ Episode 940/10000, loss: 0.00048886518925428395\n",
      "Episode Reward: 1.0\n",
      "Step 170 (227829) @ Episode 941/10000, loss: 0.00026178298867307603\n",
      "Episode Reward: 0.0\n",
      "Step 186 (228015) @ Episode 942/10000, loss: 0.00031313273939304054\n",
      "Episode Reward: 0.0\n",
      "Step 165 (228180) @ Episode 943/10000, loss: 0.00118276127614080976\n",
      "Episode Reward: 0.0\n",
      "Step 226 (228406) @ Episode 944/10000, loss: 0.00020273937843739986\n",
      "Episode Reward: 1.0\n",
      "Step 226 (228632) @ Episode 945/10000, loss: 0.00062194536440074446\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 203 (228835) @ Episode 946/10000, loss: 0.00032015290344133973\n",
      "Episode Reward: 1.0\n",
      "Step 171 (229006) @ Episode 947/10000, loss: 0.00038445630343630914\n",
      "Episode Reward: 0.0\n",
      "Step 165 (229171) @ Episode 948/10000, loss: 0.00049062038306146867\n",
      "Episode Reward: 0.0\n",
      "Step 254 (229425) @ Episode 949/10000, loss: 0.00090682681184262046\n",
      "Episode Reward: 2.0\n",
      "Step 167 (229592) @ Episode 950/10000, loss: 0.00030332538881339133\n",
      "Episode Reward: 0.0\n",
      "Step 172 (229764) @ Episode 951/10000, loss: 0.00073602108750492335\n",
      "Episode Reward: 0.0\n",
      "Step 235 (229999) @ Episode 952/10000, loss: 0.00028093345463275916\n",
      "Copied model parameters to target network.\n",
      "Step 251 (230015) @ Episode 952/10000, loss: 0.0053052157163619995\n",
      "Episode Reward: 2.0\n",
      "Step 318 (230333) @ Episode 953/10000, loss: 0.00051231292309239513\n",
      "Episode Reward: 3.0\n",
      "Step 236 (230569) @ Episode 954/10000, loss: 0.00059467134997248657\n",
      "Episode Reward: 1.0\n",
      "Step 318 (230887) @ Episode 955/10000, loss: 0.00088449008762836466\n",
      "Episode Reward: 3.0\n",
      "Step 169 (231056) @ Episode 956/10000, loss: 0.00040461943717673423\n",
      "Episode Reward: 0.0\n",
      "Step 173 (231229) @ Episode 957/10000, loss: 0.00049881328595802194\n",
      "Episode Reward: 0.0\n",
      "Step 322 (231551) @ Episode 958/10000, loss: 0.00030457327375188477\n",
      "Episode Reward: 2.0\n",
      "Step 271 (231822) @ Episode 959/10000, loss: 0.00048298109322786333\n",
      "Episode Reward: 2.0\n",
      "Step 263 (232085) @ Episode 960/10000, loss: 0.00111713283695280555\n",
      "Episode Reward: 2.0\n",
      "Step 220 (232305) @ Episode 961/10000, loss: 0.00057769956765696413\n",
      "Episode Reward: 1.0\n",
      "Step 198 (232503) @ Episode 962/10000, loss: 0.00419779820367693967\n",
      "Episode Reward: 0.0\n",
      "Step 176 (232679) @ Episode 963/10000, loss: 0.00170736503787338736\n",
      "Episode Reward: 0.0\n",
      "Step 169 (232848) @ Episode 964/10000, loss: 0.00086859677685424695\n",
      "Episode Reward: 0.0\n",
      "Step 236 (233084) @ Episode 965/10000, loss: 0.00048556784167885784\n",
      "Episode Reward: 1.0\n",
      "Step 436 (233520) @ Episode 966/10000, loss: 0.00047689522034488626\n",
      "Episode Reward: 4.0\n",
      "Step 243 (233763) @ Episode 967/10000, loss: 0.00048833794426172977\n",
      "Episode Reward: 2.0\n",
      "Step 464 (234227) @ Episode 968/10000, loss: 0.00074618944199755796\n",
      "Episode Reward: 5.0\n",
      "Step 174 (234401) @ Episode 969/10000, loss: 0.00121155451051890856\n",
      "Episode Reward: 0.0\n",
      "Step 220 (234621) @ Episode 970/10000, loss: 0.00210048398002982143\n",
      "Episode Reward: 1.0\n",
      "Step 282 (234903) @ Episode 971/10000, loss: 0.00492376321926713447\n",
      "Episode Reward: 2.0\n",
      "Step 217 (235120) @ Episode 972/10000, loss: 0.00082387571455910874\n",
      "Episode Reward: 1.0\n",
      "Step 173 (235293) @ Episode 973/10000, loss: 0.00046787137398496276\n",
      "Episode Reward: 0.0\n",
      "Step 173 (235466) @ Episode 974/10000, loss: 0.00038222881266847253\n",
      "Episode Reward: 0.0\n",
      "Step 355 (235821) @ Episode 975/10000, loss: 0.00029699836159124976\n",
      "Episode Reward: 4.0\n",
      "Step 204 (236025) @ Episode 976/10000, loss: 0.00670463684946298674\n",
      "Episode Reward: 1.0\n",
      "Step 245 (236270) @ Episode 977/10000, loss: 0.00029774426366202533\n",
      "Episode Reward: 1.0\n",
      "Step 169 (236439) @ Episode 978/10000, loss: 0.00045861341641284525\n",
      "Episode Reward: 0.0\n",
      "Step 201 (236640) @ Episode 979/10000, loss: 0.00115158036351203925\n",
      "Episode Reward: 1.0\n",
      "Step 261 (236901) @ Episode 980/10000, loss: 0.00025282567366957664\n",
      "Episode Reward: 2.0\n",
      "Step 217 (237118) @ Episode 981/10000, loss: 0.00160822703037410977\n",
      "Episode Reward: 1.0\n",
      "Step 178 (237296) @ Episode 982/10000, loss: 0.00029222862212918774\n",
      "Episode Reward: 0.0\n",
      "Step 261 (237557) @ Episode 983/10000, loss: 0.00165916583500802522\n",
      "Episode Reward: 2.0\n",
      "Step 168 (237725) @ Episode 984/10000, loss: 0.00033246475504711273\n",
      "Episode Reward: 0.0\n",
      "Step 168 (237893) @ Episode 985/10000, loss: 0.00050527445273473865\n",
      "Episode Reward: 0.0\n",
      "Step 354 (238247) @ Episode 986/10000, loss: 0.00036071107024326926\n",
      "Episode Reward: 4.0\n",
      "Step 233 (238480) @ Episode 987/10000, loss: 0.00073747395072132353\n",
      "Episode Reward: 1.0\n",
      "Step 264 (238744) @ Episode 988/10000, loss: 0.00057005445705726745\n",
      "Episode Reward: 2.0\n",
      "Step 175 (238919) @ Episode 989/10000, loss: 0.00042192847467958927\n",
      "Episode Reward: 0.0\n",
      "Step 169 (239088) @ Episode 990/10000, loss: 0.00038418770418502397\n",
      "Episode Reward: 0.0\n",
      "Step 237 (239325) @ Episode 991/10000, loss: 0.00066108361352235086\n",
      "Episode Reward: 1.0\n",
      "Step 164 (239489) @ Episode 992/10000, loss: 0.00066316139418631793\n",
      "Episode Reward: 0.0\n",
      "Step 167 (239656) @ Episode 993/10000, loss: 0.00185781565960496665\n",
      "Episode Reward: 0.0\n",
      "Step 181 (239837) @ Episode 994/10000, loss: 0.00109734688885509974\n",
      "Episode Reward: 0.0\n",
      "Step 162 (239999) @ Episode 995/10000, loss: 0.00095269118901342153\n",
      "Copied model parameters to target network.\n",
      "Step 245 (240082) @ Episode 995/10000, loss: 0.0010331296361982822\n",
      "Episode Reward: 1.0\n",
      "Step 223 (240305) @ Episode 996/10000, loss: 0.00158657226711511617\n",
      "Episode Reward: 1.0\n",
      "Step 208 (240513) @ Episode 997/10000, loss: 0.00114446901716291956\n",
      "Episode Reward: 1.0\n",
      "Step 163 (240676) @ Episode 998/10000, loss: 0.00084968609735369683\n",
      "Episode Reward: 0.0\n",
      "Step 177 (240853) @ Episode 999/10000, loss: 0.00203319522552192295\n",
      "Episode Reward: 0.0\n",
      "Step 272 (241125) @ Episode 1000/10000, loss: 0.00180144980549812324\n",
      "Episode Reward: 2.0\n",
      "Step 209 (241334) @ Episode 1001/10000, loss: 0.00129675015341490565\n",
      "Episode Reward: 1.0\n",
      "Step 167 (241501) @ Episode 1002/10000, loss: 0.00451935548335313875\n",
      "Episode Reward: 0.0\n",
      "Step 233 (241734) @ Episode 1003/10000, loss: 0.00090451835421845325\n",
      "Episode Reward: 1.0\n",
      "Step 265 (241999) @ Episode 1004/10000, loss: 0.00129313941579312098\n",
      "Episode Reward: 2.0\n",
      "Step 171 (242170) @ Episode 1005/10000, loss: 0.00100051960907876595\n",
      "Episode Reward: 0.0\n",
      "Step 288 (242458) @ Episode 1006/10000, loss: 0.00040184735553339124\n",
      "Episode Reward: 2.0\n",
      "Step 168 (242626) @ Episode 1007/10000, loss: 0.00079834432108327755\n",
      "Episode Reward: 0.0\n",
      "Step 165 (242791) @ Episode 1008/10000, loss: 0.00047333320253528655\n",
      "Episode Reward: 0.0\n",
      "Step 206 (242997) @ Episode 1009/10000, loss: 0.00084388954564929016\n",
      "Episode Reward: 1.0\n",
      "Step 315 (243312) @ Episode 1010/10000, loss: 0.00062854337738826872\n",
      "Episode Reward: 3.0\n",
      "Step 208 (243520) @ Episode 1011/10000, loss: 0.00032781649497337647\n",
      "Episode Reward: 1.0\n",
      "Step 164 (243684) @ Episode 1012/10000, loss: 0.00178272626362741034\n",
      "Episode Reward: 0.0\n",
      "Step 223 (243907) @ Episode 1013/10000, loss: 0.00110598234459757842\n",
      "Episode Reward: 1.0\n",
      "Step 229 (244136) @ Episode 1014/10000, loss: 0.00025111887953244158\n",
      "Episode Reward: 1.0\n",
      "Step 182 (244318) @ Episode 1015/10000, loss: 0.00128098914865404376\n",
      "Episode Reward: 0.0\n",
      "Step 228 (244546) @ Episode 1016/10000, loss: 0.00035658205160871155\n",
      "Episode Reward: 1.0\n",
      "Step 237 (244783) @ Episode 1017/10000, loss: 0.00470279622822999957\n",
      "Episode Reward: 1.0\n",
      "Step 213 (244996) @ Episode 1018/10000, loss: 0.00057973980437964266\n",
      "Episode Reward: 1.0\n",
      "Step 319 (245315) @ Episode 1019/10000, loss: 0.00102280569262802625\n",
      "Episode Reward: 2.0\n",
      "Step 228 (245543) @ Episode 1020/10000, loss: 0.00635022437199950236\n",
      "Episode Reward: 1.0\n",
      "Step 271 (245814) @ Episode 1021/10000, loss: 0.00309674441814422663\n",
      "Episode Reward: 2.0\n",
      "Step 297 (246111) @ Episode 1022/10000, loss: 0.00045702606439590454\n",
      "Episode Reward: 3.0\n",
      "Step 199 (246310) @ Episode 1023/10000, loss: 0.00197948934510350233\n",
      "Episode Reward: 1.0\n",
      "Step 302 (246612) @ Episode 1024/10000, loss: 0.00042697117896750575\n",
      "Episode Reward: 2.0\n",
      "Step 232 (246844) @ Episode 1025/10000, loss: 0.00316983903758227832\n",
      "Episode Reward: 1.0\n",
      "Step 350 (247194) @ Episode 1026/10000, loss: 0.00067569938255473976\n",
      "Episode Reward: 4.0\n",
      "Step 315 (247509) @ Episode 1027/10000, loss: 0.00019279099069535732\n",
      "Episode Reward: 3.0\n",
      "Step 296 (247805) @ Episode 1028/10000, loss: 0.00385326216928660875\n",
      "Episode Reward: 2.0\n",
      "Step 169 (247974) @ Episode 1029/10000, loss: 0.00048361244262196124\n",
      "Episode Reward: 0.0\n",
      "Step 303 (248277) @ Episode 1030/10000, loss: 0.00034904375206679106\n",
      "Episode Reward: 2.0\n",
      "Step 169 (248446) @ Episode 1031/10000, loss: 0.00158284767530858527\n",
      "Episode Reward: 0.0\n",
      "Step 247 (248693) @ Episode 1032/10000, loss: 0.00236671860329806835\n",
      "Episode Reward: 1.0\n",
      "Step 162 (248855) @ Episode 1033/10000, loss: 0.00136910215951502325\n",
      "Episode Reward: 0.0\n",
      "Step 201 (249056) @ Episode 1034/10000, loss: 0.00024657315225340426\n",
      "Episode Reward: 1.0\n",
      "Step 302 (249358) @ Episode 1035/10000, loss: 0.00223980192095041286\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 221 (249579) @ Episode 1036/10000, loss: 0.00016437892918474972\n",
      "Episode Reward: 1.0\n",
      "Step 167 (249746) @ Episode 1037/10000, loss: 0.00047835652367211886\n",
      "Episode Reward: 0.0\n",
      "Step 167 (249913) @ Episode 1038/10000, loss: 0.00313243526034057143\n",
      "Episode Reward: 0.0\n",
      "Step 86 (249999) @ Episode 1039/10000, loss: 0.00106934364885091783\n",
      "Copied model parameters to target network.\n",
      "Step 168 (250081) @ Episode 1039/10000, loss: 0.00267201894894242383\n",
      "Episode Reward: 0.0\n",
      "Step 205 (250286) @ Episode 1040/10000, loss: 0.00118489610031247146\n",
      "Episode Reward: 1.0\n",
      "Step 217 (250503) @ Episode 1041/10000, loss: 0.00046361889690160756\n",
      "Episode Reward: 1.0\n",
      "Step 164 (250667) @ Episode 1042/10000, loss: 0.00087625312153249986\n",
      "Episode Reward: 0.0\n",
      "Step 254 (250921) @ Episode 1043/10000, loss: 0.00060318375471979383\n",
      "Episode Reward: 1.0\n",
      "Step 254 (251175) @ Episode 1044/10000, loss: 0.00384592195041477713\n",
      "Episode Reward: 1.0\n",
      "Step 233 (251408) @ Episode 1045/10000, loss: 0.00070344877894967792\n",
      "Episode Reward: 1.0\n",
      "Step 317 (251725) @ Episode 1046/10000, loss: 0.00173816620372235775\n",
      "Episode Reward: 3.0\n",
      "Step 300 (252025) @ Episode 1047/10000, loss: 0.00127470341976732027\n",
      "Episode Reward: 2.0\n",
      "Step 275 (252300) @ Episode 1048/10000, loss: 0.00064338429365307094\n",
      "Episode Reward: 2.0\n",
      "Step 204 (252504) @ Episode 1049/10000, loss: 0.00101588910911232237\n",
      "Episode Reward: 1.0\n",
      "Step 179 (252683) @ Episode 1050/10000, loss: 0.00314421206712722855\n",
      "Episode Reward: 0.0\n",
      "Step 247 (252930) @ Episode 1051/10000, loss: 0.00403237063437700317\n",
      "Episode Reward: 1.0\n",
      "Step 186 (253116) @ Episode 1052/10000, loss: 0.00192431884352117785\n",
      "Episode Reward: 0.0\n",
      "Step 235 (253351) @ Episode 1053/10000, loss: 0.00138945295475423343\n",
      "Episode Reward: 1.0\n",
      "Step 169 (253520) @ Episode 1054/10000, loss: 0.00116272852756083019\n",
      "Episode Reward: 0.0\n",
      "Step 165 (253685) @ Episode 1055/10000, loss: 0.00185621192213147886\n",
      "Episode Reward: 0.0\n",
      "Step 207 (253892) @ Episode 1056/10000, loss: 0.00023809386766515672\n",
      "Episode Reward: 1.0\n",
      "Step 300 (254192) @ Episode 1057/10000, loss: 0.00037629299913533033\n",
      "Episode Reward: 2.0\n",
      "Step 177 (254369) @ Episode 1058/10000, loss: 0.00119586696382612133\n",
      "Episode Reward: 0.0\n",
      "Step 364 (254733) @ Episode 1059/10000, loss: 0.00151917361654341225\n",
      "Episode Reward: 3.0\n",
      "Step 219 (254952) @ Episode 1060/10000, loss: 0.00064616295276209715\n",
      "Episode Reward: 1.0\n",
      "Step 300 (255252) @ Episode 1061/10000, loss: 0.00039253308204934238\n",
      "Episode Reward: 2.0\n",
      "Step 172 (255424) @ Episode 1062/10000, loss: 0.00118661636952310816\n",
      "Episode Reward: 0.0\n",
      "Step 242 (255666) @ Episode 1063/10000, loss: 0.00030219083419069653\n",
      "Episode Reward: 1.0\n",
      "Step 258 (255924) @ Episode 1064/10000, loss: 0.00036363198887556795\n",
      "Episode Reward: 1.0\n",
      "Step 278 (256202) @ Episode 1065/10000, loss: 0.00098900252487510447\n",
      "Episode Reward: 2.0\n",
      "Step 228 (256430) @ Episode 1066/10000, loss: 0.00077347725164145237\n",
      "Episode Reward: 1.0\n",
      "Step 293 (256723) @ Episode 1067/10000, loss: 0.00020057513029314578\n",
      "Episode Reward: 2.0\n",
      "Step 255 (256978) @ Episode 1068/10000, loss: 0.00027417688397690654\n",
      "Episode Reward: 1.0\n",
      "Step 220 (257198) @ Episode 1069/10000, loss: 0.00086756329983472823\n",
      "Episode Reward: 1.0\n",
      "Step 302 (257500) @ Episode 1070/10000, loss: 0.00091465824516490147\n",
      "Episode Reward: 2.0\n",
      "Step 169 (257669) @ Episode 1071/10000, loss: 0.00047764167538844055\n",
      "Episode Reward: 0.0\n",
      "Step 252 (257921) @ Episode 1072/10000, loss: 0.00016392866382375364\n",
      "Episode Reward: 1.0\n",
      "Step 169 (258090) @ Episode 1073/10000, loss: 0.00056140433298423897\n",
      "Episode Reward: 0.0\n",
      "Step 282 (258372) @ Episode 1074/10000, loss: 0.00020314082212280482\n",
      "Episode Reward: 2.0\n",
      "Step 219 (258591) @ Episode 1075/10000, loss: 0.00027800505631603364\n",
      "Episode Reward: 1.0\n",
      "Step 273 (258864) @ Episode 1076/10000, loss: 0.00092846306506544355\n",
      "Episode Reward: 2.0\n",
      "Step 189 (259053) @ Episode 1077/10000, loss: 0.00049547979142516855\n",
      "Episode Reward: 0.0\n",
      "Step 230 (259283) @ Episode 1078/10000, loss: 0.00058196508325636394\n",
      "Episode Reward: 1.0\n",
      "Step 358 (259641) @ Episode 1079/10000, loss: 0.00017745536752045155\n",
      "Episode Reward: 4.0\n",
      "Step 235 (259876) @ Episode 1080/10000, loss: 0.00056718289852142333\n",
      "Episode Reward: 1.0\n",
      "Step 123 (259999) @ Episode 1081/10000, loss: 0.00070516968844458464\n",
      "Copied model parameters to target network.\n",
      "Step 213 (260089) @ Episode 1081/10000, loss: 0.00118898728396743545\n",
      "Episode Reward: 1.0\n",
      "Step 280 (260369) @ Episode 1082/10000, loss: 0.00192854390479624273\n",
      "Episode Reward: 2.0\n",
      "Step 290 (260659) @ Episode 1083/10000, loss: 0.00408436032012105764\n",
      "Episode Reward: 2.0\n",
      "Step 184 (260843) @ Episode 1084/10000, loss: 0.00110784103162586695\n",
      "Episode Reward: 0.0\n",
      "Step 202 (261045) @ Episode 1085/10000, loss: 0.00079352210741490134\n",
      "Episode Reward: 1.0\n",
      "Step 161 (261206) @ Episode 1086/10000, loss: 0.00133612786885350945\n",
      "Episode Reward: 0.0\n",
      "Step 256 (261462) @ Episode 1087/10000, loss: 0.00193674548063427246\n",
      "Episode Reward: 2.0\n",
      "Step 263 (261725) @ Episode 1088/10000, loss: 0.00053794641280546783\n",
      "Episode Reward: 2.0\n",
      "Step 255 (261980) @ Episode 1089/10000, loss: 0.00065585615811869518\n",
      "Episode Reward: 2.0\n",
      "Step 212 (262192) @ Episode 1090/10000, loss: 0.00040285949944518507\n",
      "Episode Reward: 1.0\n",
      "Step 211 (262403) @ Episode 1091/10000, loss: 0.00048638563021086156\n",
      "Episode Reward: 1.0\n",
      "Step 177 (262580) @ Episode 1092/10000, loss: 0.00064380693947896364\n",
      "Episode Reward: 0.0\n",
      "Step 217 (262797) @ Episode 1093/10000, loss: 0.00089717347873374826\n",
      "Episode Reward: 1.0\n",
      "Step 208 (263005) @ Episode 1094/10000, loss: 0.00269356253556907186\n",
      "Episode Reward: 1.0\n",
      "Step 450 (263455) @ Episode 1095/10000, loss: 0.00326498551294207572\n",
      "Episode Reward: 4.0\n",
      "Step 269 (263724) @ Episode 1096/10000, loss: 0.00224099145270884044\n",
      "Episode Reward: 2.0\n",
      "Step 244 (263968) @ Episode 1097/10000, loss: 0.00074664026033133276\n",
      "Episode Reward: 1.0\n",
      "Step 236 (264204) @ Episode 1098/10000, loss: 0.00052612810395658025\n",
      "Episode Reward: 1.0\n",
      "Step 203 (264407) @ Episode 1099/10000, loss: 0.00179812812712043522\n",
      "Episode Reward: 1.0\n",
      "Step 246 (264653) @ Episode 1100/10000, loss: 0.00089387502521276477\n",
      "Episode Reward: 2.0\n",
      "Step 448 (265101) @ Episode 1101/10000, loss: 0.00049951433902606375\n",
      "Episode Reward: 5.0\n",
      "Step 420 (265521) @ Episode 1102/10000, loss: 0.00379447522573173058\n",
      "Episode Reward: 6.0\n",
      "Step 259 (265780) @ Episode 1103/10000, loss: 0.00033977488055825233\n",
      "Episode Reward: 2.0\n",
      "Step 314 (266094) @ Episode 1104/10000, loss: 0.00634481245651841216\n",
      "Episode Reward: 2.0\n",
      "Step 178 (266272) @ Episode 1105/10000, loss: 0.00070013228105381134\n",
      "Episode Reward: 0.0\n",
      "Step 352 (266624) @ Episode 1106/10000, loss: 0.00064806145383045085\n",
      "Episode Reward: 3.0\n",
      "Step 231 (266855) @ Episode 1107/10000, loss: 0.00028881343314424157\n",
      "Episode Reward: 1.0\n",
      "Step 209 (267064) @ Episode 1108/10000, loss: 0.00634726602584123696\n",
      "Episode Reward: 1.0\n",
      "Step 273 (267337) @ Episode 1109/10000, loss: 0.00067396782105788597\n",
      "Episode Reward: 2.0\n",
      "Step 162 (267499) @ Episode 1110/10000, loss: 0.00023289148521143943\n",
      "Episode Reward: 0.0\n",
      "Step 250 (267749) @ Episode 1111/10000, loss: 0.00056791712995618585\n",
      "Episode Reward: 1.0\n",
      "Step 223 (267972) @ Episode 1112/10000, loss: 0.00049853388918563727\n",
      "Episode Reward: 1.0\n",
      "Step 171 (268143) @ Episode 1113/10000, loss: 0.00052420207066461444\n",
      "Episode Reward: 0.0\n",
      "Step 179 (268322) @ Episode 1114/10000, loss: 0.00187338085379451515\n",
      "Episode Reward: 0.0\n",
      "Step 208 (268530) @ Episode 1115/10000, loss: 0.00053802580805495383\n",
      "Episode Reward: 1.0\n",
      "Step 176 (268706) @ Episode 1116/10000, loss: 0.00051859189989045263\n",
      "Episode Reward: 0.0\n",
      "Step 312 (269018) @ Episode 1117/10000, loss: 0.00429543014615774153\n",
      "Episode Reward: 3.0\n",
      "Step 331 (269349) @ Episode 1118/10000, loss: 0.00402864441275596683\n",
      "Episode Reward: 2.0\n",
      "Step 170 (269519) @ Episode 1119/10000, loss: 0.00116674660239368686\n",
      "Episode Reward: 0.0\n",
      "Step 306 (269825) @ Episode 1120/10000, loss: 0.00125445530284196145\n",
      "Episode Reward: 2.0\n",
      "Step 174 (269999) @ Episode 1121/10000, loss: 0.00040325667941942813\n",
      "Copied model parameters to target network.\n",
      "Step 246 (270071) @ Episode 1121/10000, loss: 0.0034718890674412256\n",
      "Episode Reward: 1.0\n",
      "Step 162 (270233) @ Episode 1122/10000, loss: 0.00655769463628530596\n",
      "Episode Reward: 0.0\n",
      "Step 182 (270415) @ Episode 1123/10000, loss: 0.00389333441853523255\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 223 (270638) @ Episode 1124/10000, loss: 0.00230325059965252883\n",
      "Episode Reward: 1.0\n",
      "Step 491 (271129) @ Episode 1125/10000, loss: 0.00208421959541738038\n",
      "Episode Reward: 5.0\n",
      "Step 227 (271356) @ Episode 1126/10000, loss: 0.00133302633184939625\n",
      "Episode Reward: 1.0\n",
      "Step 291 (271647) @ Episode 1127/10000, loss: 0.00052724068518728023\n",
      "Episode Reward: 2.0\n",
      "Step 212 (271859) @ Episode 1128/10000, loss: 0.00251719355583190916\n",
      "Episode Reward: 1.0\n",
      "Step 270 (272129) @ Episode 1129/10000, loss: 0.00079696567263454215\n",
      "Episode Reward: 2.0\n",
      "Step 420 (272549) @ Episode 1130/10000, loss: 0.00154485588427633055\n",
      "Episode Reward: 5.0\n",
      "Step 172 (272721) @ Episode 1131/10000, loss: 0.00094750791322439917\n",
      "Episode Reward: 0.0\n",
      "Step 287 (273008) @ Episode 1132/10000, loss: 0.00031344546005129814\n",
      "Episode Reward: 2.0\n",
      "Step 167 (273175) @ Episode 1133/10000, loss: 0.00121954618953168454\n",
      "Episode Reward: 0.0\n",
      "Step 251 (273426) @ Episode 1134/10000, loss: 0.00045434487401507795\n",
      "Episode Reward: 1.0\n",
      "Step 313 (273739) @ Episode 1135/10000, loss: 0.00143180484883487223\n",
      "Episode Reward: 3.0\n",
      "Step 357 (274096) @ Episode 1136/10000, loss: 0.00088519259588792923\n",
      "Episode Reward: 3.0\n",
      "Step 292 (274388) @ Episode 1137/10000, loss: 0.00063236558344215154\n",
      "Episode Reward: 3.0\n",
      "Step 207 (274595) @ Episode 1138/10000, loss: 0.00056617887457832696\n",
      "Episode Reward: 1.0\n",
      "Step 247 (274842) @ Episode 1139/10000, loss: 0.00057064427528530364\n",
      "Episode Reward: 2.0\n",
      "Step 228 (275070) @ Episode 1140/10000, loss: 0.00024345386191271245\n",
      "Episode Reward: 1.0\n",
      "Step 273 (275343) @ Episode 1141/10000, loss: 0.00052374007645994424\n",
      "Episode Reward: 2.0\n",
      "Step 239 (275582) @ Episode 1142/10000, loss: 0.00382412667386233887\n",
      "Episode Reward: 1.0\n",
      "Step 230 (275812) @ Episode 1143/10000, loss: 0.00062738923588767657\n",
      "Episode Reward: 1.0\n",
      "Step 244 (276056) @ Episode 1144/10000, loss: 0.00213640183210372923\n",
      "Episode Reward: 1.0\n",
      "Step 288 (276344) @ Episode 1145/10000, loss: 0.00113482656888663774\n",
      "Episode Reward: 2.0\n",
      "Step 202 (276546) @ Episode 1146/10000, loss: 0.00140909838955849437\n",
      "Episode Reward: 1.0\n",
      "Step 234 (276780) @ Episode 1147/10000, loss: 0.00092729646712541586\n",
      "Episode Reward: 1.0\n",
      "Step 283 (277063) @ Episode 1148/10000, loss: 0.00055912154493853455\n",
      "Episode Reward: 2.0\n",
      "Step 343 (277406) @ Episode 1149/10000, loss: 0.00041342535405419767\n",
      "Episode Reward: 3.0\n",
      "Step 214 (277620) @ Episode 1150/10000, loss: 0.00072802760405465965\n",
      "Episode Reward: 1.0\n",
      "Step 344 (277964) @ Episode 1151/10000, loss: 0.00043105916120111944\n",
      "Episode Reward: 3.0\n",
      "Step 170 (278134) @ Episode 1152/10000, loss: 0.00272457487881183625\n",
      "Episode Reward: 0.0\n",
      "Step 353 (278487) @ Episode 1153/10000, loss: 0.00034134514862671494\n",
      "Episode Reward: 4.0\n",
      "Step 185 (278672) @ Episode 1154/10000, loss: 0.00132951361592859037\n",
      "Episode Reward: 0.0\n",
      "Step 272 (278944) @ Episode 1155/10000, loss: 0.00088191562099382286\n",
      "Episode Reward: 1.0\n",
      "Step 230 (279174) @ Episode 1156/10000, loss: 0.00090928218560293326\n",
      "Episode Reward: 1.0\n",
      "Step 209 (279383) @ Episode 1157/10000, loss: 0.00231001060456037586\n",
      "Episode Reward: 1.0\n",
      "Step 439 (279822) @ Episode 1158/10000, loss: 0.00029326783260330567\n",
      "Episode Reward: 4.0\n",
      "Step 177 (279999) @ Episode 1159/10000, loss: 0.00024341780226677656\n",
      "Copied model parameters to target network.\n",
      "Step 309 (280131) @ Episode 1159/10000, loss: 0.00190990732517093425\n",
      "Episode Reward: 3.0\n",
      "Step 208 (280339) @ Episode 1160/10000, loss: 0.00144394976086914543\n",
      "Episode Reward: 1.0\n",
      "Step 284 (280623) @ Episode 1161/10000, loss: 0.00589146325364708956\n",
      "Episode Reward: 2.0\n",
      "Step 173 (280796) @ Episode 1162/10000, loss: 0.00065372925018891697\n",
      "Episode Reward: 0.0\n",
      "Step 252 (281048) @ Episode 1163/10000, loss: 0.00146235001739114527\n",
      "Episode Reward: 1.0\n",
      "Step 199 (281247) @ Episode 1164/10000, loss: 0.00266889971680939227\n",
      "Episode Reward: 1.0\n",
      "Step 211 (281458) @ Episode 1165/10000, loss: 0.00081531738396734584\n",
      "Episode Reward: 1.0\n",
      "Step 300 (281758) @ Episode 1166/10000, loss: 0.00526662683114409456\n",
      "Episode Reward: 3.0\n",
      "Step 213 (281971) @ Episode 1167/10000, loss: 0.00140338926576077944\n",
      "Episode Reward: 1.0\n",
      "Step 172 (282143) @ Episode 1168/10000, loss: 0.00079032441135495963\n",
      "Episode Reward: 0.0\n",
      "Step 407 (282550) @ Episode 1169/10000, loss: 0.00059641187544912196\n",
      "Episode Reward: 4.0\n",
      "Step 214 (282764) @ Episode 1170/10000, loss: 0.00089732080232352024\n",
      "Episode Reward: 1.0\n",
      "Step 220 (282984) @ Episode 1171/10000, loss: 0.00037036603316664696\n",
      "Episode Reward: 1.0\n",
      "Step 259 (283243) @ Episode 1172/10000, loss: 0.00059518771013244994\n",
      "Episode Reward: 2.0\n",
      "Step 304 (283547) @ Episode 1173/10000, loss: 0.00060566386673599484\n",
      "Episode Reward: 3.0\n",
      "Step 279 (283826) @ Episode 1174/10000, loss: 0.00049399829003959897\n",
      "Episode Reward: 2.0\n",
      "Step 168 (283994) @ Episode 1175/10000, loss: 0.00084581784904003147\n",
      "Episode Reward: 0.0\n",
      "Step 482 (284476) @ Episode 1176/10000, loss: 0.00197745021432638175\n",
      "Episode Reward: 6.0\n",
      "Step 381 (284857) @ Episode 1177/10000, loss: 0.00230297679081559273\n",
      "Episode Reward: 3.0\n",
      "Step 297 (285154) @ Episode 1178/10000, loss: 0.00162090896628797056\n",
      "Episode Reward: 2.0\n",
      "Step 249 (285403) @ Episode 1179/10000, loss: 0.00364052061922848226\n",
      "Episode Reward: 1.0\n",
      "Step 176 (285579) @ Episode 1180/10000, loss: 0.00071706587914377455\n",
      "Episode Reward: 0.0\n",
      "Step 218 (285797) @ Episode 1181/10000, loss: 0.00222753663547337066\n",
      "Episode Reward: 1.0\n",
      "Step 231 (286028) @ Episode 1182/10000, loss: 0.00056010676780715584\n",
      "Episode Reward: 1.0\n",
      "Step 167 (286195) @ Episode 1183/10000, loss: 0.00086536735761910684\n",
      "Episode Reward: 0.0\n",
      "Step 235 (286430) @ Episode 1184/10000, loss: 0.00024838739773258567\n",
      "Episode Reward: 1.0\n",
      "Step 288 (286718) @ Episode 1185/10000, loss: 0.00039563924656249583\n",
      "Episode Reward: 2.0\n",
      "Step 230 (286948) @ Episode 1186/10000, loss: 0.00472981203347444536\n",
      "Episode Reward: 1.0\n",
      "Step 212 (287160) @ Episode 1187/10000, loss: 0.00069419638020917774\n",
      "Episode Reward: 1.0\n",
      "Step 508 (287668) @ Episode 1188/10000, loss: 0.00102586380671709785\n",
      "Episode Reward: 6.0\n",
      "Step 362 (288030) @ Episode 1189/10000, loss: 0.00049682735698297624\n",
      "Episode Reward: 3.0\n",
      "Step 279 (288309) @ Episode 1190/10000, loss: 0.00190836470574140556\n",
      "Episode Reward: 2.0\n",
      "Step 168 (288477) @ Episode 1191/10000, loss: 0.00037896190769970417\n",
      "Episode Reward: 0.0\n",
      "Step 158 (288635) @ Episode 1192/10000, loss: 0.00050494162132963547\n",
      "Episode Reward: 0.0\n",
      "Step 404 (289039) @ Episode 1193/10000, loss: 0.00209291838109493267\n",
      "Episode Reward: 4.0\n",
      "Step 288 (289327) @ Episode 1194/10000, loss: 0.00179078523069620138\n",
      "Episode Reward: 2.0\n",
      "Step 207 (289534) @ Episode 1195/10000, loss: 0.00775327067822217933\n",
      "Episode Reward: 1.0\n",
      "Step 310 (289844) @ Episode 1196/10000, loss: 0.00083260441897436986\n",
      "Episode Reward: 3.0\n",
      "Step 155 (289999) @ Episode 1197/10000, loss: 0.00364050129428505913\n",
      "Copied model parameters to target network.\n",
      "Step 298 (290142) @ Episode 1197/10000, loss: 0.0009051256929524243\n",
      "Episode Reward: 3.0\n",
      "Step 177 (290319) @ Episode 1198/10000, loss: 0.0020198696292936886\n",
      "Episode Reward: 0.0\n",
      "Step 212 (290531) @ Episode 1199/10000, loss: 0.00117512128781527285\n",
      "Episode Reward: 1.0\n",
      "Step 164 (290695) @ Episode 1200/10000, loss: 0.00053950527217239144\n",
      "Episode Reward: 0.0\n",
      "Step 763 (291458) @ Episode 1201/10000, loss: 0.00042600333108566786\n",
      "Episode Reward: 11.0\n",
      "Step 209 (291667) @ Episode 1202/10000, loss: 0.0034140269272029413\n",
      "Episode Reward: 1.0\n",
      "Step 186 (291853) @ Episode 1203/10000, loss: 0.0030010687187314034\n",
      "Episode Reward: 0.0\n",
      "Step 301 (292154) @ Episode 1204/10000, loss: 0.0005334917223080993\n",
      "Episode Reward: 2.0\n",
      "Step 416 (292570) @ Episode 1205/10000, loss: 0.00273976218886673455\n",
      "Episode Reward: 4.0\n",
      "Step 248 (292818) @ Episode 1206/10000, loss: 0.00190956820733845234\n",
      "Episode Reward: 2.0\n",
      "Step 302 (293120) @ Episode 1207/10000, loss: 0.00072834873571991923\n",
      "Episode Reward: 3.0\n",
      "Step 206 (293326) @ Episode 1208/10000, loss: 0.00159775651991367346\n",
      "Episode Reward: 1.0\n",
      "Step 268 (293594) @ Episode 1209/10000, loss: 0.00374775985255837446\n",
      "Episode Reward: 2.0\n",
      "Step 171 (293765) @ Episode 1210/10000, loss: 0.00112634594552218914\n",
      "Episode Reward: 0.0\n",
      "Step 418 (294183) @ Episode 1211/10000, loss: 0.00095596315804868944\n",
      "Episode Reward: 5.0\n",
      "Step 225 (294408) @ Episode 1212/10000, loss: 0.00109529052861034874\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 427 (294835) @ Episode 1213/10000, loss: 0.00139038939960300925\n",
      "Episode Reward: 4.0\n",
      "Step 343 (295178) @ Episode 1214/10000, loss: 0.00142461562063544995\n",
      "Episode Reward: 2.0\n",
      "Step 169 (295347) @ Episode 1215/10000, loss: 0.00192580837756395347\n",
      "Episode Reward: 0.0\n",
      "Step 353 (295700) @ Episode 1216/10000, loss: 0.00243991939350962647\n",
      "Episode Reward: 3.0\n",
      "Step 589 (296289) @ Episode 1217/10000, loss: 0.00329606048762798315\n",
      "Episode Reward: 7.0\n",
      "Step 395 (296684) @ Episode 1218/10000, loss: 0.00089505512733012443\n",
      "Episode Reward: 4.0\n",
      "Step 305 (296989) @ Episode 1219/10000, loss: 0.00066484836861491287\n",
      "Episode Reward: 2.0\n",
      "Step 287 (297276) @ Episode 1220/10000, loss: 0.00163057190366089346\n",
      "Episode Reward: 2.0\n",
      "Step 219 (297495) @ Episode 1221/10000, loss: 0.00073395279468968513\n",
      "Episode Reward: 1.0\n",
      "Step 245 (297740) @ Episode 1222/10000, loss: 0.00045182061148807406\n",
      "Episode Reward: 2.0\n",
      "Step 263 (298003) @ Episode 1223/10000, loss: 0.00047203555004671216\n",
      "Episode Reward: 2.0\n",
      "Step 270 (298273) @ Episode 1224/10000, loss: 0.00318770739249885163\n",
      "Episode Reward: 2.0\n",
      "Step 206 (298479) @ Episode 1225/10000, loss: 0.00027510354993864894\n",
      "Episode Reward: 1.0\n",
      "Step 310 (298789) @ Episode 1226/10000, loss: 0.00056877348106354486\n",
      "Episode Reward: 2.0\n",
      "Step 429 (299218) @ Episode 1227/10000, loss: 0.00028120150091126563\n",
      "Episode Reward: 4.0\n",
      "Step 284 (299502) @ Episode 1228/10000, loss: 0.00031024619238451123\n",
      "Episode Reward: 2.0\n",
      "Step 314 (299816) @ Episode 1229/10000, loss: 0.00098218291532248264\n",
      "Episode Reward: 3.0\n",
      "Step 183 (299999) @ Episode 1230/10000, loss: 0.00207803607918322173\n",
      "Copied model parameters to target network.\n",
      "Step 217 (300033) @ Episode 1230/10000, loss: 0.0030382699333131313\n",
      "Episode Reward: 1.0\n",
      "Step 179 (300212) @ Episode 1231/10000, loss: 0.00178146641701459883\n",
      "Episode Reward: 0.0\n",
      "Step 313 (300525) @ Episode 1232/10000, loss: 0.00330967898480594165\n",
      "Episode Reward: 3.0\n",
      "Step 330 (300855) @ Episode 1233/10000, loss: 0.00273766252212226433\n",
      "Episode Reward: 3.0\n",
      "Step 355 (301210) @ Episode 1234/10000, loss: 0.00200468138791620737\n",
      "Episode Reward: 4.0\n",
      "Step 248 (301458) @ Episode 1235/10000, loss: 0.00200222176499664817\n",
      "Episode Reward: 2.0\n",
      "Step 224 (301682) @ Episode 1236/10000, loss: 0.00083342485595494515\n",
      "Episode Reward: 1.0\n",
      "Step 433 (302115) @ Episode 1237/10000, loss: 0.00113912159577012063\n",
      "Episode Reward: 5.0\n",
      "Step 314 (302429) @ Episode 1238/10000, loss: 0.00097676820587366827\n",
      "Episode Reward: 3.0\n",
      "Step 303 (302732) @ Episode 1239/10000, loss: 0.00710204988718032854\n",
      "Episode Reward: 3.0\n",
      "Step 226 (302958) @ Episode 1240/10000, loss: 0.00092760211555287244\n",
      "Episode Reward: 1.0\n",
      "Step 340 (303298) @ Episode 1241/10000, loss: 0.00035915785701945424\n",
      "Episode Reward: 3.0\n",
      "Step 243 (303541) @ Episode 1242/10000, loss: 0.00092451821547001666\n",
      "Episode Reward: 2.0\n",
      "Step 339 (303880) @ Episode 1243/10000, loss: 0.00064617936732247473\n",
      "Episode Reward: 2.0\n",
      "Step 277 (304157) @ Episode 1244/10000, loss: 0.00072096922667697077\n",
      "Episode Reward: 2.0\n",
      "Step 311 (304468) @ Episode 1245/10000, loss: 0.00269815302453935157\n",
      "Episode Reward: 3.0\n",
      "Step 307 (304775) @ Episode 1246/10000, loss: 0.00249356264248490335\n",
      "Episode Reward: 3.0\n",
      "Step 356 (305131) @ Episode 1247/10000, loss: 0.00023899832740426064\n",
      "Episode Reward: 3.0\n",
      "Step 269 (305400) @ Episode 1248/10000, loss: 0.00151488394476473336\n",
      "Episode Reward: 1.0\n",
      "Step 233 (305633) @ Episode 1249/10000, loss: 0.00270248996093869263\n",
      "Episode Reward: 1.0\n",
      "Step 252 (305885) @ Episode 1250/10000, loss: 0.00122338638175278963\n",
      "Episode Reward: 2.0\n",
      "Step 204 (306089) @ Episode 1251/10000, loss: 0.00032234360696747916\n",
      "Episode Reward: 1.0\n",
      "Step 380 (306469) @ Episode 1252/10000, loss: 0.00018736001220531762\n",
      "Episode Reward: 4.0\n",
      "Step 485 (306954) @ Episode 1253/10000, loss: 0.00084918149514123866\n",
      "Episode Reward: 6.0\n",
      "Step 202 (307156) @ Episode 1254/10000, loss: 0.00088692893041297793\n",
      "Episode Reward: 0.0\n",
      "Step 340 (307496) @ Episode 1255/10000, loss: 0.00029806274687871337\n",
      "Episode Reward: 3.0\n",
      "Step 546 (308042) @ Episode 1256/10000, loss: 0.00047373253619298345\n",
      "Episode Reward: 7.0\n",
      "Step 228 (308270) @ Episode 1257/10000, loss: 0.00238386122509837156\n",
      "Episode Reward: 1.0\n",
      "Step 377 (308647) @ Episode 1258/10000, loss: 0.00114443269558250914\n",
      "Episode Reward: 4.0\n",
      "Step 264 (308911) @ Episode 1259/10000, loss: 0.00127487326972186573\n",
      "Episode Reward: 2.0\n",
      "Step 335 (309246) @ Episode 1260/10000, loss: 0.00106602883897721776\n",
      "Episode Reward: 3.0\n",
      "Step 278 (309524) @ Episode 1261/10000, loss: 0.00036962842568755154\n",
      "Episode Reward: 2.0\n",
      "Step 379 (309903) @ Episode 1262/10000, loss: 0.00058763730339705947\n",
      "Episode Reward: 4.0\n",
      "Step 96 (309999) @ Episode 1263/10000, loss: 0.00350964814424514778\n",
      "Copied model parameters to target network.\n",
      "Step 309 (310212) @ Episode 1263/10000, loss: 0.0014973112847656012\n",
      "Episode Reward: 3.0\n",
      "Step 417 (310629) @ Episode 1264/10000, loss: 0.00294493581168353566\n",
      "Episode Reward: 5.0\n",
      "Step 300 (310929) @ Episode 1265/10000, loss: 0.00049935444258153445\n",
      "Episode Reward: 2.0\n",
      "Step 247 (311176) @ Episode 1266/10000, loss: 0.00053705822210758924\n",
      "Episode Reward: 2.0\n",
      "Step 347 (311523) @ Episode 1267/10000, loss: 0.00360963935963809573\n",
      "Episode Reward: 6.0\n",
      "Step 252 (311775) @ Episode 1268/10000, loss: 0.00148228206671774394\n",
      "Episode Reward: 2.0\n",
      "Step 306 (312081) @ Episode 1269/10000, loss: 0.00233831210061907777\n",
      "Episode Reward: 2.0\n",
      "Step 364 (312445) @ Episode 1270/10000, loss: 0.00533249648287892364\n",
      "Episode Reward: 3.0\n",
      "Step 423 (312868) @ Episode 1271/10000, loss: 0.00117939221672713763\n",
      "Episode Reward: 5.0\n",
      "Step 319 (313187) @ Episode 1272/10000, loss: 0.00051286740927025683\n",
      "Episode Reward: 3.0\n",
      "Step 350 (313537) @ Episode 1273/10000, loss: 0.00088564644102007157\n",
      "Episode Reward: 4.0\n",
      "Step 334 (313871) @ Episode 1274/10000, loss: 0.00360714131966233253\n",
      "Episode Reward: 3.0\n",
      "Step 510 (314381) @ Episode 1275/10000, loss: 0.00260263867676258196\n",
      "Episode Reward: 8.0\n",
      "Step 255 (314636) @ Episode 1276/10000, loss: 0.00053441012278199254\n",
      "Episode Reward: 2.0\n",
      "Step 340 (314976) @ Episode 1277/10000, loss: 0.00019970987341366708\n",
      "Episode Reward: 3.0\n",
      "Step 418 (315394) @ Episode 1278/10000, loss: 0.00024425634182989633\n",
      "Episode Reward: 5.0\n",
      "Step 405 (315799) @ Episode 1279/10000, loss: 0.00356104294769465923\n",
      "Episode Reward: 4.0\n",
      "Step 287 (316086) @ Episode 1280/10000, loss: 0.00027576394495554274\n",
      "Episode Reward: 3.0\n",
      "Step 419 (316505) @ Episode 1281/10000, loss: 0.00080295640509575675\n",
      "Episode Reward: 4.0\n",
      "Step 457 (316962) @ Episode 1282/10000, loss: 0.00189915741793811323\n",
      "Episode Reward: 5.0\n",
      "Step 460 (317422) @ Episode 1283/10000, loss: 0.00071765191387385134\n",
      "Episode Reward: 5.0\n",
      "Step 242 (317664) @ Episode 1284/10000, loss: 0.00049873453099280676\n",
      "Episode Reward: 2.0\n",
      "Step 344 (318008) @ Episode 1285/10000, loss: 0.00029454575269483035\n",
      "Episode Reward: 3.0\n",
      "Step 252 (318260) @ Episode 1286/10000, loss: 0.00275748455896973686\n",
      "Episode Reward: 2.0\n",
      "Step 282 (318542) @ Episode 1287/10000, loss: 0.00126018631272017967\n",
      "Episode Reward: 3.0\n",
      "Step 318 (318860) @ Episode 1288/10000, loss: 0.00102367729414254436\n",
      "Episode Reward: 3.0\n",
      "Step 403 (319263) @ Episode 1289/10000, loss: 0.00039320896030403674\n",
      "Episode Reward: 4.0\n",
      "Step 276 (319539) @ Episode 1290/10000, loss: 0.00242713885381817866\n",
      "Episode Reward: 2.0\n",
      "Step 460 (319999) @ Episode 1291/10000, loss: 0.00100738531909883023\n",
      "Episode Reward: 5.0\n",
      "Step 0 (319999) @ Episode 1292/10000, loss: None\n",
      "Copied model parameters to target network.\n",
      "Step 550 (320549) @ Episode 1292/10000, loss: 0.00252127414569258786\n",
      "Episode Reward: 7.0\n",
      "Step 403 (320952) @ Episode 1293/10000, loss: 0.00120691489428281783\n",
      "Episode Reward: 4.0\n",
      "Step 458 (321410) @ Episode 1294/10000, loss: 0.00551219191402196924\n",
      "Episode Reward: 6.0\n",
      "Step 465 (321875) @ Episode 1295/10000, loss: 0.00086600967915728695\n",
      "Episode Reward: 9.0\n",
      "Step 482 (322357) @ Episode 1296/10000, loss: 0.00065996078774333093\n",
      "Episode Reward: 6.0\n",
      "Step 378 (322735) @ Episode 1297/10000, loss: 0.00313625624403357574\n",
      "Episode Reward: 5.0\n",
      "Step 369 (323104) @ Episode 1298/10000, loss: 0.00177099590655416256\n",
      "Episode Reward: 4.0\n",
      "Step 594 (323698) @ Episode 1299/10000, loss: 0.00168708409182727346\n",
      "Episode Reward: 7.0\n",
      "Step 419 (324117) @ Episode 1300/10000, loss: 0.00099306437186896847\n",
      "Episode Reward: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 475 (324592) @ Episode 1301/10000, loss: 0.00090551387984305626\n",
      "Episode Reward: 5.0\n",
      "Step 391 (324983) @ Episode 1302/10000, loss: 0.00064869190100580456\n",
      "Episode Reward: 4.0\n",
      "Step 314 (325297) @ Episode 1303/10000, loss: 0.00067367323208600284\n",
      "Episode Reward: 3.0\n",
      "Step 303 (325600) @ Episode 1304/10000, loss: 0.00107735698111355334\n",
      "Episode Reward: 3.0\n",
      "Step 580 (326180) @ Episode 1305/10000, loss: 0.00526833534240722663\n",
      "Episode Reward: 7.0\n",
      "Step 275 (326455) @ Episode 1306/10000, loss: 0.00308809848502278336\n",
      "Episode Reward: 2.0\n",
      "Step 377 (326832) @ Episode 1307/10000, loss: 0.00068887032102793465\n",
      "Episode Reward: 4.0\n",
      "Step 497 (327329) @ Episode 1308/10000, loss: 0.00041354945278726523\n",
      "Episode Reward: 6.0\n",
      "Step 303 (327632) @ Episode 1309/10000, loss: 0.00087897590128704916\n",
      "Episode Reward: 2.0\n",
      "Step 502 (328134) @ Episode 1310/10000, loss: 0.00136601109988987454\n",
      "Episode Reward: 7.0\n",
      "Step 496 (328630) @ Episode 1311/10000, loss: 0.00230105547234416365\n",
      "Episode Reward: 6.0\n",
      "Step 265 (328895) @ Episode 1312/10000, loss: 0.00165394227951765065\n",
      "Episode Reward: 2.0\n",
      "Step 338 (329233) @ Episode 1313/10000, loss: 0.00081626756582409145\n",
      "Episode Reward: 3.0\n",
      "Step 341 (329574) @ Episode 1314/10000, loss: 0.00041973349289037287\n",
      "Episode Reward: 3.0\n",
      "Step 271 (329845) @ Episode 1315/10000, loss: 0.00036956180701963603\n",
      "Episode Reward: 2.0\n",
      "Step 154 (329999) @ Episode 1316/10000, loss: 0.00056968349963426594\n",
      "Copied model parameters to target network.\n",
      "Step 275 (330120) @ Episode 1316/10000, loss: 0.0022589017171412706\n",
      "Episode Reward: 2.0\n",
      "Step 594 (330714) @ Episode 1317/10000, loss: 0.00237732706591486934\n",
      "Episode Reward: 8.0\n",
      "Step 460 (331174) @ Episode 1318/10000, loss: 0.00816518813371658316\n",
      "Episode Reward: 5.0\n",
      "Step 409 (331583) @ Episode 1319/10000, loss: 0.00054593198001384747\n",
      "Episode Reward: 5.0\n",
      "Step 274 (331857) @ Episode 1320/10000, loss: 0.00368361477740108975\n",
      "Episode Reward: 2.0\n",
      "Step 418 (332275) @ Episode 1321/10000, loss: 0.00081161613343283536\n",
      "Episode Reward: 5.0\n",
      "Step 344 (332619) @ Episode 1322/10000, loss: 0.00047586136497557163\n",
      "Episode Reward: 4.0\n",
      "Step 337 (332956) @ Episode 1323/10000, loss: 0.00373085215687751773\n",
      "Episode Reward: 3.0\n",
      "Step 552 (333508) @ Episode 1324/10000, loss: 0.00438694795593619355\n",
      "Episode Reward: 7.0\n",
      "Step 630 (334138) @ Episode 1325/10000, loss: 0.00101710308808833366\n",
      "Episode Reward: 9.0\n",
      "Step 622 (334760) @ Episode 1326/10000, loss: 0.00191304064355790624\n",
      "Episode Reward: 7.0\n",
      "Step 403 (335163) @ Episode 1327/10000, loss: 0.00251051317900419246\n",
      "Episode Reward: 4.0\n",
      "Step 358 (335521) @ Episode 1328/10000, loss: 0.00149539276026189334\n",
      "Episode Reward: 3.0\n",
      "Step 578 (336099) @ Episode 1329/10000, loss: 0.00048130028881132697\n",
      "Episode Reward: 8.0\n",
      "Step 429 (336528) @ Episode 1330/10000, loss: 0.00141557783354073767\n",
      "Episode Reward: 5.0\n",
      "Step 426 (336954) @ Episode 1331/10000, loss: 0.00024076629779301584\n",
      "Episode Reward: 6.0\n",
      "Step 437 (337391) @ Episode 1332/10000, loss: 0.00280905561521649366\n",
      "Episode Reward: 5.0\n",
      "Step 499 (337890) @ Episode 1333/10000, loss: 0.00031422788742929697\n",
      "Episode Reward: 6.0\n",
      "Step 613 (338503) @ Episode 1334/10000, loss: 0.00179054366890341044\n",
      "Episode Reward: 11.0\n",
      "Step 648 (339151) @ Episode 1335/10000, loss: 0.00121807830873876855\n",
      "Episode Reward: 12.0\n",
      "Step 497 (339648) @ Episode 1336/10000, loss: 0.0088248346000909855\n",
      "Episode Reward: 6.0\n",
      "Step 310 (339958) @ Episode 1337/10000, loss: 0.0018819458782672882\n",
      "Episode Reward: 3.0\n",
      "Step 41 (339999) @ Episode 1338/10000, loss: 0.0024145443458110094\n",
      "Copied model parameters to target network.\n",
      "Step 458 (340416) @ Episode 1338/10000, loss: 0.0021558667067438364\n",
      "Episode Reward: 7.0\n",
      "Step 488 (340904) @ Episode 1339/10000, loss: 0.0011261909967288375\n",
      "Episode Reward: 6.0\n",
      "Step 611 (341515) @ Episode 1340/10000, loss: 0.0015819470863789326\n",
      "Episode Reward: 8.0\n",
      "Step 289 (341804) @ Episode 1341/10000, loss: 0.0008957668324001133\n",
      "Episode Reward: 2.0\n",
      "Step 595 (342399) @ Episode 1342/10000, loss: 0.0010053189471364021\n",
      "Episode Reward: 8.0\n",
      "Step 470 (342869) @ Episode 1343/10000, loss: 0.0024789173621684313\n",
      "Episode Reward: 5.0\n",
      "Step 375 (343244) @ Episode 1344/10000, loss: 0.0012891265796497464\n",
      "Episode Reward: 4.0\n",
      "Step 475 (343719) @ Episode 1345/10000, loss: 0.00156275590416044177\n",
      "Episode Reward: 5.0\n",
      "Step 428 (344147) @ Episode 1346/10000, loss: 0.00328842853195965354\n",
      "Episode Reward: 5.0\n",
      "Step 444 (344591) @ Episode 1347/10000, loss: 0.00180599780287593667\n",
      "Episode Reward: 6.0\n",
      "Step 507 (345098) @ Episode 1348/10000, loss: 0.0018641327042132616\n",
      "Episode Reward: 7.0\n",
      "Step 474 (345572) @ Episode 1349/10000, loss: 0.00151179067324846985\n",
      "Episode Reward: 5.0\n",
      "Step 463 (346035) @ Episode 1350/10000, loss: 0.00553924590349197444\n",
      "Episode Reward: 5.0\n",
      "Step 262 (346297) @ Episode 1351/10000, loss: 0.00089498294983059174\n",
      "Episode Reward: 2.0\n",
      "Step 675 (346972) @ Episode 1352/10000, loss: 0.00222775293514132597\n",
      "Episode Reward: 12.0\n",
      "Step 482 (347454) @ Episode 1353/10000, loss: 0.0018774796044453979\n",
      "Episode Reward: 6.0\n",
      "Step 505 (347959) @ Episode 1354/10000, loss: 0.00085872208001092084\n",
      "Episode Reward: 6.0\n",
      "Step 522 (348481) @ Episode 1355/10000, loss: 0.00169262138660997153\n",
      "Episode Reward: 8.0\n",
      "Step 534 (349015) @ Episode 1356/10000, loss: 0.00290349498391151436\n",
      "Episode Reward: 7.0\n",
      "Step 278 (349293) @ Episode 1357/10000, loss: 0.0010443178471177816\n",
      "Episode Reward: 2.0\n",
      "Step 376 (349669) @ Episode 1358/10000, loss: 0.00086955941515043386\n",
      "Episode Reward: 4.0\n",
      "Step 330 (349999) @ Episode 1359/10000, loss: 0.0036893002688884735\n",
      "Copied model parameters to target network.\n",
      "Step 735 (350404) @ Episode 1359/10000, loss: 0.0016701873391866684\n",
      "Episode Reward: 11.0\n",
      "Step 385 (350789) @ Episode 1360/10000, loss: 0.0018557684961706444\n",
      "Episode Reward: 4.0\n",
      "Step 571 (351360) @ Episode 1361/10000, loss: 0.0009743571281433105\n",
      "Episode Reward: 7.0\n",
      "Step 326 (351686) @ Episode 1362/10000, loss: 0.0078503163531422623\n",
      "Episode Reward: 4.0\n",
      "Step 392 (352078) @ Episode 1363/10000, loss: 0.0017046586144715548\n",
      "Episode Reward: 4.0\n",
      "Step 619 (352697) @ Episode 1364/10000, loss: 0.00378736737184226533\n",
      "Episode Reward: 8.0\n",
      "Step 463 (353160) @ Episode 1365/10000, loss: 0.0029822338838130236\n",
      "Episode Reward: 7.0\n",
      "Step 730 (353890) @ Episode 1366/10000, loss: 0.00138387712650001054\n",
      "Episode Reward: 17.0\n",
      "Step 518 (354408) @ Episode 1367/10000, loss: 0.0093353372067213064\n",
      "Episode Reward: 7.0\n",
      "Step 262 (354670) @ Episode 1368/10000, loss: 0.0038822635542601347\n",
      "Episode Reward: 2.0\n",
      "Step 397 (355067) @ Episode 1369/10000, loss: 0.0023410054855048656\n",
      "Episode Reward: 4.0\n",
      "Step 517 (355584) @ Episode 1370/10000, loss: 0.0033024866133928312\n",
      "Episode Reward: 7.0\n",
      "Step 470 (356054) @ Episode 1371/10000, loss: 0.00161031482275575436\n",
      "Episode Reward: 6.0\n",
      "Step 546 (356600) @ Episode 1372/10000, loss: 0.00694113317877054266\n",
      "Episode Reward: 8.0\n",
      "Step 546 (357146) @ Episode 1373/10000, loss: 0.00528863351792097197\n",
      "Episode Reward: 7.0\n",
      "Step 735 (357881) @ Episode 1374/10000, loss: 0.00683912914246320767\n",
      "Episode Reward: 11.0\n",
      "Step 479 (358360) @ Episode 1375/10000, loss: 0.00354535272344946863\n",
      "Episode Reward: 6.0\n",
      "Step 341 (358701) @ Episode 1376/10000, loss: 0.0059618279337882996\n",
      "Episode Reward: 4.0\n",
      "Step 483 (359184) @ Episode 1377/10000, loss: 0.00059199897805228837\n",
      "Episode Reward: 5.0\n",
      "Step 548 (359732) @ Episode 1378/10000, loss: 0.00126409681979566814\n",
      "Episode Reward: 10.0\n",
      "Step 267 (359999) @ Episode 1379/10000, loss: 0.0039546163752675069\n",
      "Copied model parameters to target network.\n",
      "Step 540 (360272) @ Episode 1379/10000, loss: 0.0059062885120511055\n",
      "Episode Reward: 11.0\n",
      "Step 559 (360831) @ Episode 1380/10000, loss: 0.0043689003214240076\n",
      "Episode Reward: 5.0\n",
      "Step 661 (361492) @ Episode 1381/10000, loss: 0.0029364838264882565\n",
      "Episode Reward: 10.0\n",
      "Step 553 (362045) @ Episode 1382/10000, loss: 0.0044148205779492855\n",
      "Episode Reward: 7.0\n",
      "Step 577 (362622) @ Episode 1383/10000, loss: 0.0011697995942085981\n",
      "Episode Reward: 6.0\n",
      "Step 586 (363208) @ Episode 1384/10000, loss: 0.0026422005612403154\n",
      "Episode Reward: 8.0\n",
      "Step 582 (363790) @ Episode 1385/10000, loss: 0.01362131256610155113\n",
      "Episode Reward: 9.0\n",
      "Step 594 (364384) @ Episode 1386/10000, loss: 0.0008716685697436333\n",
      "Episode Reward: 10.0\n",
      "Step 541 (364925) @ Episode 1387/10000, loss: 0.0030550833325833082\n",
      "Episode Reward: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 306 (365231) @ Episode 1388/10000, loss: 0.00323250098153948857\n",
      "Episode Reward: 3.0\n",
      "Step 511 (365742) @ Episode 1389/10000, loss: 0.0022584435064345696\n",
      "Episode Reward: 7.0\n",
      "Step 726 (366468) @ Episode 1390/10000, loss: 0.0035633940715342768\n",
      "Episode Reward: 10.0\n",
      "Step 537 (367005) @ Episode 1391/10000, loss: 0.0026709181256592274\n",
      "Episode Reward: 6.0\n",
      "Step 610 (367615) @ Episode 1392/10000, loss: 0.00124939379747957684\n",
      "Episode Reward: 8.0\n",
      "Step 509 (368124) @ Episode 1393/10000, loss: 0.00174686161335557774\n",
      "Episode Reward: 6.0\n",
      "Step 667 (368791) @ Episode 1394/10000, loss: 0.00200132350437343137\n",
      "Episode Reward: 9.0\n",
      "Step 726 (369517) @ Episode 1395/10000, loss: 0.00197001942433416845\n",
      "Episode Reward: 11.0\n",
      "Step 482 (369999) @ Episode 1396/10000, loss: 0.00127373181749135265\n",
      "Copied model parameters to target network.\n",
      "Step 602 (370119) @ Episode 1396/10000, loss: 0.0015335060888901353\n",
      "Episode Reward: 9.0\n",
      "Step 308 (370427) @ Episode 1397/10000, loss: 0.0017026355490088463\n",
      "Episode Reward: 2.0\n",
      "Step 575 (371002) @ Episode 1398/10000, loss: 0.0012579277390614152\n",
      "Episode Reward: 10.0\n",
      "Step 703 (371705) @ Episode 1399/10000, loss: 0.0010561074595898395\n",
      "Episode Reward: 13.0\n",
      "Step 765 (372470) @ Episode 1400/10000, loss: 0.00203873147256672456\n",
      "Episode Reward: 12.0\n",
      "Step 517 (372987) @ Episode 1401/10000, loss: 0.0119901522994041443\n",
      "Episode Reward: 7.0\n",
      "Step 572 (373559) @ Episode 1402/10000, loss: 0.0105907041579484946\n",
      "Episode Reward: 8.0\n",
      "Step 721 (374280) @ Episode 1403/10000, loss: 0.0043861828744411477\n",
      "Episode Reward: 11.0\n",
      "Step 941 (375221) @ Episode 1404/10000, loss: 0.00107988691888749635\n",
      "Episode Reward: 20.0\n",
      "Step 619 (375840) @ Episode 1405/10000, loss: 0.0034058534074574712\n",
      "Episode Reward: 12.0\n",
      "Step 548 (376388) @ Episode 1406/10000, loss: 0.0016525998944416642\n",
      "Episode Reward: 7.0\n",
      "Step 737 (377125) @ Episode 1407/10000, loss: 0.0015722233802080154\n",
      "Episode Reward: 11.0\n",
      "Step 697 (377822) @ Episode 1408/10000, loss: 0.00559515273198485487\n",
      "Episode Reward: 10.0\n",
      "Step 889 (378711) @ Episode 1409/10000, loss: 0.00404723919928073954\n",
      "Episode Reward: 16.0\n",
      "Step 582 (379293) @ Episode 1410/10000, loss: 0.0021881647408008575\n",
      "Episode Reward: 8.0\n",
      "Step 706 (379999) @ Episode 1411/10000, loss: 0.00173214147798717023\n",
      "Copied model parameters to target network.\n",
      "Step 775 (380068) @ Episode 1411/10000, loss: 0.0135005880147218783\n",
      "Episode Reward: 13.0\n",
      "Step 713 (380781) @ Episode 1412/10000, loss: 0.0017503525596112013\n",
      "Episode Reward: 11.0\n",
      "Step 614 (381395) @ Episode 1413/10000, loss: 0.0010478978510946035\n",
      "Episode Reward: 10.0\n",
      "Step 748 (382143) @ Episode 1414/10000, loss: 0.0024940900038927794\n",
      "Episode Reward: 11.0\n",
      "Step 751 (382894) @ Episode 1415/10000, loss: 0.0021003503352403644\n",
      "Episode Reward: 12.0\n",
      "Step 594 (383488) @ Episode 1416/10000, loss: 0.0032168687321245677\n",
      "Episode Reward: 8.0\n",
      "Step 625 (384113) @ Episode 1417/10000, loss: 0.00267861178144812663\n",
      "Episode Reward: 9.0\n",
      "Step 608 (384721) @ Episode 1418/10000, loss: 0.0087727969512343486\n",
      "Episode Reward: 12.0\n",
      "Step 709 (385430) @ Episode 1419/10000, loss: 0.0078949797898530964\n",
      "Episode Reward: 11.0\n",
      "Step 713 (386143) @ Episode 1420/10000, loss: 0.0015141149051487446\n",
      "Episode Reward: 11.0\n",
      "Step 486 (386629) @ Episode 1421/10000, loss: 0.0009443359449505806\n",
      "Episode Reward: 7.0\n",
      "Step 496 (387125) @ Episode 1422/10000, loss: 0.0022054323926568035\n",
      "Episode Reward: 6.0\n",
      "Step 672 (387797) @ Episode 1423/10000, loss: 0.00085165275959298017\n",
      "Episode Reward: 9.0\n",
      "Step 896 (388693) @ Episode 1424/10000, loss: 0.00141567306127399284\n",
      "Episode Reward: 16.0\n",
      "Step 428 (389121) @ Episode 1425/10000, loss: 0.0023031120654195547\n",
      "Episode Reward: 5.0\n",
      "Step 644 (389765) @ Episode 1426/10000, loss: 0.00228772312402725253\n",
      "Episode Reward: 10.0\n",
      "Step 234 (389999) @ Episode 1427/10000, loss: 0.0044935643672943115\n",
      "Copied model parameters to target network.\n",
      "Step 498 (390263) @ Episode 1427/10000, loss: 0.0158003456890583045\n",
      "Episode Reward: 6.0\n",
      "Step 744 (391007) @ Episode 1428/10000, loss: 0.0012798481620848179\n",
      "Episode Reward: 15.0\n",
      "Step 608 (391615) @ Episode 1429/10000, loss: 0.0043207248672842987\n",
      "Episode Reward: 9.0\n",
      "Step 875 (392490) @ Episode 1430/10000, loss: 0.0032507155556231737\n",
      "Episode Reward: 14.0\n",
      "Step 573 (393063) @ Episode 1431/10000, loss: 0.00104204518720507623\n",
      "Episode Reward: 8.0\n",
      "Step 615 (393678) @ Episode 1432/10000, loss: 0.0091440062969923024\n",
      "Episode Reward: 10.0\n",
      "Step 864 (394542) @ Episode 1433/10000, loss: 0.0034332990180701017\n",
      "Episode Reward: 15.0\n",
      "Step 691 (395233) @ Episode 1434/10000, loss: 0.00170485954731702877\n",
      "Episode Reward: 12.0\n",
      "Step 449 (395682) @ Episode 1435/10000, loss: 0.00186143140308558946\n",
      "Episode Reward: 6.0\n",
      "Step 580 (396262) @ Episode 1436/10000, loss: 0.0031144428066909313\n",
      "Episode Reward: 12.0\n",
      "Step 902 (397164) @ Episode 1437/10000, loss: 0.00164900464005768383\n",
      "Episode Reward: 15.0\n",
      "Step 768 (397932) @ Episode 1438/10000, loss: 0.00465221889317035723\n",
      "Episode Reward: 12.0\n",
      "Step 731 (398663) @ Episode 1439/10000, loss: 0.00635851826518774873\n",
      "Episode Reward: 13.0\n",
      "Step 656 (399319) @ Episode 1440/10000, loss: 0.00299146329052746377\n",
      "Episode Reward: 14.0\n",
      "Step 680 (399999) @ Episode 1441/10000, loss: 0.00212832004763185983\n",
      "Copied model parameters to target network.\n",
      "Step 757 (400076) @ Episode 1441/10000, loss: 0.0034170586150139578\n",
      "Episode Reward: 12.0\n",
      "Step 804 (400880) @ Episode 1442/10000, loss: 0.0044825226068496767\n",
      "Episode Reward: 13.0\n",
      "Step 724 (401604) @ Episode 1443/10000, loss: 0.0017225879710167646\n",
      "Episode Reward: 14.0\n",
      "Step 725 (402329) @ Episode 1444/10000, loss: 0.0020453825127333403\n",
      "Episode Reward: 11.0\n",
      "Step 759 (403088) @ Episode 1445/10000, loss: 0.00209435541182756425\n",
      "Episode Reward: 12.0\n",
      "Step 730 (403818) @ Episode 1446/10000, loss: 0.00182776176370680337\n",
      "Episode Reward: 13.0\n",
      "Step 1041 (404859) @ Episode 1447/10000, loss: 0.0016554761677980423\n",
      "Episode Reward: 16.0\n",
      "Step 742 (405601) @ Episode 1448/10000, loss: 0.00672523444518446953\n",
      "Episode Reward: 10.0\n",
      "Step 552 (406153) @ Episode 1449/10000, loss: 0.00138092879205942153\n",
      "Episode Reward: 8.0\n",
      "Step 540 (406693) @ Episode 1450/10000, loss: 0.00436166953295469364\n",
      "Episode Reward: 8.0\n",
      "Step 613 (407306) @ Episode 1451/10000, loss: 0.00162950973026454454\n",
      "Episode Reward: 9.0\n",
      "Step 759 (408065) @ Episode 1452/10000, loss: 0.00146513059735298167\n",
      "Episode Reward: 12.0\n",
      "Step 898 (408963) @ Episode 1453/10000, loss: 0.00417467579245567376\n",
      "Episode Reward: 12.0\n",
      "Step 914 (409877) @ Episode 1454/10000, loss: 0.00114594376645982275\n",
      "Episode Reward: 14.0\n",
      "Step 122 (409999) @ Episode 1455/10000, loss: 0.0049443459138274195\n",
      "Copied model parameters to target network.\n",
      "Step 450 (410327) @ Episode 1455/10000, loss: 0.0100614083930850033\n",
      "Episode Reward: 5.0\n",
      "Step 782 (411109) @ Episode 1456/10000, loss: 0.0022407018113881352\n",
      "Episode Reward: 14.0\n",
      "Step 723 (411832) @ Episode 1457/10000, loss: 0.0013005400542169813\n",
      "Episode Reward: 13.0\n",
      "Step 1133 (412965) @ Episode 1458/10000, loss: 0.0009621061617508531\n",
      "Episode Reward: 20.0\n",
      "Step 989 (413954) @ Episode 1459/10000, loss: 0.0023912477772682905\n",
      "Episode Reward: 15.0\n",
      "Step 867 (414821) @ Episode 1460/10000, loss: 0.0008483145502395928\n",
      "Episode Reward: 17.0\n",
      "Step 803 (415624) @ Episode 1461/10000, loss: 0.0009380658157169819\n",
      "Episode Reward: 13.0\n",
      "Step 887 (416511) @ Episode 1462/10000, loss: 0.00440221279859542857\n",
      "Episode Reward: 21.0\n",
      "Step 768 (417279) @ Episode 1463/10000, loss: 0.0016036238521337513\n",
      "Episode Reward: 13.0\n",
      "Step 493 (417772) @ Episode 1464/10000, loss: 0.0028546361718326807\n",
      "Episode Reward: 7.0\n",
      "Step 595 (418367) @ Episode 1465/10000, loss: 0.0053848112002015115\n",
      "Episode Reward: 9.0\n",
      "Step 697 (419064) @ Episode 1466/10000, loss: 0.0028729527257382871\n",
      "Episode Reward: 17.0\n",
      "Step 531 (419595) @ Episode 1467/10000, loss: 0.0049327700398862363\n",
      "Episode Reward: 11.0\n",
      "Step 404 (419999) @ Episode 1468/10000, loss: 0.0013779724249616265\n",
      "Copied model parameters to target network.\n",
      "Step 720 (420315) @ Episode 1468/10000, loss: 0.0077827423810958865\n",
      "Episode Reward: 11.0\n",
      "Step 904 (421219) @ Episode 1469/10000, loss: 0.0012212486471980812\n",
      "Episode Reward: 17.0\n",
      "Step 736 (421955) @ Episode 1470/10000, loss: 0.00073332432657480246\n",
      "Episode Reward: 12.0\n",
      "Step 833 (422788) @ Episode 1471/10000, loss: 0.00202546152286231584\n",
      "Episode Reward: 13.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 883 (423671) @ Episode 1472/10000, loss: 0.00262613152153796183\n",
      "Episode Reward: 12.0\n",
      "Step 812 (424483) @ Episode 1473/10000, loss: 0.0019272062927484512\n",
      "Episode Reward: 17.0\n",
      "Step 579 (425062) @ Episode 1474/10000, loss: 0.0075043663382530214\n",
      "Episode Reward: 8.0\n",
      "Step 897 (425959) @ Episode 1475/10000, loss: 0.0045777084305882458\n",
      "Episode Reward: 21.0\n",
      "Step 814 (426773) @ Episode 1476/10000, loss: 0.0010407343506813057\n",
      "Episode Reward: 12.0\n",
      "Step 507 (427280) @ Episode 1477/10000, loss: 0.0043350756168365486\n",
      "Episode Reward: 7.0\n",
      "Step 777 (428057) @ Episode 1478/10000, loss: 0.0027387961745262146\n",
      "Episode Reward: 12.0\n",
      "Step 528 (428585) @ Episode 1479/10000, loss: 0.0120038967579603286\n",
      "Episode Reward: 7.0\n",
      "Step 643 (429228) @ Episode 1480/10000, loss: 0.0011659680167213082\n",
      "Episode Reward: 8.0\n",
      "Step 739 (429967) @ Episode 1481/10000, loss: 0.0045879492536187176\n",
      "Episode Reward: 11.0\n",
      "Step 32 (429999) @ Episode 1482/10000, loss: 0.0032879735808819532\n",
      "Copied model parameters to target network.\n",
      "Step 737 (430704) @ Episode 1482/10000, loss: 0.0018134347628802063\n",
      "Episode Reward: 11.0\n",
      "Step 387 (431091) @ Episode 1483/10000, loss: 0.0096041029319167145\n",
      "Episode Reward: 5.0\n",
      "Step 583 (431674) @ Episode 1484/10000, loss: 0.0046256380155682567\n",
      "Episode Reward: 8.0\n",
      "Step 517 (432191) @ Episode 1485/10000, loss: 0.0062379972077906134\n",
      "Episode Reward: 6.0\n",
      "Step 681 (432872) @ Episode 1486/10000, loss: 0.0050721848383545876\n",
      "Episode Reward: 10.0\n",
      "Step 736 (433608) @ Episode 1487/10000, loss: 0.0051850802265107633\n",
      "Episode Reward: 12.0\n",
      "Step 614 (434222) @ Episode 1488/10000, loss: 0.0015672284644097096\n",
      "Episode Reward: 9.0\n",
      "Step 730 (434952) @ Episode 1489/10000, loss: 0.0032197404652833946\n",
      "Episode Reward: 13.0\n",
      "Step 883 (435835) @ Episode 1490/10000, loss: 0.00126931257545948036\n",
      "Episode Reward: 15.0\n",
      "Step 736 (436571) @ Episode 1491/10000, loss: 0.0049519171006977565\n",
      "Episode Reward: 17.0\n",
      "Step 646 (437217) @ Episode 1492/10000, loss: 0.00086898263543844226\n",
      "Episode Reward: 24.0\n",
      "Step 423 (437640) @ Episode 1493/10000, loss: 0.0113371992483735085\n",
      "Episode Reward: 5.0\n",
      "Step 794 (438434) @ Episode 1494/10000, loss: 0.0093837780877947877\n",
      "Episode Reward: 14.0\n",
      "Step 633 (439067) @ Episode 1495/10000, loss: 0.0021396125666797165\n",
      "Episode Reward: 10.0\n",
      "Step 727 (439794) @ Episode 1496/10000, loss: 0.0024985305499285465\n",
      "Episode Reward: 10.0\n",
      "Step 205 (439999) @ Episode 1497/10000, loss: 0.0032626432366669187\n",
      "Copied model parameters to target network.\n",
      "Step 833 (440627) @ Episode 1497/10000, loss: 0.0030704657547175884\n",
      "Episode Reward: 13.0\n",
      "Step 909 (441536) @ Episode 1498/10000, loss: 0.0051945475861430177\n",
      "Episode Reward: 12.0\n",
      "Step 803 (442339) @ Episode 1499/10000, loss: 0.0033627438824623823\n",
      "Episode Reward: 29.0\n",
      "Step 540 (442879) @ Episode 1500/10000, loss: 0.0049668126739561566\n",
      "Episode Reward: 8.0\n",
      "Step 1041 (443920) @ Episode 1501/10000, loss: 0.0083509739488363277\n",
      "Episode Reward: 27.0\n",
      "Step 993 (444913) @ Episode 1502/10000, loss: 0.0034813366364687688\n",
      "Episode Reward: 28.0\n",
      "Step 749 (445662) @ Episode 1503/10000, loss: 0.0014774159062653787\n",
      "Episode Reward: 11.0\n",
      "Step 987 (446649) @ Episode 1504/10000, loss: 0.0024933409877121453\n",
      "Episode Reward: 22.0\n",
      "Step 696 (447345) @ Episode 1505/10000, loss: 0.0021899100393056876\n",
      "Episode Reward: 12.0\n",
      "Step 762 (448107) @ Episode 1506/10000, loss: 0.00175737368408590566\n",
      "Episode Reward: 16.0\n",
      "Step 902 (449009) @ Episode 1507/10000, loss: 0.0116606904193758964\n",
      "Episode Reward: 20.0\n",
      "Step 694 (449703) @ Episode 1508/10000, loss: 0.0097730923444032673\n",
      "Episode Reward: 10.0\n",
      "Step 296 (449999) @ Episode 1509/10000, loss: 0.0015949702356010675\n",
      "Copied model parameters to target network.\n",
      "Step 808 (450511) @ Episode 1509/10000, loss: 0.0048523675650358255\n",
      "Episode Reward: 16.0\n",
      "Step 662 (451173) @ Episode 1510/10000, loss: 0.0050012432038784034\n",
      "Episode Reward: 11.0\n",
      "Step 918 (452091) @ Episode 1511/10000, loss: 0.0095484424382448216\n",
      "Episode Reward: 14.0\n",
      "Step 1131 (453222) @ Episode 1512/10000, loss: 0.0101172188296914192\n",
      "Episode Reward: 20.0\n",
      "Step 704 (453926) @ Episode 1513/10000, loss: 0.0036345303524285555\n",
      "Episode Reward: 10.0\n",
      "Step 711 (454637) @ Episode 1514/10000, loss: 0.0187300555408000955\n",
      "Episode Reward: 10.0\n",
      "Step 877 (455514) @ Episode 1515/10000, loss: 0.0023384089581668377\n",
      "Episode Reward: 15.0\n",
      "Step 889 (456403) @ Episode 1516/10000, loss: 0.0081570465117692955\n",
      "Episode Reward: 18.0\n",
      "Step 717 (457120) @ Episode 1517/10000, loss: 0.00199319492094218736\n",
      "Episode Reward: 11.0\n",
      "Step 878 (457998) @ Episode 1518/10000, loss: 0.0018183707725256681\n",
      "Episode Reward: 14.0\n",
      "Step 1031 (459029) @ Episode 1519/10000, loss: 0.0027066273614764214\n",
      "Episode Reward: 21.0\n",
      "Step 902 (459931) @ Episode 1520/10000, loss: 0.0016823314363136888\n",
      "Episode Reward: 18.0\n",
      "Step 68 (459999) @ Episode 1521/10000, loss: 0.0010450333356857303\n",
      "Copied model parameters to target network.\n",
      "Step 577 (460508) @ Episode 1521/10000, loss: 0.0093029532581567765\n",
      "Episode Reward: 8.0\n",
      "Step 773 (461281) @ Episode 1522/10000, loss: 0.0665311068296432536\n",
      "Episode Reward: 12.0\n",
      "Step 934 (462215) @ Episode 1523/10000, loss: 0.0016996220219880342\n",
      "Episode Reward: 22.0\n",
      "Step 993 (463208) @ Episode 1524/10000, loss: 0.0030619781464338303\n",
      "Episode Reward: 24.0\n",
      "Step 1010 (464218) @ Episode 1525/10000, loss: 0.0054001016542315485\n",
      "Episode Reward: 17.0\n",
      "Step 476 (464694) @ Episode 1526/10000, loss: 0.0034718818496912718\n",
      "Episode Reward: 7.0\n",
      "Step 911 (465605) @ Episode 1527/10000, loss: 0.0021427422761917114\n",
      "Episode Reward: 13.0\n",
      "Step 926 (466531) @ Episode 1528/10000, loss: 0.0030740152578800917\n",
      "Episode Reward: 19.0\n",
      "Step 856 (467387) @ Episode 1529/10000, loss: 0.0037481486797332764\n",
      "Episode Reward: 14.0\n",
      "Step 676 (468063) @ Episode 1530/10000, loss: 0.0017873831093311316\n",
      "Episode Reward: 11.0\n",
      "Step 553 (468616) @ Episode 1531/10000, loss: 0.0017328591784462333\n",
      "Episode Reward: 9.0\n",
      "Step 813 (469429) @ Episode 1532/10000, loss: 0.0050250999629497531\n",
      "Episode Reward: 16.0\n",
      "Step 570 (469999) @ Episode 1533/10000, loss: 0.0016603994881734252\n",
      "Copied model parameters to target network.\n",
      "Step 686 (470115) @ Episode 1533/10000, loss: 0.0043094605207443248\n",
      "Episode Reward: 11.0\n",
      "Step 979 (471094) @ Episode 1534/10000, loss: 0.0044655911624431616\n",
      "Episode Reward: 26.0\n",
      "Step 882 (471976) @ Episode 1535/10000, loss: 0.0098922653123736383\n",
      "Episode Reward: 16.0\n",
      "Step 885 (472861) @ Episode 1536/10000, loss: 0.0172782652080059053\n",
      "Episode Reward: 17.0\n",
      "Step 879 (473740) @ Episode 1537/10000, loss: 0.0029761374462395906\n",
      "Episode Reward: 22.0\n",
      "Step 763 (474503) @ Episode 1538/10000, loss: 0.0027545136399567127\n",
      "Episode Reward: 13.0\n",
      "Step 909 (475412) @ Episode 1539/10000, loss: 0.0022492031566798687\n",
      "Episode Reward: 15.0\n",
      "Step 523 (475935) @ Episode 1540/10000, loss: 0.0097215129062533385\n",
      "Episode Reward: 8.0\n",
      "Step 882 (476817) @ Episode 1541/10000, loss: 0.0054733641445636756\n",
      "Episode Reward: 14.0\n",
      "Step 865 (477682) @ Episode 1542/10000, loss: 0.0016214922070503235\n",
      "Episode Reward: 14.0\n",
      "Step 898 (478580) @ Episode 1543/10000, loss: 0.0042776465415954593\n",
      "Episode Reward: 14.0\n",
      "Step 841 (479421) @ Episode 1544/10000, loss: 0.0101555055007338525\n",
      "Episode Reward: 15.0\n",
      "Step 578 (479999) @ Episode 1545/10000, loss: 0.0083663081750273719\n",
      "Copied model parameters to target network.\n",
      "Step 1019 (480440) @ Episode 1545/10000, loss: 0.0028706551529467106\n",
      "Episode Reward: 22.0\n",
      "Step 1181 (481621) @ Episode 1546/10000, loss: 0.0029711173847317696\n",
      "Episode Reward: 24.0\n",
      "Step 1086 (482707) @ Episode 1547/10000, loss: 0.0010930926073342562\n",
      "Episode Reward: 18.0\n",
      "Step 865 (483572) @ Episode 1548/10000, loss: 0.0020792842842638493\n",
      "Episode Reward: 14.0\n",
      "Step 839 (484411) @ Episode 1549/10000, loss: 0.0066307568922638892\n",
      "Episode Reward: 18.0\n",
      "Step 1044 (485455) @ Episode 1550/10000, loss: 0.0045520565472543244\n",
      "Episode Reward: 24.0\n",
      "Step 911 (486366) @ Episode 1551/10000, loss: 0.0043715983629226685\n",
      "Episode Reward: 16.0\n",
      "Step 1222 (487588) @ Episode 1552/10000, loss: 0.0009295743075199425\n",
      "Episode Reward: 30.0\n",
      "Step 1066 (488654) @ Episode 1553/10000, loss: 0.0020737200975418094\n",
      "Episode Reward: 27.0\n",
      "Step 906 (489560) @ Episode 1554/10000, loss: 0.0029005040414631367\n",
      "Episode Reward: 18.0\n",
      "Step 439 (489999) @ Episode 1555/10000, loss: 0.0032346784137189398\n",
      "Copied model parameters to target network.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 647 (490207) @ Episode 1555/10000, loss: 0.0028777986299246555\n",
      "Episode Reward: 10.0\n",
      "Step 746 (490953) @ Episode 1556/10000, loss: 0.0036941457074135545\n",
      "Episode Reward: 16.0\n",
      "Step 1013 (491966) @ Episode 1557/10000, loss: 0.0027548423968255523\n",
      "Episode Reward: 20.0\n",
      "Step 919 (492885) @ Episode 1558/10000, loss: 0.0043772547505795956\n",
      "Episode Reward: 14.0\n",
      "Step 939 (493824) @ Episode 1559/10000, loss: 0.0076415701769292355\n",
      "Episode Reward: 18.0\n",
      "Step 620 (494444) @ Episode 1560/10000, loss: 0.0024427422322332867\n",
      "Episode Reward: 9.0\n",
      "Step 1126 (495570) @ Episode 1561/10000, loss: 0.0042068050242960458\n",
      "Episode Reward: 21.0\n",
      "Step 884 (496454) @ Episode 1562/10000, loss: 0.0015472879167646175\n",
      "Episode Reward: 15.0\n",
      "Step 903 (497357) @ Episode 1563/10000, loss: 0.0020713850390166044\n",
      "Episode Reward: 16.0\n",
      "Step 1044 (498401) @ Episode 1564/10000, loss: 0.0068885302171111116\n",
      "Episode Reward: 20.0\n",
      "Step 1217 (499618) @ Episode 1565/10000, loss: 0.0128737986087799074\n",
      "Episode Reward: 34.0\n",
      "Step 381 (499999) @ Episode 1566/10000, loss: 0.0058241337537765567\n",
      "Copied model parameters to target network.\n",
      "Step 983 (500601) @ Episode 1566/10000, loss: 0.0268946327269077363\n",
      "Episode Reward: 16.0\n",
      "Step 634 (501235) @ Episode 1567/10000, loss: 0.0022837021388113558\n",
      "Episode Reward: 13.0\n",
      "Step 856 (502091) @ Episode 1568/10000, loss: 0.0189967900514602667\n",
      "Episode Reward: 14.0\n",
      "Step 1057 (503148) @ Episode 1569/10000, loss: 0.0031794756650924683\n",
      "Episode Reward: 20.0\n",
      "Step 922 (504070) @ Episode 1570/10000, loss: 0.0079406332224607474\n",
      "Episode Reward: 22.0\n",
      "Step 860 (504930) @ Episode 1571/10000, loss: 0.0076953256502747542\n",
      "Episode Reward: 19.0\n",
      "Step 833 (505763) @ Episode 1572/10000, loss: 0.0098208859562873846\n",
      "Episode Reward: 15.0\n",
      "Step 1201 (506964) @ Episode 1573/10000, loss: 0.00363874551840126583\n",
      "Episode Reward: 29.0\n",
      "Step 877 (507841) @ Episode 1574/10000, loss: 0.00307383434846997265\n",
      "Episode Reward: 19.0\n",
      "Step 949 (508790) @ Episode 1575/10000, loss: 0.0118690887466073045\n",
      "Episode Reward: 17.0\n",
      "Step 1035 (509825) @ Episode 1576/10000, loss: 0.0015298068756237626\n",
      "Episode Reward: 18.0\n",
      "Step 174 (509999) @ Episode 1577/10000, loss: 0.0019357908749952912\n",
      "Copied model parameters to target network.\n",
      "Step 480 (510305) @ Episode 1577/10000, loss: 0.0030661257915198803\n",
      "Episode Reward: 11.0\n",
      "Step 1360 (511665) @ Episode 1578/10000, loss: 0.0067992685362696652\n",
      "Episode Reward: 37.0\n",
      "Step 1193 (512858) @ Episode 1579/10000, loss: 0.0043270615860819823\n",
      "Episode Reward: 30.0\n",
      "Step 832 (513690) @ Episode 1580/10000, loss: 0.0020394744351506233\n",
      "Episode Reward: 13.0\n",
      "Step 840 (514530) @ Episode 1581/10000, loss: 0.0111118461936712277\n",
      "Episode Reward: 15.0\n",
      "Step 1572 (516102) @ Episode 1582/10000, loss: 0.0067585795186460023\n",
      "Episode Reward: 47.0\n",
      "Step 717 (516819) @ Episode 1583/10000, loss: 0.0110758394002914435\n",
      "Episode Reward: 12.0\n",
      "Step 1032 (517851) @ Episode 1584/10000, loss: 0.0017953247297555208\n",
      "Episode Reward: 18.0\n",
      "Step 798 (518649) @ Episode 1585/10000, loss: 0.0024594224523752928\n",
      "Episode Reward: 14.0\n",
      "Step 1183 (519832) @ Episode 1586/10000, loss: 0.0061244675889611246\n",
      "Episode Reward: 32.0\n",
      "Step 167 (519999) @ Episode 1587/10000, loss: 0.0033009878825396326\n",
      "Copied model parameters to target network.\n",
      "Step 808 (520640) @ Episode 1587/10000, loss: 0.0118108000606298455\n",
      "Episode Reward: 13.0\n",
      "Step 831 (521471) @ Episode 1588/10000, loss: 0.0186257530003786135\n",
      "Episode Reward: 14.0\n",
      "Step 1318 (522789) @ Episode 1589/10000, loss: 0.0017301749903708696\n",
      "Episode Reward: 40.0\n",
      "Step 1541 (524330) @ Episode 1590/10000, loss: 0.0053755929693579675\n",
      "Episode Reward: 42.0\n",
      "Step 1148 (525478) @ Episode 1591/10000, loss: 0.0030607858207076797\n",
      "Episode Reward: 27.0\n",
      "Step 1101 (526579) @ Episode 1592/10000, loss: 0.0044876821339130482\n",
      "Episode Reward: 28.0\n",
      "Step 953 (527532) @ Episode 1593/10000, loss: 0.0112606175243854525\n",
      "Episode Reward: 16.0\n",
      "Step 1074 (528606) @ Episode 1594/10000, loss: 0.0031810221262276173\n",
      "Episode Reward: 26.0\n",
      "Step 1338 (529944) @ Episode 1595/10000, loss: 0.0086806053295731547\n",
      "Episode Reward: 32.0\n",
      "Step 55 (529999) @ Episode 1596/10000, loss: 0.0024466651957482135\n",
      "Copied model parameters to target network.\n",
      "Step 918 (530862) @ Episode 1596/10000, loss: 0.0015641622012481093\n",
      "Episode Reward: 16.0\n",
      "Step 1222 (532084) @ Episode 1597/10000, loss: 0.0322083868086338044\n",
      "Episode Reward: 34.0\n",
      "Step 1174 (533258) @ Episode 1598/10000, loss: 0.0018204221269115806\n",
      "Episode Reward: 20.0\n",
      "Step 1040 (534298) @ Episode 1599/10000, loss: 0.0021002003923058516\n",
      "Episode Reward: 24.0\n",
      "Step 910 (535208) @ Episode 1600/10000, loss: 0.0206717941910028467\n",
      "Episode Reward: 19.0\n",
      "Step 1124 (536332) @ Episode 1601/10000, loss: 0.0025465295184403665\n",
      "Episode Reward: 25.0\n",
      "Step 1228 (537560) @ Episode 1602/10000, loss: 0.0046776933595538146\n",
      "Episode Reward: 28.0\n",
      "Step 906 (538466) @ Episode 1603/10000, loss: 0.0031694844365119934\n",
      "Episode Reward: 21.0\n",
      "Step 1134 (539600) @ Episode 1604/10000, loss: 0.0024307542480528355\n",
      "Episode Reward: 29.0\n",
      "Step 399 (539999) @ Episode 1605/10000, loss: 0.0036153062246739864\n",
      "Copied model parameters to target network.\n",
      "Step 964 (540564) @ Episode 1605/10000, loss: 0.0023096906952559957\n",
      "Episode Reward: 27.0\n",
      "Step 824 (541388) @ Episode 1606/10000, loss: 0.0028353605885058644\n",
      "Episode Reward: 15.0\n",
      "Step 1063 (542451) @ Episode 1607/10000, loss: 0.0083928909152746217\n",
      "Episode Reward: 18.0\n",
      "Step 1241 (543692) @ Episode 1608/10000, loss: 0.0112719750031828888\n",
      "Episode Reward: 26.0\n",
      "Step 1114 (544806) @ Episode 1609/10000, loss: 0.0028284373693168163\n",
      "Episode Reward: 23.0\n",
      "Step 1026 (545832) @ Episode 1610/10000, loss: 0.0180374104529619216\n",
      "Episode Reward: 23.0\n",
      "Step 928 (546760) @ Episode 1611/10000, loss: 0.0017067271983250976\n",
      "Episode Reward: 17.0\n",
      "Step 982 (547742) @ Episode 1612/10000, loss: 0.0100040705874562267\n",
      "Episode Reward: 16.0\n",
      "Step 1011 (548753) @ Episode 1613/10000, loss: 0.0038039789069443944\n",
      "Episode Reward: 25.0\n",
      "Step 886 (549639) @ Episode 1614/10000, loss: 0.0037012263201177126\n",
      "Episode Reward: 17.0\n",
      "Step 360 (549999) @ Episode 1615/10000, loss: 0.0019043221836909652\n",
      "Copied model parameters to target network.\n",
      "Step 863 (550502) @ Episode 1615/10000, loss: 0.0015091089298948646\n",
      "Episode Reward: 18.0\n",
      "Step 837 (551339) @ Episode 1616/10000, loss: 0.0032084162812680006\n",
      "Episode Reward: 22.0\n",
      "Step 909 (552248) @ Episode 1617/10000, loss: 0.0057352511212229735\n",
      "Episode Reward: 29.0\n",
      "Step 1479 (553727) @ Episode 1618/10000, loss: 0.0021135215647518635\n",
      "Episode Reward: 41.0\n",
      "Step 937 (554664) @ Episode 1619/10000, loss: 0.00725179305300116567\n",
      "Episode Reward: 25.0\n",
      "Step 1206 (555870) @ Episode 1620/10000, loss: 0.0292599312961101536\n",
      "Episode Reward: 26.0\n",
      "Step 1088 (556958) @ Episode 1621/10000, loss: 0.0173863805830478677\n",
      "Episode Reward: 30.0\n",
      "Step 1288 (558246) @ Episode 1622/10000, loss: 0.0041774204000830658\n",
      "Episode Reward: 32.0\n",
      "Step 1489 (559735) @ Episode 1623/10000, loss: 0.0026371295098215343\n",
      "Episode Reward: 38.0\n",
      "Step 264 (559999) @ Episode 1624/10000, loss: 0.0008093089563772082\n",
      "Copied model parameters to target network.\n",
      "Step 953 (560688) @ Episode 1624/10000, loss: 0.0031338259577751161\n",
      "Episode Reward: 16.0\n",
      "Step 1031 (561719) @ Episode 1625/10000, loss: 0.0019689656328409914\n",
      "Episode Reward: 25.0\n",
      "Step 1520 (563239) @ Episode 1626/10000, loss: 0.0299160331487655648\n",
      "Episode Reward: 40.0\n",
      "Step 819 (564058) @ Episode 1627/10000, loss: 0.0048894556239247321\n",
      "Episode Reward: 15.0\n",
      "Step 1218 (565276) @ Episode 1628/10000, loss: 0.0010772924870252618\n",
      "Episode Reward: 33.0\n",
      "Step 1265 (566541) @ Episode 1629/10000, loss: 0.00191294657997787056\n",
      "Episode Reward: 41.0\n",
      "Step 1140 (567681) @ Episode 1630/10000, loss: 0.0030089889187365777\n",
      "Episode Reward: 33.0\n",
      "Step 1005 (568686) @ Episode 1631/10000, loss: 0.0015041845617815852\n",
      "Episode Reward: 33.0\n",
      "Step 1111 (569797) @ Episode 1632/10000, loss: 0.0031661945395171642\n",
      "Episode Reward: 24.0\n",
      "Step 202 (569999) @ Episode 1633/10000, loss: 0.0018785201245918876\n",
      "Copied model parameters to target network.\n",
      "Step 1381 (571178) @ Episode 1633/10000, loss: 0.0026379111222922808\n",
      "Episode Reward: 34.0\n",
      "Step 1558 (572736) @ Episode 1634/10000, loss: 0.0037113253492861986\n",
      "Episode Reward: 52.0\n",
      "Step 906 (573642) @ Episode 1635/10000, loss: 0.0034943311475217342\n",
      "Episode Reward: 17.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1249 (574891) @ Episode 1636/10000, loss: 0.0070698433555662634\n",
      "Episode Reward: 26.0\n",
      "Step 1373 (576264) @ Episode 1637/10000, loss: 0.0042416276410222056\n",
      "Episode Reward: 28.0\n",
      "Step 1412 (577676) @ Episode 1638/10000, loss: 0.0072193355299532414\n",
      "Episode Reward: 32.0\n",
      "Step 721 (578397) @ Episode 1639/10000, loss: 0.0024058979470282793\n",
      "Episode Reward: 13.0\n",
      "Step 1044 (579441) @ Episode 1640/10000, loss: 0.0023733465932309628\n",
      "Episode Reward: 25.0\n",
      "Step 558 (579999) @ Episode 1641/10000, loss: 0.0216692872345447544\n",
      "Copied model parameters to target network.\n",
      "Step 1679 (581120) @ Episode 1641/10000, loss: 0.0036850504111498594\n",
      "Episode Reward: 57.0\n",
      "Step 848 (581968) @ Episode 1642/10000, loss: 0.0049895434640347968\n",
      "Episode Reward: 15.0\n",
      "Step 1017 (582985) @ Episode 1643/10000, loss: 0.0040016430430114277\n",
      "Episode Reward: 22.0\n",
      "Step 939 (583924) @ Episode 1644/10000, loss: 0.0092822490260005428\n",
      "Episode Reward: 21.0\n",
      "Step 979 (584903) @ Episode 1645/10000, loss: 0.0052862865850329426\n",
      "Episode Reward: 32.0\n",
      "Step 1286 (586189) @ Episode 1646/10000, loss: 0.0007222715066745877\n",
      "Episode Reward: 29.0\n",
      "Step 805 (586994) @ Episode 1647/10000, loss: 0.0034467168152332306\n",
      "Episode Reward: 13.0\n",
      "Step 1413 (588407) @ Episode 1648/10000, loss: 0.0031779929995536804\n",
      "Episode Reward: 31.0\n",
      "Step 1241 (589648) @ Episode 1649/10000, loss: 0.0019253727514296775\n",
      "Episode Reward: 36.0\n",
      "Step 351 (589999) @ Episode 1650/10000, loss: 0.0023065931163728237\n",
      "Copied model parameters to target network.\n",
      "Step 1342 (590990) @ Episode 1650/10000, loss: 0.0028672586195170887\n",
      "Episode Reward: 35.0\n",
      "Step 1371 (592361) @ Episode 1651/10000, loss: 0.0072343735955655575\n",
      "Episode Reward: 34.0\n",
      "Step 974 (593335) @ Episode 1652/10000, loss: 0.0075263655744493015\n",
      "Episode Reward: 20.0\n",
      "Step 1007 (594342) @ Episode 1653/10000, loss: 0.0028482605703175076\n",
      "Episode Reward: 21.0\n",
      "Step 1012 (595354) @ Episode 1654/10000, loss: 0.0053245634771883495\n",
      "Episode Reward: 31.0\n",
      "Step 1053 (596407) @ Episode 1655/10000, loss: 0.0082532037049531944\n",
      "Episode Reward: 23.0\n",
      "Step 1122 (597529) @ Episode 1656/10000, loss: 0.0025418414734303954\n",
      "Episode Reward: 28.0\n",
      "Step 1106 (598635) @ Episode 1657/10000, loss: 0.0083080912008881572\n",
      "Episode Reward: 29.0\n",
      "Step 1298 (599933) @ Episode 1658/10000, loss: 0.0045483284629881387\n",
      "Episode Reward: 30.0\n",
      "Step 66 (599999) @ Episode 1659/10000, loss: 0.0024777723010629416\n",
      "Copied model parameters to target network.\n",
      "Step 1304 (601237) @ Episode 1659/10000, loss: 0.0075550922192633154\n",
      "Episode Reward: 31.0\n",
      "Step 1036 (602273) @ Episode 1660/10000, loss: 0.0036456983070820573\n",
      "Episode Reward: 20.0\n",
      "Step 1023 (603296) @ Episode 1661/10000, loss: 0.0011183617170900106\n",
      "Episode Reward: 24.0\n",
      "Step 1336 (604632) @ Episode 1662/10000, loss: 0.0050022937357425698\n",
      "Episode Reward: 29.0\n",
      "Step 1103 (605735) @ Episode 1663/10000, loss: 0.0019205508287996054\n",
      "Episode Reward: 21.0\n",
      "Step 1122 (606857) @ Episode 1664/10000, loss: 0.0013706757454201584\n",
      "Episode Reward: 30.0\n",
      "Step 1195 (608052) @ Episode 1665/10000, loss: 0.0019333830568939447\n",
      "Episode Reward: 25.0\n",
      "Step 1170 (609222) @ Episode 1666/10000, loss: 0.0066546536982059482\n",
      "Episode Reward: 26.0\n",
      "Step 584 (609806) @ Episode 1667/10000, loss: 0.0018433829536661506\n",
      "Episode Reward: 12.0\n",
      "Step 193 (609999) @ Episode 1668/10000, loss: 0.0035329810343682766\n",
      "Copied model parameters to target network.\n",
      "Step 1047 (610853) @ Episode 1668/10000, loss: 0.0223066192120313642\n",
      "Episode Reward: 21.0\n",
      "Step 995 (611848) @ Episode 1669/10000, loss: 0.0026328642852604396\n",
      "Episode Reward: 19.0\n",
      "Step 593 (612441) @ Episode 1670/10000, loss: 0.0039193457923829556\n",
      "Episode Reward: 10.0\n",
      "Step 1359 (613800) @ Episode 1671/10000, loss: 0.0013558340724557638\n",
      "Episode Reward: 25.0\n",
      "Step 1115 (614915) @ Episode 1672/10000, loss: 0.0028357957489788532\n",
      "Episode Reward: 33.0\n",
      "Step 1108 (616023) @ Episode 1673/10000, loss: 0.0031664359848946333\n",
      "Episode Reward: 29.0\n",
      "Step 777 (616800) @ Episode 1674/10000, loss: 0.0377537608146667568\n",
      "Episode Reward: 13.0\n",
      "Step 1099 (617899) @ Episode 1675/10000, loss: 0.0043651596643030645\n",
      "Episode Reward: 23.0\n",
      "Step 960 (618859) @ Episode 1676/10000, loss: 0.0022765707690268755\n",
      "Episode Reward: 23.0\n",
      "Step 970 (619829) @ Episode 1677/10000, loss: 0.0250597186386585247\n",
      "Episode Reward: 27.0\n",
      "Step 170 (619999) @ Episode 1678/10000, loss: 0.0019780932925641537\n",
      "Copied model parameters to target network.\n",
      "Step 1253 (621082) @ Episode 1678/10000, loss: 0.0037467957008630037\n",
      "Episode Reward: 47.0\n",
      "Step 1375 (622457) @ Episode 1679/10000, loss: 0.0085247661918401724\n",
      "Episode Reward: 38.0\n",
      "Step 797 (623254) @ Episode 1680/10000, loss: 0.0026321019977331167\n",
      "Episode Reward: 14.0\n",
      "Step 830 (624084) @ Episode 1681/10000, loss: 0.0112282950431108478\n",
      "Episode Reward: 20.0\n",
      "Step 1381 (625465) @ Episode 1682/10000, loss: 0.0033953585661947727\n",
      "Episode Reward: 33.0\n",
      "Step 642 (626107) @ Episode 1683/10000, loss: 0.0036240771878510714\n",
      "Episode Reward: 9.0\n",
      "Step 1351 (627458) @ Episode 1684/10000, loss: 0.0045808106660842896\n",
      "Episode Reward: 29.0\n",
      "Step 981 (628439) @ Episode 1685/10000, loss: 0.0051445392891764642\n",
      "Episode Reward: 20.0\n",
      "Step 946 (629385) @ Episode 1686/10000, loss: 0.0017807192634791136\n",
      "Episode Reward: 19.0\n",
      "Step 614 (629999) @ Episode 1687/10000, loss: 0.0020940401591360575\n",
      "Copied model parameters to target network.\n",
      "Step 819 (630204) @ Episode 1687/10000, loss: 0.0016549478750675917\n",
      "Episode Reward: 18.0\n",
      "Step 958 (631162) @ Episode 1688/10000, loss: 0.0021622898057103157\n",
      "Episode Reward: 34.0\n",
      "Step 956 (632118) @ Episode 1689/10000, loss: 0.0018986165523529053\n",
      "Episode Reward: 17.0\n",
      "Step 1229 (633347) @ Episode 1690/10000, loss: 0.0007526149856857955\n",
      "Episode Reward: 24.0\n",
      "Step 769 (634116) @ Episode 1691/10000, loss: 0.0019026454538106918\n",
      "Episode Reward: 15.0\n",
      "Step 595 (634711) @ Episode 1692/10000, loss: 0.0045472769998013975\n",
      "Episode Reward: 12.0\n",
      "Step 1337 (636048) @ Episode 1693/10000, loss: 0.0023210686631500723\n",
      "Episode Reward: 26.0\n",
      "Step 1092 (637140) @ Episode 1694/10000, loss: 0.0020507709123194218\n",
      "Episode Reward: 20.0\n",
      "Step 1161 (638301) @ Episode 1695/10000, loss: 0.0031190153677016497\n",
      "Episode Reward: 24.0\n",
      "Step 393 (638694) @ Episode 1696/10000, loss: 0.0042695375159382825\n",
      "Episode Reward: 5.0\n",
      "Step 695 (639389) @ Episode 1697/10000, loss: 0.0018561182077974084\n",
      "Episode Reward: 11.0\n",
      "Step 610 (639999) @ Episode 1698/10000, loss: 0.0053026909008622172\n",
      "Copied model parameters to target network.\n",
      "Step 1154 (640543) @ Episode 1698/10000, loss: 0.0031843513716012249\n",
      "Episode Reward: 27.0\n",
      "Step 1085 (641628) @ Episode 1699/10000, loss: 0.0050496226176619536\n",
      "Episode Reward: 19.0\n",
      "Step 824 (642452) @ Episode 1700/10000, loss: 0.0030693709850311285\n",
      "Episode Reward: 21.0\n",
      "Step 1511 (643963) @ Episode 1701/10000, loss: 0.0043765120208263437\n",
      "Episode Reward: 44.0\n",
      "Step 703 (644666) @ Episode 1702/10000, loss: 0.0024252522271126514\n",
      "Episode Reward: 11.0\n",
      "Step 782 (645448) @ Episode 1703/10000, loss: 0.0016574484761804342\n",
      "Episode Reward: 19.0\n",
      "Step 1034 (646482) @ Episode 1704/10000, loss: 0.0036059659905731682\n",
      "Episode Reward: 25.0\n",
      "Step 1013 (647495) @ Episode 1705/10000, loss: 0.0026429411955177784\n",
      "Episode Reward: 19.0\n",
      "Step 863 (648358) @ Episode 1706/10000, loss: 0.0087575642392039303\n",
      "Episode Reward: 18.0\n",
      "Step 835 (649193) @ Episode 1707/10000, loss: 0.0022169135045260195\n",
      "Episode Reward: 14.0\n",
      "Step 786 (649979) @ Episode 1708/10000, loss: 0.0012271546293050056\n",
      "Episode Reward: 13.0\n",
      "Step 20 (649999) @ Episode 1709/10000, loss: 0.0031559325288981237\n",
      "Copied model parameters to target network.\n",
      "Step 779 (650758) @ Episode 1709/10000, loss: 0.0030750366859138013\n",
      "Episode Reward: 16.0\n",
      "Step 1099 (651857) @ Episode 1710/10000, loss: 0.0043886965140700348\n",
      "Episode Reward: 30.0\n",
      "Step 1077 (652934) @ Episode 1711/10000, loss: 0.0053374795243144035\n",
      "Episode Reward: 29.0\n",
      "Step 874 (653808) @ Episode 1712/10000, loss: 0.0010736967669799924\n",
      "Episode Reward: 15.0\n",
      "Step 671 (654479) @ Episode 1713/10000, loss: 0.0016307544428855184\n",
      "Episode Reward: 12.0\n",
      "Step 1020 (655499) @ Episode 1714/10000, loss: 0.1115026250481605532\n",
      "Episode Reward: 30.0\n",
      "Step 1076 (656575) @ Episode 1715/10000, loss: 0.0026484814006835222\n",
      "Episode Reward: 23.0\n",
      "Step 1098 (657673) @ Episode 1716/10000, loss: 0.0053098048083484177\n",
      "Episode Reward: 19.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1402 (659075) @ Episode 1717/10000, loss: 0.0071102813817560675\n",
      "Episode Reward: 38.0\n",
      "Step 819 (659894) @ Episode 1718/10000, loss: 0.0036737653426826187\n",
      "Episode Reward: 18.0\n",
      "Step 105 (659999) @ Episode 1719/10000, loss: 0.0021117120049893856\n",
      "Copied model parameters to target network.\n",
      "Step 1098 (660992) @ Episode 1719/10000, loss: 0.0037458911538124084\n",
      "Episode Reward: 26.0\n",
      "Step 985 (661977) @ Episode 1720/10000, loss: 0.0015484137693420053\n",
      "Episode Reward: 16.0\n",
      "Step 824 (662801) @ Episode 1721/10000, loss: 0.0340719036757946787\n",
      "Episode Reward: 13.0\n",
      "Step 1844 (664645) @ Episode 1722/10000, loss: 0.0024786021094769246\n",
      "Episode Reward: 54.0\n",
      "Step 1049 (665694) @ Episode 1723/10000, loss: 0.0183382723480463037\n",
      "Episode Reward: 24.0\n",
      "Step 504 (666198) @ Episode 1724/10000, loss: 0.0012809170875698328\n",
      "Episode Reward: 14.0\n",
      "Step 826 (667024) @ Episode 1725/10000, loss: 0.0072358013130724438\n",
      "Episode Reward: 17.0\n",
      "Step 1569 (668593) @ Episode 1726/10000, loss: 0.0015798776876181364\n",
      "Episode Reward: 37.0\n",
      "Step 1099 (669692) @ Episode 1727/10000, loss: 0.0431638844311237343\n",
      "Episode Reward: 21.0\n",
      "Step 307 (669999) @ Episode 1728/10000, loss: 0.0015400741249322891\n",
      "Copied model parameters to target network.\n",
      "Step 725 (670417) @ Episode 1728/10000, loss: 0.0123652406036853794\n",
      "Episode Reward: 13.0\n",
      "Step 617 (671034) @ Episode 1729/10000, loss: 0.0050980756059288983\n",
      "Episode Reward: 13.0\n",
      "Step 987 (672021) @ Episode 1730/10000, loss: 0.0033790380693972115\n",
      "Episode Reward: 18.0\n",
      "Step 856 (672877) @ Episode 1731/10000, loss: 0.0026407842524349693\n",
      "Episode Reward: 21.0\n",
      "Step 1020 (673897) @ Episode 1732/10000, loss: 0.0033719129860401154\n",
      "Episode Reward: 19.0\n",
      "Step 1297 (675194) @ Episode 1733/10000, loss: 0.0295777022838592535\n",
      "Episode Reward: 27.0\n",
      "Step 691 (675885) @ Episode 1734/10000, loss: 0.0032202829606831074\n",
      "Episode Reward: 11.0\n",
      "Step 1160 (677045) @ Episode 1735/10000, loss: 0.0020423540845513344\n",
      "Episode Reward: 24.0\n",
      "Step 884 (677929) @ Episode 1736/10000, loss: 0.0017272578552365303\n",
      "Episode Reward: 16.0\n",
      "Step 1478 (679407) @ Episode 1737/10000, loss: 0.0034111738204956055\n",
      "Episode Reward: 33.0\n",
      "Step 592 (679999) @ Episode 1738/10000, loss: 0.0020672646351158626\n",
      "Copied model parameters to target network.\n",
      "Step 1071 (680478) @ Episode 1738/10000, loss: 0.0050357580184936525\n",
      "Episode Reward: 25.0\n",
      "Step 1048 (681526) @ Episode 1739/10000, loss: 0.0032555554062128067\n",
      "Episode Reward: 31.0\n",
      "Step 1149 (682675) @ Episode 1740/10000, loss: 0.0028457297012209892\n",
      "Episode Reward: 24.0\n",
      "Step 1131 (683806) @ Episode 1741/10000, loss: 0.0054321996867656717\n",
      "Episode Reward: 21.0\n",
      "Step 826 (684632) @ Episode 1742/10000, loss: 0.0131614655256271362\n",
      "Episode Reward: 21.0\n",
      "Step 973 (685605) @ Episode 1743/10000, loss: 0.0028135578613728285\n",
      "Episode Reward: 24.0\n",
      "Step 594 (686199) @ Episode 1744/10000, loss: 0.0026174942031502724\n",
      "Episode Reward: 11.0\n",
      "Step 994 (687193) @ Episode 1745/10000, loss: 0.0040409523062407974\n",
      "Episode Reward: 17.0\n",
      "Step 1255 (688448) @ Episode 1746/10000, loss: 0.0052943057380616665\n",
      "Episode Reward: 36.0\n",
      "Step 954 (689402) @ Episode 1747/10000, loss: 0.0099698724225163465\n",
      "Episode Reward: 17.0\n",
      "Step 597 (689999) @ Episode 1748/10000, loss: 0.0078442711383104326\n",
      "Copied model parameters to target network.\n",
      "Step 802 (690204) @ Episode 1748/10000, loss: 0.0035938154906034478\n",
      "Episode Reward: 23.0\n",
      "Step 637 (690841) @ Episode 1749/10000, loss: 0.0035472870804369456\n",
      "Episode Reward: 12.0\n",
      "Step 1041 (691882) @ Episode 1750/10000, loss: 0.0044048572890460493\n",
      "Episode Reward: 24.0\n",
      "Step 1456 (693338) @ Episode 1751/10000, loss: 0.0098943850025534636\n",
      "Episode Reward: 24.0\n",
      "Step 777 (694115) @ Episode 1752/10000, loss: 0.0022966675460338593\n",
      "Episode Reward: 13.0\n",
      "Step 862 (694977) @ Episode 1753/10000, loss: 0.0055627059191465382\n",
      "Episode Reward: 21.0\n",
      "Step 935 (695912) @ Episode 1754/10000, loss: 0.0011910839239135385\n",
      "Episode Reward: 19.0\n",
      "Step 1060 (696972) @ Episode 1755/10000, loss: 0.0048041460104286676\n",
      "Episode Reward: 25.0\n",
      "Step 1164 (698136) @ Episode 1756/10000, loss: 0.0008954888326115906\n",
      "Episode Reward: 26.0\n",
      "Step 803 (698939) @ Episode 1757/10000, loss: 0.0057725338265299833\n",
      "Episode Reward: 12.0\n",
      "Step 765 (699704) @ Episode 1758/10000, loss: 0.0043887626379728324\n",
      "Episode Reward: 15.0\n",
      "Step 295 (699999) @ Episode 1759/10000, loss: 0.0038283604662865445\n",
      "Copied model parameters to target network.\n",
      "Step 1070 (700774) @ Episode 1759/10000, loss: 0.0824028700590133777\n",
      "Episode Reward: 24.0\n",
      "Step 1561 (702335) @ Episode 1760/10000, loss: 0.0081694228574633628\n",
      "Episode Reward: 31.0\n",
      "Step 705 (703040) @ Episode 1761/10000, loss: 0.0146497320383787164\n",
      "Episode Reward: 19.0\n",
      "Step 760 (703800) @ Episode 1762/10000, loss: 0.0014558765105903149\n",
      "Episode Reward: 14.0\n",
      "Step 942 (704742) @ Episode 1763/10000, loss: 0.0028020469471812255\n",
      "Episode Reward: 17.0\n",
      "Step 857 (705599) @ Episode 1764/10000, loss: 0.0014308545505627997\n",
      "Episode Reward: 24.0\n",
      "Step 776 (706375) @ Episode 1765/10000, loss: 0.0107555473223328597\n",
      "Episode Reward: 27.0\n",
      "Step 1069 (707444) @ Episode 1766/10000, loss: 0.0186050869524478924\n",
      "Episode Reward: 18.0\n",
      "Step 809 (708253) @ Episode 1767/10000, loss: 0.0048842667602002624\n",
      "Episode Reward: 14.0\n",
      "Step 1081 (709334) @ Episode 1768/10000, loss: 0.0023324743378907447\n",
      "Episode Reward: 26.0\n",
      "Step 652 (709986) @ Episode 1769/10000, loss: 0.0264380089938640636\n",
      "Episode Reward: 11.0\n",
      "Step 13 (709999) @ Episode 1770/10000, loss: 0.0029840474016964436\n",
      "Copied model parameters to target network.\n",
      "Step 654 (710640) @ Episode 1770/10000, loss: 0.0050960867665708065\n",
      "Episode Reward: 17.0\n",
      "Step 664 (711304) @ Episode 1771/10000, loss: 0.0257088728249073033\n",
      "Episode Reward: 11.0\n",
      "Step 738 (712042) @ Episode 1772/10000, loss: 0.0028529898263514045\n",
      "Episode Reward: 12.0\n",
      "Step 1133 (713175) @ Episode 1773/10000, loss: 0.0012021490838378668\n",
      "Episode Reward: 30.0\n",
      "Step 747 (713922) @ Episode 1774/10000, loss: 0.0017216593259945512\n",
      "Episode Reward: 10.0\n",
      "Step 801 (714723) @ Episode 1775/10000, loss: 0.0042732534930109986\n",
      "Episode Reward: 16.0\n",
      "Step 698 (715421) @ Episode 1776/10000, loss: 0.0014926778385415673\n",
      "Episode Reward: 13.0\n",
      "Step 847 (716268) @ Episode 1777/10000, loss: 0.0034664436243474483\n",
      "Episode Reward: 17.0\n",
      "Step 744 (717012) @ Episode 1778/10000, loss: 0.0040379227139055734\n",
      "Episode Reward: 12.0\n",
      "Step 1203 (718215) @ Episode 1779/10000, loss: 0.0030782097019255165\n",
      "Episode Reward: 22.0\n",
      "Step 893 (719108) @ Episode 1780/10000, loss: 0.0045149731449782854\n",
      "Episode Reward: 23.0\n",
      "Step 891 (719999) @ Episode 1781/10000, loss: 0.0027894463855773216\n",
      "Copied model parameters to target network.\n",
      "Step 1322 (720430) @ Episode 1781/10000, loss: 0.0031290382612496614\n",
      "Episode Reward: 27.0\n",
      "Step 613 (721043) @ Episode 1782/10000, loss: 0.0182921923696994787\n",
      "Episode Reward: 10.0\n",
      "Step 1320 (722363) @ Episode 1783/10000, loss: 0.0040284665301442153\n",
      "Episode Reward: 33.0\n",
      "Step 1000 (723363) @ Episode 1784/10000, loss: 0.004740520846098661\n",
      "Episode Reward: 18.0\n",
      "Step 1162 (724525) @ Episode 1785/10000, loss: 0.0876558944582939193\n",
      "Episode Reward: 36.0\n",
      "Step 1090 (725615) @ Episode 1786/10000, loss: 0.0468488931655883875\n",
      "Episode Reward: 21.0\n",
      "Step 968 (726583) @ Episode 1787/10000, loss: 0.0071222828701138516\n",
      "Episode Reward: 20.0\n",
      "Step 1546 (728129) @ Episode 1788/10000, loss: 0.0021847165189683437\n",
      "Episode Reward: 37.0\n",
      "Step 1244 (729373) @ Episode 1789/10000, loss: 0.0029669331852346666\n",
      "Episode Reward: 27.0\n",
      "Step 626 (729999) @ Episode 1790/10000, loss: 0.0043722977861762058\n",
      "Copied model parameters to target network.\n",
      "Step 1000 (730373) @ Episode 1790/10000, loss: 0.002837233245372772\n",
      "Episode Reward: 20.0\n",
      "Step 1242 (731615) @ Episode 1791/10000, loss: 0.0081242006272077566\n",
      "Episode Reward: 23.0\n",
      "Step 620 (732235) @ Episode 1792/10000, loss: 0.0049265655688941486\n",
      "Episode Reward: 8.0\n",
      "Step 1072 (733307) @ Episode 1793/10000, loss: 0.0046415342949330815\n",
      "Episode Reward: 26.0\n",
      "Step 916 (734223) @ Episode 1794/10000, loss: 0.0056976093910634527\n",
      "Episode Reward: 28.0\n",
      "Step 1014 (735237) @ Episode 1795/10000, loss: 0.0036110947839915752\n",
      "Episode Reward: 17.0\n",
      "Step 679 (735916) @ Episode 1796/10000, loss: 0.0024767233990132816\n",
      "Episode Reward: 11.0\n",
      "Step 612 (736528) @ Episode 1797/10000, loss: 0.0065382099710404876\n",
      "Episode Reward: 9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 947 (737475) @ Episode 1798/10000, loss: 0.0032298273872584105\n",
      "Episode Reward: 23.0\n",
      "Step 917 (738392) @ Episode 1799/10000, loss: 0.0120262773707509047\n",
      "Episode Reward: 20.0\n",
      "Step 1024 (739416) @ Episode 1800/10000, loss: 0.0023992764763534074\n",
      "Episode Reward: 21.0\n",
      "Step 537 (739953) @ Episode 1801/10000, loss: 0.0033141882158815866\n",
      "Episode Reward: 8.0\n",
      "Step 46 (739999) @ Episode 1802/10000, loss: 0.0043905661441385757\n",
      "Copied model parameters to target network.\n",
      "Step 1300 (741253) @ Episode 1802/10000, loss: 0.0028253020718693733\n",
      "Episode Reward: 23.0\n",
      "Step 862 (742115) @ Episode 1803/10000, loss: 0.0027282864321023226\n",
      "Episode Reward: 21.0\n",
      "Step 756 (742871) @ Episode 1804/10000, loss: 0.0042024152353405951\n",
      "Episode Reward: 23.0\n",
      "Step 956 (743827) @ Episode 1805/10000, loss: 0.0020406830590218306\n",
      "Episode Reward: 18.0\n",
      "Step 736 (744563) @ Episode 1806/10000, loss: 0.0014094829093664885\n",
      "Episode Reward: 10.0\n",
      "Step 920 (745483) @ Episode 1807/10000, loss: 0.0028900397010147575\n",
      "Episode Reward: 13.0\n",
      "Step 1402 (746885) @ Episode 1808/10000, loss: 0.0018752109026536345\n",
      "Episode Reward: 25.0\n",
      "Step 766 (747651) @ Episode 1809/10000, loss: 0.0023016305640339857\n",
      "Episode Reward: 23.0\n",
      "Step 985 (748636) @ Episode 1810/10000, loss: 0.0052428087219595913\n",
      "Episode Reward: 21.0\n",
      "Step 1093 (749729) @ Episode 1811/10000, loss: 0.0014403250534087423\n",
      "Episode Reward: 23.0\n",
      "Step 270 (749999) @ Episode 1812/10000, loss: 0.0082428650930523874\n",
      "Copied model parameters to target network.\n",
      "Step 1342 (751071) @ Episode 1812/10000, loss: 0.0361088588833808968\n",
      "Episode Reward: 31.0\n",
      "Step 1155 (752226) @ Episode 1813/10000, loss: 0.0026665383484214544\n",
      "Episode Reward: 24.0\n",
      "Step 674 (752900) @ Episode 1814/10000, loss: 0.0027067034970968968\n",
      "Episode Reward: 11.0\n",
      "Step 806 (753706) @ Episode 1815/10000, loss: 0.0016959207132458687\n",
      "Episode Reward: 23.0\n",
      "Step 1272 (754978) @ Episode 1816/10000, loss: 0.0045968210324645044\n",
      "Episode Reward: 29.0\n",
      "Step 1012 (755990) @ Episode 1817/10000, loss: 0.0030518383719027042\n",
      "Episode Reward: 18.0\n",
      "Step 823 (756813) @ Episode 1818/10000, loss: 0.0079079139977693567\n",
      "Episode Reward: 13.0\n",
      "Step 824 (757637) @ Episode 1819/10000, loss: 0.0015413659857586026\n",
      "Episode Reward: 14.0\n",
      "Step 1073 (758710) @ Episode 1820/10000, loss: 0.0018071224913001061\n",
      "Episode Reward: 27.0\n",
      "Step 1028 (759738) @ Episode 1821/10000, loss: 0.0095190359279513366\n",
      "Episode Reward: 28.0\n",
      "Step 261 (759999) @ Episode 1822/10000, loss: 0.0023070841562002897\n",
      "Copied model parameters to target network.\n",
      "Step 882 (760620) @ Episode 1822/10000, loss: 0.0341361947357654603\n",
      "Episode Reward: 22.0\n",
      "Step 1107 (761727) @ Episode 1823/10000, loss: 0.0041733509860932835\n",
      "Episode Reward: 24.0\n",
      "Step 910 (762637) @ Episode 1824/10000, loss: 0.0030486898031085735\n",
      "Episode Reward: 16.0\n",
      "Step 783 (763420) @ Episode 1825/10000, loss: 0.0016361080342903733\n",
      "Episode Reward: 20.0\n",
      "Step 499 (763919) @ Episode 1826/10000, loss: 0.0095405522733926775\n",
      "Episode Reward: 6.0\n",
      "Step 934 (764853) @ Episode 1827/10000, loss: 0.0058498010039329534\n",
      "Episode Reward: 15.0\n",
      "Step 1254 (766107) @ Episode 1828/10000, loss: 0.0038709235377609733\n",
      "Episode Reward: 37.0\n",
      "Step 1208 (767315) @ Episode 1829/10000, loss: 0.0443134456872940062\n",
      "Episode Reward: 31.0\n",
      "Step 1210 (768525) @ Episode 1830/10000, loss: 0.0138208270072937017\n",
      "Episode Reward: 34.0\n",
      "Step 795 (769320) @ Episode 1831/10000, loss: 0.0033542900346219548\n",
      "Episode Reward: 16.0\n",
      "Step 679 (769999) @ Episode 1832/10000, loss: 0.0019149895524606109\n",
      "Copied model parameters to target network.\n",
      "Step 1264 (770584) @ Episode 1832/10000, loss: 0.0056105875410139568\n",
      "Episode Reward: 30.0\n",
      "Step 840 (771424) @ Episode 1833/10000, loss: 0.0035592769272625446\n",
      "Episode Reward: 15.0\n",
      "Step 1126 (772550) @ Episode 1834/10000, loss: 0.0057785883545875558\n",
      "Episode Reward: 21.0\n",
      "Step 867 (773417) @ Episode 1835/10000, loss: 0.0021268716081976897\n",
      "Episode Reward: 16.0\n",
      "Step 794 (774211) @ Episode 1836/10000, loss: 0.0043504564091563225\n",
      "Episode Reward: 27.0\n",
      "Step 907 (775118) @ Episode 1837/10000, loss: 0.0020724863279610872\n",
      "Episode Reward: 18.0\n",
      "Step 1235 (776353) @ Episode 1838/10000, loss: 0.0062377438880503182\n",
      "Episode Reward: 36.0\n",
      "Step 713 (777066) @ Episode 1839/10000, loss: 0.0053906319662928584\n",
      "Episode Reward: 14.0\n",
      "Step 876 (777942) @ Episode 1840/10000, loss: 0.0142631204798817634\n",
      "Episode Reward: 16.0\n",
      "Step 1275 (779217) @ Episode 1841/10000, loss: 0.0055575198493897915\n",
      "Episode Reward: 33.0\n",
      "Step 782 (779999) @ Episode 1842/10000, loss: 0.0031525618396699436\n",
      "Copied model parameters to target network.\n",
      "Step 1212 (780429) @ Episode 1842/10000, loss: 0.0115015171468257952\n",
      "Episode Reward: 23.0\n",
      "Step 1025 (781454) @ Episode 1843/10000, loss: 0.0198091920465230945\n",
      "Episode Reward: 20.0\n",
      "Step 1038 (782492) @ Episode 1844/10000, loss: 0.0061349649913609032\n",
      "Episode Reward: 16.0\n",
      "Step 1361 (783853) @ Episode 1845/10000, loss: 0.0020736542064696557\n",
      "Episode Reward: 22.0\n",
      "Step 992 (784845) @ Episode 1846/10000, loss: 0.0032865300308912992\n",
      "Episode Reward: 19.0\n",
      "Step 1060 (785905) @ Episode 1847/10000, loss: 0.0665669515728950536\n",
      "Episode Reward: 19.0\n",
      "Step 929 (786834) @ Episode 1848/10000, loss: 0.0259442236274480825\n",
      "Episode Reward: 15.0\n",
      "Step 1330 (788164) @ Episode 1849/10000, loss: 0.0036166966892778873\n",
      "Episode Reward: 34.0\n",
      "Step 1086 (789250) @ Episode 1850/10000, loss: 0.0021415085066109896\n",
      "Episode Reward: 26.0\n",
      "Step 749 (789999) @ Episode 1851/10000, loss: 0.0030685989186167717\n",
      "Copied model parameters to target network.\n",
      "Step 1060 (790310) @ Episode 1851/10000, loss: 0.0055830581113696155\n",
      "Episode Reward: 22.0\n",
      "Step 1530 (791840) @ Episode 1852/10000, loss: 0.0011797897750511765\n",
      "Episode Reward: 46.0\n",
      "Step 969 (792809) @ Episode 1853/10000, loss: 0.0061441054567694665\n",
      "Episode Reward: 22.0\n",
      "Step 720 (793529) @ Episode 1854/10000, loss: 0.0410720258951187143\n",
      "Episode Reward: 11.0\n",
      "Step 1401 (794930) @ Episode 1855/10000, loss: 0.0047905901446938515\n",
      "Episode Reward: 38.0\n",
      "Step 823 (795753) @ Episode 1856/10000, loss: 0.0046503199264407163\n",
      "Episode Reward: 17.0\n",
      "Step 1137 (796890) @ Episode 1857/10000, loss: 0.0025979857891798026\n",
      "Episode Reward: 23.0\n",
      "Step 1010 (797900) @ Episode 1858/10000, loss: 0.0138209089636802676\n",
      "Episode Reward: 23.0\n",
      "Step 1181 (799081) @ Episode 1859/10000, loss: 0.0024302096571773294\n",
      "Episode Reward: 31.0\n",
      "Step 636 (799717) @ Episode 1860/10000, loss: 0.0019123053643852472\n",
      "Episode Reward: 10.0\n",
      "Step 282 (799999) @ Episode 1861/10000, loss: 0.0040989182889461525\n",
      "Copied model parameters to target network.\n",
      "Step 1626 (801343) @ Episode 1861/10000, loss: 0.0041265832260251045\n",
      "Episode Reward: 49.0\n",
      "Step 1103 (802446) @ Episode 1862/10000, loss: 0.0029961557593196638\n",
      "Episode Reward: 28.0\n",
      "Step 1252 (803698) @ Episode 1863/10000, loss: 0.0056052668951451782\n",
      "Episode Reward: 35.0\n",
      "Step 1128 (804826) @ Episode 1864/10000, loss: 0.0102862538769841244\n",
      "Episode Reward: 22.0\n",
      "Step 577 (805403) @ Episode 1865/10000, loss: 0.0045786253176629544\n",
      "Episode Reward: 8.0\n",
      "Step 1083 (806486) @ Episode 1866/10000, loss: 0.0078401016071438795\n",
      "Episode Reward: 25.0\n",
      "Step 1248 (807734) @ Episode 1867/10000, loss: 0.0048329052515327936\n",
      "Episode Reward: 28.0\n",
      "Step 872 (808606) @ Episode 1868/10000, loss: 0.0059376605786383153\n",
      "Episode Reward: 17.0\n",
      "Step 819 (809425) @ Episode 1869/10000, loss: 0.0049652894958853729\n",
      "Episode Reward: 21.0\n",
      "Step 574 (809999) @ Episode 1870/10000, loss: 0.0014472176553681493\n",
      "Copied model parameters to target network.\n",
      "Step 984 (810409) @ Episode 1870/10000, loss: 0.0030576041899621487\n",
      "Episode Reward: 16.0\n",
      "Step 892 (811301) @ Episode 1871/10000, loss: 0.0036064530722796917\n",
      "Episode Reward: 13.0\n",
      "Step 860 (812161) @ Episode 1872/10000, loss: 0.0026203701272606856\n",
      "Episode Reward: 21.0\n",
      "Step 1564 (813725) @ Episode 1873/10000, loss: 0.0059887357056140973\n",
      "Episode Reward: 42.0\n",
      "Step 891 (814616) @ Episode 1874/10000, loss: 0.0043038846924901015\n",
      "Episode Reward: 18.0\n",
      "Step 1465 (816081) @ Episode 1875/10000, loss: 0.0024707831908017397\n",
      "Episode Reward: 40.0\n",
      "Step 1050 (817131) @ Episode 1876/10000, loss: 0.0034430027008056645\n",
      "Episode Reward: 33.0\n",
      "Step 975 (818106) @ Episode 1877/10000, loss: 0.0019355893600732088\n",
      "Episode Reward: 20.0\n",
      "Step 761 (818867) @ Episode 1878/10000, loss: 0.0045524761080741883\n",
      "Episode Reward: 15.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 821 (819688) @ Episode 1879/10000, loss: 0.0071193324401974685\n",
      "Episode Reward: 13.0\n",
      "Step 311 (819999) @ Episode 1880/10000, loss: 0.0029056339990347624\n",
      "Copied model parameters to target network.\n",
      "Step 933 (820621) @ Episode 1880/10000, loss: 0.0078579066321253784\n",
      "Episode Reward: 19.0\n",
      "Step 902 (821523) @ Episode 1881/10000, loss: 0.0044496078044176163\n",
      "Episode Reward: 16.0\n",
      "Step 1230 (822753) @ Episode 1882/10000, loss: 0.0042791501618921764\n",
      "Episode Reward: 31.0\n",
      "Step 707 (823460) @ Episode 1883/10000, loss: 0.0091859456151723867\n",
      "Episode Reward: 16.0\n",
      "Step 1081 (824541) @ Episode 1884/10000, loss: 0.0177434571087360386\n",
      "Episode Reward: 35.0\n",
      "Step 834 (825375) @ Episode 1885/10000, loss: 0.0102072302252054213\n",
      "Episode Reward: 15.0\n",
      "Step 1285 (826660) @ Episode 1886/10000, loss: 0.0054839029908180247\n",
      "Episode Reward: 35.0\n",
      "Step 698 (827358) @ Episode 1887/10000, loss: 0.0021347110159695157\n",
      "Episode Reward: 11.0\n",
      "Step 631 (827989) @ Episode 1888/10000, loss: 0.0041731377132236962\n",
      "Episode Reward: 9.0\n",
      "Step 1113 (829102) @ Episode 1889/10000, loss: 0.0041472562588751326\n",
      "Episode Reward: 20.0\n",
      "Step 897 (829999) @ Episode 1890/10000, loss: 0.0040478953160345554\n",
      "Copied model parameters to target network.\n",
      "Step 1431 (830533) @ Episode 1890/10000, loss: 0.0048735965974628925\n",
      "Episode Reward: 38.0\n",
      "Step 771 (831304) @ Episode 1891/10000, loss: 0.0049401861615478997\n",
      "Episode Reward: 12.0\n",
      "Step 1185 (832489) @ Episode 1892/10000, loss: 0.0036779842339456082\n",
      "Episode Reward: 29.0\n",
      "Step 1355 (833844) @ Episode 1893/10000, loss: 0.0046776607632637025\n",
      "Episode Reward: 37.0\n",
      "Step 912 (834756) @ Episode 1894/10000, loss: 0.0084050847217440673\n",
      "Episode Reward: 23.0\n",
      "Step 900 (835656) @ Episode 1895/10000, loss: 0.0017536096274852753\n",
      "Episode Reward: 13.0\n",
      "Step 690 (836346) @ Episode 1896/10000, loss: 0.0035369105171412234\n",
      "Episode Reward: 18.0\n",
      "Step 1071 (837417) @ Episode 1897/10000, loss: 0.0166800227016210566\n",
      "Episode Reward: 19.0\n",
      "Step 888 (838305) @ Episode 1898/10000, loss: 0.0042754644528031352\n",
      "Episode Reward: 17.0\n",
      "Step 753 (839058) @ Episode 1899/10000, loss: 0.0048178844153881074\n",
      "Episode Reward: 14.0\n",
      "Step 941 (839999) @ Episode 1900/10000, loss: 0.0066337101161479955\n",
      "Copied model parameters to target network.\n",
      "Step 1298 (840356) @ Episode 1900/10000, loss: 0.0048545203171670445\n",
      "Episode Reward: 26.0\n",
      "Step 768 (841124) @ Episode 1901/10000, loss: 0.0052253683097660545\n",
      "Episode Reward: 13.0\n",
      "Step 972 (842096) @ Episode 1902/10000, loss: 0.0014275487046688795\n",
      "Episode Reward: 16.0\n",
      "Step 1089 (843185) @ Episode 1903/10000, loss: 0.0063525112345814705\n",
      "Episode Reward: 21.0\n",
      "Step 806 (843991) @ Episode 1904/10000, loss: 0.0204490181058645257\n",
      "Episode Reward: 24.0\n",
      "Step 1598 (845589) @ Episode 1905/10000, loss: 0.0372540317475795755\n",
      "Episode Reward: 45.0\n",
      "Step 1184 (846773) @ Episode 1906/10000, loss: 0.0053127598948776727\n",
      "Episode Reward: 26.0\n",
      "Step 1865 (848638) @ Episode 1907/10000, loss: 0.0092053739354014493\n",
      "Episode Reward: 51.0\n",
      "Step 909 (849547) @ Episode 1908/10000, loss: 0.0124904736876487737\n",
      "Episode Reward: 19.0\n",
      "Step 452 (849999) @ Episode 1909/10000, loss: 0.0046930001117289077\n",
      "Copied model parameters to target network.\n",
      "Step 1256 (850803) @ Episode 1909/10000, loss: 0.0208210255950689312\n",
      "Episode Reward: 26.0\n",
      "Step 1192 (851995) @ Episode 1910/10000, loss: 0.0071552572771906854\n",
      "Episode Reward: 35.0\n",
      "Step 805 (852800) @ Episode 1911/10000, loss: 0.0161850228905677828\n",
      "Episode Reward: 20.0\n",
      "Step 1209 (854009) @ Episode 1912/10000, loss: 0.0697278231382378985\n",
      "Episode Reward: 23.0\n",
      "Step 997 (855006) @ Episode 1913/10000, loss: 0.0047555575147271167\n",
      "Episode Reward: 20.0\n",
      "Step 1087 (856093) @ Episode 1914/10000, loss: 0.0029694393742829564\n",
      "Episode Reward: 26.0\n",
      "Step 1594 (857687) @ Episode 1915/10000, loss: 0.0060798255726695063\n",
      "Episode Reward: 47.0\n",
      "Step 1431 (859118) @ Episode 1916/10000, loss: 0.0046798121184110647\n",
      "Episode Reward: 30.0\n",
      "Step 881 (859999) @ Episode 1917/10000, loss: 0.0031812309753149753\n",
      "Copied model parameters to target network.\n",
      "Step 983 (860101) @ Episode 1917/10000, loss: 0.0130099412053823475\n",
      "Episode Reward: 19.0\n",
      "Step 747 (860848) @ Episode 1918/10000, loss: 0.0102030169218778612\n",
      "Episode Reward: 13.0\n",
      "Step 678 (861526) @ Episode 1919/10000, loss: 0.0928639024496078505\n",
      "Episode Reward: 11.0\n",
      "Step 1385 (862911) @ Episode 1920/10000, loss: 0.0064601451158523564\n",
      "Episode Reward: 31.0\n",
      "Step 1374 (864285) @ Episode 1921/10000, loss: 0.0055345189757645135\n",
      "Episode Reward: 40.0\n",
      "Step 679 (864964) @ Episode 1922/10000, loss: 0.0140593145042657855\n",
      "Episode Reward: 9.0\n",
      "Step 665 (865629) @ Episode 1923/10000, loss: 0.0144266812130808835\n",
      "Episode Reward: 20.0\n",
      "Step 1262 (866891) @ Episode 1924/10000, loss: 0.0081737190485000614\n",
      "Episode Reward: 33.0\n",
      "Step 1192 (868083) @ Episode 1925/10000, loss: 0.0038692906964570284\n",
      "Episode Reward: 22.0\n",
      "Step 1167 (869250) @ Episode 1926/10000, loss: 0.0019955097232013945\n",
      "Episode Reward: 20.0\n",
      "Step 749 (869999) @ Episode 1927/10000, loss: 0.0176534503698349823\n",
      "Copied model parameters to target network.\n",
      "Step 1643 (870893) @ Episode 1927/10000, loss: 0.0071826316416263587\n",
      "Episode Reward: 55.0\n",
      "Step 1226 (872119) @ Episode 1928/10000, loss: 0.0026640342548489573\n",
      "Episode Reward: 26.0\n",
      "Step 1075 (873194) @ Episode 1929/10000, loss: 0.0083582205697894197\n",
      "Episode Reward: 19.0\n",
      "Step 1051 (874245) @ Episode 1930/10000, loss: 0.0029957364313304424\n",
      "Episode Reward: 21.0\n",
      "Step 1063 (875308) @ Episode 1931/10000, loss: 0.0053929961286485195\n",
      "Episode Reward: 27.0\n",
      "Step 1583 (876891) @ Episode 1932/10000, loss: 0.0060056191869080074\n",
      "Episode Reward: 52.0\n",
      "Step 1278 (878169) @ Episode 1933/10000, loss: 0.0069300830364227295\n",
      "Episode Reward: 30.0\n",
      "Step 1410 (879579) @ Episode 1934/10000, loss: 0.0114567512646317489\n",
      "Episode Reward: 29.0\n",
      "Step 420 (879999) @ Episode 1935/10000, loss: 0.0021971017122268677\n",
      "Copied model parameters to target network.\n",
      "Step 1197 (880776) @ Episode 1935/10000, loss: 0.0057053253985941417\n",
      "Episode Reward: 25.0\n",
      "Step 1165 (881941) @ Episode 1936/10000, loss: 0.0045619858428835875\n",
      "Episode Reward: 41.0\n",
      "Step 1056 (882997) @ Episode 1937/10000, loss: 0.0026417684275656947\n",
      "Episode Reward: 24.0\n",
      "Step 1129 (884126) @ Episode 1938/10000, loss: 0.0070913312956690796\n",
      "Episode Reward: 41.0\n",
      "Step 663 (884789) @ Episode 1939/10000, loss: 0.0093047339469194415\n",
      "Episode Reward: 14.0\n",
      "Step 710 (885499) @ Episode 1940/10000, loss: 0.0084486333653330842\n",
      "Episode Reward: 12.0\n",
      "Step 1130 (886629) @ Episode 1941/10000, loss: 0.0066033601760864265\n",
      "Episode Reward: 26.0\n",
      "Step 1270 (887899) @ Episode 1942/10000, loss: 0.0079543069005012515\n",
      "Episode Reward: 40.0\n",
      "Step 990 (888889) @ Episode 1943/10000, loss: 0.0034293949138373137\n",
      "Episode Reward: 19.0\n",
      "Step 878 (889767) @ Episode 1944/10000, loss: 0.0030016254168003798\n",
      "Episode Reward: 19.0\n",
      "Step 232 (889999) @ Episode 1945/10000, loss: 0.0095917824655771267\n",
      "Copied model parameters to target network.\n",
      "Step 782 (890549) @ Episode 1945/10000, loss: 0.0046395128592848785\n",
      "Episode Reward: 13.0\n",
      "Step 1402 (891951) @ Episode 1946/10000, loss: 0.0068168207071721553\n",
      "Episode Reward: 38.0\n",
      "Step 943 (892894) @ Episode 1947/10000, loss: 0.0293144937604665764\n",
      "Episode Reward: 17.0\n",
      "Step 1918 (894812) @ Episode 1948/10000, loss: 0.0075148283503949644\n",
      "Episode Reward: 56.0\n",
      "Step 1178 (895990) @ Episode 1949/10000, loss: 0.0046437098644673825\n",
      "Episode Reward: 33.0\n",
      "Step 672 (896662) @ Episode 1950/10000, loss: 0.0065005556680262094\n",
      "Episode Reward: 11.0\n",
      "Step 95 (896757) @ Episode 1951/10000, loss: 0.0017440591473132372"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-85e8d1e8d7c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m                                     \u001b[0mepsilon_decay_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                                     \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                                     batch_size=40):\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_rewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEpisode Reward: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_rewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/secondary_experience_replay/SER.py\u001b[0m in \u001b[0;36mdeep_q_learning\u001b[0;34m(sess, env, q_estimator, target_estimator, state_processor, num_episodes, experiment_dir, replay_memory_size, replay_memory_init_size, update_target_estimator_every, discount_factor, epsilon_start, epsilon_end, epsilon_decay_steps, batch_size, record_video_every)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Perform gradient descent update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mstates_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/secondary_experience_replay/SER.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, sess, s, a, y)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_pl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_pl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         summaries, global_step, _, loss = sess.run(\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m             feed_dict)\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_writer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/exp37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import psutil\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from SER import StateProcessor, Estimator, ModelParametersCopier, make_epsilon_greedy_policy, deep_q_learning\n",
    "\n",
    "from reinforcementlearning.lib import plotting\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "env = gym.envs.make(\"Breakout-v0\")\n",
    "\n",
    "VALID_ACTIONS = [0, 1, 2, 3]\n",
    "\n",
    "# training\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Where we save our checkpoints and graphs\n",
    "experiment_dir = os.path.abspath(\"./experiments_ser/{}\".format(env.spec.id))\n",
    "\n",
    "# Create a glboal step variable\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "# Create estimators\n",
    "q_estimator = Estimator(scope=\"q_estimator\", summaries_dir=experiment_dir)\n",
    "target_estimator = Estimator(scope=\"target_q\")\n",
    "\n",
    "# State processor\n",
    "state_processor = StateProcessor()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Run it!\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for t, stats in deep_q_learning(sess,\n",
    "                                    env,\n",
    "                                    q_estimator=q_estimator,\n",
    "                                    target_estimator=target_estimator,\n",
    "                                    state_processor=state_processor,\n",
    "                                    experiment_dir=experiment_dir,\n",
    "                                    num_episodes=10000,\n",
    "                                    replay_memory_size=500000,\n",
    "                                    replay_memory_init_size=50000,\n",
    "                                    update_target_estimator_every=10000,\n",
    "                                    epsilon_start=1.0,\n",
    "                                    epsilon_end=0.1,\n",
    "                                    epsilon_decay_steps=500000,\n",
    "                                    discount_factor=0.99,\n",
    "                                    batch_size=40,\n",
    "                                    ser_coef=64):\n",
    "        results.append(stats.episode_rewards[-1])\n",
    "        print(\"\\nEpisode Reward: {}\".format(stats.episode_rewards[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD4CAYAAAD4k815AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2deXhU1fnHPyf7QkICCWuAhE0W2UGLLCKiolI3rKC0ilq1tq6tVvzVBa22Wte6VEtdgIqguBRFZRUFBUFAQCBAAgRICEkISxLIMsv5/TFLZpLZk8xMwvt5Hh7unHvuPe/cmXzvO+99z3uU1hpBEASh5RARagMEQRCExkWEXRAEoYUhwi4IgtDCEGEXBEFoYYiwC4IgtDCigjlYWlqazszMDOaQgiAIzZ5NmzYd1Vqn+9o/qMKemZnJxo0bgzmkIAhCs0cpdcCf/hKKEQRBaGGIsAuCILQwRNgFQRBaGEGNsbvCYDCQn59PVVVVqE0RAiQuLo6MjAyio6NDbYogCISBsOfn55OUlERmZiZKqVCbI/iJ1prS0lLy8/PJysoKtTmCIBAGoZiqqiratm0rot5MUUrRtm1b+cUlCGFEyIUdEFFv5sjnJwjhRVgIuyAIgjvyjp7iu5yjoTajWSHCDjz99NP079+fgQMHMnjwYNavXw/AuHHjOOussxg8eDCDBw/m2muvBWDmzJl07tyZwYMH069fP+bPn+/yvL72a2q++eYbJk2aFJKxBaGhjHv+G3799vpQm9GsCPnD01Czbt06Fi9ezObNm4mNjeXo0aPU1NTY98+bN4/hw4fXO+7+++/ngQceICcnh2HDhnHttde6zArxtV9jYjKZiIyMbNIxBEEIX854j72wsJC0tDRiY2MBSEtLo1OnTj4f36tXLxISEjh+/Lhf/Z577jlGjBjBwIEDefzxx+1tr7zyCmC5IYwfPx6Ar7/+mmnTpgFw5513Mnz4cPr3728/DizlGh566CGGDh3KwoULWbJkCX369GHo0KF88sknPr8fQRCaP2HlsT/x+Q52Hi5r1HP265TM47/s73b/xRdfzJNPPknv3r2ZMGECU6ZM4fzzz7fvnzZtGvHx8QBcdNFFPPfcc07Hb968mV69etGuXTuPdjj2W7ZsGTk5OWzYsAGtNVdccQWrV69mzJgxvPDCC9xzzz1s3LiR6upqDAYDa9asYezYsYAlbNSmTRtMJhMXXngh27ZtY+DAgQC0bduWzZs3U1VVRa9evfj666/p2bMnU6ZMCejaCYLQcG6fu5FNB46z6dGLgjbmGe+xt2rVik2bNjFr1izS09OZMmUKs2fPtu+fN28eW7ZsYcuWLU6i/tJLL9G/f3/OPfdc/vKXv7g9v6t+y5YtY9myZQwZMoShQ4eya9cue6hm06ZNlJWVERsby8iRI9m4cSNr1qxhzJgxAHz44YcMHTqUIUOGsGPHDnbu3Gkfyybgu3btIisri169eqGU4te//nVjXjJBEPxg2c4iSk/VeO/YiISVx+7Js25KIiMjGTduHOPGjWPAgAHMmTOH6dOnezzGFjv/7LPPuPXWW9m7dy9xcXE+9dNa8/DDD3PHHXfU65+VlcXs2bM577zzGDhwIKtWrSI3N5e+ffuyf/9+nn/+eX788UdSU1OZPn26U/54YmJig6+FIAjNnzPeY9+9ezc5OTn211u2bKFbt24+H3/FFVcwfPhw5syZ43O/Sy65hHfeeYeKigoACgoKKC4uBmDMmDE8//zzjB07ljFjxvDmm28yZMgQlFKUlZWRmJhI69atKSoq4quvvnI5Vp8+fcjLy2Pv3r0AIcvGEYQzlS9/LiS3uCJk44eVxx4KKioquPvuuzlx4gRRUVH07NmTWbNm2fc7xtjT0tJYsWJFvXM89thj3HDDDdx2221ERLi/V9r6ZWdnk52dzciRIwFLOOi9996jXbt2jBkzhqeffpqRI0eSmJhIXFycPQwzaNAghgwZQp8+fejSpQujRo1yOU5cXByzZs3i8ssvJyEhgTFjxlBeXh7wNRIEwT9+P28zAHnPXB6S8ZXWOmiDDR8+XNddaCM7O5u+ffsGzQahaZDPUWgqMmd8AYROJAPB0ebGsF8ptUlrXT/v2g1nfChGEISWh9aaYDqt4YYIuyAILY6sh7/kgYXbQm1GyBBhFwShRfLx5vxQmxAyRNgFQRBaGCLsgiAILQwRdkEQhBaGCDtNW7ZXKUVubq697eWXX0YphWPa55YtW1BKsWTJErc2ZmZmMmDAAAYOHMj555/PgQMHGuOt+8306dP56KOPQjK2IAi+ccYLu2PZ3m3btrFixQq6dOli3+9YK8ZR0O6//362bNnCokWLuOOOOzAYDC7PP2DAABYsWGB/vXDhQvr3dy6dMH/+fEaPHu11huiqVavYtm0b48aN46mnngrk7fqF0Whs8jEEwRM1RnOoTWgQoUq5POOFvanL9l511VUsWrQIgL1799K6dWvS0tLs+7XWLFy4kNmzZ7N8+XKf1g4dOXIkBQUFAJSUlDB58mRGjBjBiBEj+P777wHLDeXEiRNorWnbti1z584F4MYbb2T58uXk5eUxZswYhg4dytChQ1m7di1gWZRjzJgxXHHFFfTr1w+tNXfddRdnnXUWEyZMsJc+EIRgMO65VaE2oUEs+PFQSMYNr5ICm+6D41sa95ypg2HYy253N3XZ3uTkZLp06cL27dtZtGgRU6ZM4d1337XvX7t2LVlZWfTo0YNx48bxxRdfMHnyZI9vacmSJVx11VUA3Hvvvdx///2MHj2agwcPcskll5Cdnc2oUaP4/vvv6datG927d2fNmjXceOONrFu3jjfeeAOlFMuXLycuLo6cnByuv/56e3ho8+bNbN++naysLD755BN2797Nzp07KSoqol+/ftxyyy0e7ROExuLwyea9SPrK7NA4QuEl7CHAVrZ3zZo1rFq1iilTpvDMM8/Yqzu6W0HppZde4t1332XPnj18/vnnHseYOnUqCxYsYOnSpaxcudJJ2OfPn8/UqVPt/ebOnetW2C+44AKOHTtGq1at+Otf/wrAihUrnEr3lpWVUVFRwZgxY1i9ejXdunXjzjvvZNasWRQUFJCamkpiYiInT57krrvuYsuWLURGRrJnzx77Oc455xyysrIAWL16Nddffz2RkZF06tTJvviHIAjhS3gJuwfPuilpyrK9AJMmTeLBBx9k+PDhJCcn29tNJhMff/wxixYt4umnn0ZrTWlpKeXl5SQlJdU7z6pVq0hJSWHatGk8/vjjvPjii5jNZn744Yd6Y48dO5bXX3+dgwcP8vTTT/Ppp5/y0Ucf2QuKvfTSS7Rv356tW7diNpudjpfyv4LgH1prXli2h8nDMshKC/3fj08xdqVUnlLqZ6XUFqXURmtbG6XUcqVUjvX/1KY1tWkIRtnehIQEnn322XoLcqxcuZKBAwdy6NAh8vLyOHDgAJMnT+bTTz91e66oqChefvll5s6dy7Fjx7j44ot59dVXnewH6NKlC0ePHiUnJ4fu3bszevRoezlggJMnT9KxY0ciIiL473//i8lkcjne2LFj+eCDDzCZTBQWFrJqVfOOeQpCU3D4ZBWvrcpl+rsbQm0K4N/D0wu01oMdKozNAFZqrXsBK62vmx0VFRXcdNNN9OvXj4EDB7Jz505mzpxp3z9t2jR7uuOECRNcnuOxxx6ze8/umDp1KkOHDnVqmz9/PldffbVT2+TJk71mx3Ts2JHrr7+e119/nVdeeYWNGzcycOBA+vXrx5tvvmnvd+6559K7d2/AUue9oKCA0aNHA/D73/+eOXPmMGjQIHbt2uXWS7/66qvp1asX/fr148Ybb7SXGhYEoRZb9ovRFB6Fx3wq26uUygOGa62POrTtBsZprQuVUh2Bb7TWZ3k6j5TtbbnI5yg0BbaSt+Bf2dtgl/rNP36a0c+uonNKPN/PGG8ff0LfdqywPkANx7K9GlimlNqklLrd2tZea11o3T4CtPfDTkEQBKGJ8PXh6WitdYFSqh2wXCm1y3Gn1lorpVy6/tYbwe0AXbt2bZCxgiAI4Ui4lX73yWPXWhdY/y8GPgXOAYqsIRis/7tM2NRaz9JaD9daD09PT3d3/gBMF8IF+fwEIbzwKuxKqUSlVJJtG7gY2A58Btxk7XYTsCgQA+Li4igtLRVxaKbYUjTdpXoKQkuhrMrA3fN/4uRp1+VDwglfQjHtgU+VUrb+72utlyilfgQ+VErdChwArgvEgIyMDPLz8ykpKQnkcCEMiIuLIyMjI9RmCEKTMvv7PD7fepjMtgn86WKPeSIhx6uwa633AYNctJcCFzbUgOjoaPssR0EQhHCnOQQXzvgiYIIgCL6gQm2AH4iwC4IgtDBE2AVBEFoYIuyCIAh+oAn/ILsIuyAIIeOZr3bx7vf7Azr2719mMzvAY5uKghOVvPNd6G0Kr7K9giCcUbz57V4Abh7lf2bcv1fvA2B6AMc2JU8u3um9UxMjHrsgCIIPqADSYkKVGinCLgiC4IXi8irySk8DzSOPXUIxgiAIXjjn6ZWhNsEvxGMXBEFoYYiwC4Ig+EEziMSIsAuCIDSUTQeOh9oEJ0TYBUEQGshzS3eH2gQnRNgFQRBaGCLsgiA0e7TWrMwuwmxuDhHwpkeEXRCEZs9nWw9z65yNzF2XF2pTwgIRdkEQmj1HTlYBcNj6f1PSHCYoibALgtDsaQZaG1RE2AVBEFoYIuyCIAh+4E899lD9khBhFwShxdCc1iVtSkTYBUEIOd/nHg21CT5TWWPi862HQ22GR0TYBUEIOdPeWh9qE3xm7roD3D3/J7YcOhFqU9wiwi4IghAAp6qNoTbBLSLsgiAILQxZaEMQhLDiQOkpzn/uGy7q197nY8J10tDXu4pDMq7PHrtSKlIp9ZNSarH1dZZSar1SKlcp9YFSKqbpzBQE4Uxh3d5SAJbvLAroeB2uKh9E/AnF3AtkO7x+FnhJa90TOA7c2piGCYIgCIHhk7ArpTKAy4G3rK8VMB74yNplDnBVUxgoCILgM0FMZD9aUR28wfzEV4/9ZeDPgNn6ui1wQmtteyycD3R2daBS6nal1Eal1MaSkpIGGSsIghAu3LtgS6hNcItXYVdKTQKKtdabAhlAaz1Laz1caz08PT09kFMIgnAG0dAIuYTYfcuKGQVcoZS6DIgDkoF/AilKqSir154BFDSdmYIgCO7xp37LmYBXj11r/bDWOkNrnQlMBb7WWk8DVgHXWrvdBCxqMisFQRAEn2nIBKWHgD8qpXKxxNzfbhyTBEEQAkd8dz8nKGmtvwG+sW7vA85pfJMEQRACQ0l9R0BmngqC0MIIZqXItXuPUm0wh92kKBF2QRBaFDe+syFoY93wH0tVyk6t44I2pi9IETBBEMKKQJzfUDvM4eWvi7ALghAiwiF8YTSZqTGa67VrrakymEJgUeMgwi4IQkh4afmeJh9jT1G5x/3XvLGW3o98Va/9rTX76fPoEorLq3wap/Ckb/2ChQi7IAgh4ePNjT+nUdVJiskuLPPYf1v+SZfti7dZlr47fCK8BNtXRNgFQQgJdUXYRljMIrUaZw6DcFEgiLALghAS3Am7O/7+ZTZGU/14uCe0hhqjmacW76SsyuC0z2x2L9oRVts+2ZzPdznNZ6FtGyLsgiCEhAg/lf3fq/cFtCLRpz/l89Z3+3l+6W6n9q357hejtln23g8H+fXbzWehbRsi7IIghIS6sm7LkvEU/Thd43+mitHqmRtMzif24LD7fdMJN0TYBUEICaqOePoSzvY3BTHQeH0z13URdkEQQkM9j92HYxozt9yTeNe96TQ3RNgFQQgNAWhnlYvJRJ7w9CvA077mLesi7IIghAi3MXYPx1R6ibE3liBLjF0QBMEPsgvLePqLnfXCHU9/me21zICrUMwDC7dSUW100dsznrQ7LHLpG4BUdxQEIahMnfUDJysNtEuKdWp/9/s87pvQ2+OxJhepLB9tyicuunF91NziikY9X7ARj10QhKBi88pdhTuUwmPwOyIiOCGSZjrh1I547IIgBBWbZrrSaG+Cajvk2Kkan8aqqDZytMJ1X6PJ/WCmZq7sIuyCIISEQFIKbccM/etyn/o/tmiH231PLna/z1O5gUDRWgctjVJCMYIghIRANM7bMf6cc3uB+8qPzdtfF2EXBCFEuK/u6J4ghdibJMYezOiOCLsgCCFBBZB1Hqz88qYo1xvMXwEi7IIghISAQjGNb4ZLmvmzUxF2QRCCjFU0XXrf3gTVzd2gsYW4STz2IN4tRNgFQQgJgXjfa3OPUlRWf7k6X73/3UfKOV3jfpbq/qOnOH6qRjx2QRCEgAhA2TceOM65f1tZr90mxJ7i9gaTmUteXs3v3tvsts8Fz3/DhBe/ZVi3VP+N80JYxdiVUnFKqQ1Kqa1KqR1KqSes7VlKqfVKqVyl1AdKqZimN1cQhJZCsMts2XLT1+8r9div9FQN53ZvEwyTmgxfPPZqYLzWehAwGJiolPoF8Czwkta6J3AcuLXpzBQEoaXharKORjf7MIg7wirdUVuwVcSJtv7TwHjgI2v7HOCqJrFQEIQWwZLthVzzr+/tIQlXHnug4me7R7y2KtdtH8dT/+rNtYEN1EzwqaSAUioS2AT0BF4H9gIntNa2pxD5QGc3x94O3A7QtWvXhtorCEIz5ffzNmPWEB8d6bZPoE6tLzcEx6yUH/OOBzhS4ASzFLBPD0+11iat9WAgAzgH6OPrAFrrWVrr4Vrr4enp6QGaKQhCcyfSOm3UVnrXlcw1ZUpgC43wuMSvrBit9QlgFTASSFFK2Tz+DKCgkW0TBKEZsbekggOlp9zut+WtG8yW5e1c1Tz/fm9pk4m7ra6Xy/T5IATAwyrGrpRKV0qlWLfjgYuAbCwCf621203AoqYyUhCE8OfCF77l/Oe+cbvfJuyeBO6e+T+RXVjeyJZhHVe7Hb9u2+dbDzeJDcHClxh7R2CONc4eAXyotV6slNoJLFBKPQX8BLzdhHYKgtDMifSxglfpqWqP+7vGFBKnqtlTnWlv88UZ9tSn7r4jJ+tPgmpOeBV2rfU2YIiL9n1Y4u2CIAhe8bUyY42HBTAAVve5DYDMbYvtbb6c2lO4xbKveS9g7YjMPBUEoVFxNeUfICrSN7kxmsxu9/0icZt9O5L6C1t7wlMI6La5G51en6rx79wNHb+xEWEXBKFRWbv3qMt2X0vuelqyblbmU/btjJgi+7Yvmmkr7OWq76rdJT7Z1lwQYRcEoVGJj3Yd4fXRYbdnzdQlKeIUyZGn7a+7x/qXiBeqGa1JEac4Oz43/PLYBUEQfCU+xvUEpMgGeOwxysDPZ08B4A8HHgLg3awnuKz1dwDUGN2Hb2zY0h196duYvNbtWRb3ug9MlUEbU4RdEIRGJTbKtaz4upCzwSHGnhhxmryBk3i68+v2tu8rBrHhVD8A/tXtGT8sC43LPjh+t2WjPCdoY4qwC4LQqLiLpftaM93xBtAz9hAAv2qzAoCrc5/nhCmZF4/82t6nh7WPN8wh0PVoZeDnyp4A6KS+QRtXhF0QhEbFXVqhr8LuePzzXV522rfldG8ANpzqb2+b0mZZg+xqKrrH5pMz4GpGJ23lYHV7dER00MYWYRcEocnYsP8YmTO+4NCx0947W9l1pHbmaZW5dpmHN4qvRVsly0wkZ2//EICjxhSfzhvszJdesQft2zERhqCOLcIuCEKT8eFGS5hk3d5Sj6sbuSJaGRiQsBeASTkv8+yR6U77K8wJADzYYW7DDW0C4iNqZ9D+q/hXsuapIAgtg4bM5Ryf9KN9e7s1Tu2KaGXil62/bcBIFhpbeCelrAbgzeLJLDx2UaOe2xsi7IIghCWJEZb0wApTvNs+U/f+DYBxSZsaPF7+8cZLR4xWBiYkW25Mzxy5mUodF15rngqCIDQGvj48tXFN6tcATNzzmts+P5wayIHqDsQ2Qgz7yte/b/A5bHSKtsTzPzp2YaOd0x9E2AVBaHI02u+wzOikrQDkG9p77NcppoRJKWvoFF0coHUWjp2q8blvcmQFyZH168nb6BZTCMDC4xPsbVIrRhCEFoHNS/dX1NpHWerNvFk82WvfvxfeAsCIxB3+DdIAtvS7nm39p7rc91CH2bza9R9UmWPYXtkjaDY5IsIuCEKD6f7wFy7bPtyYD8C73+eRV+p7yuOt6ZZ1exzz1d2x8JjFK860esnBIELV3qk6RRejMHNWXB4PtJ/Lne0+onXUKdZVDOCUNXMHCOrEV58WsxYEQfCEq1mdjm27i/xbFSk9yrLY9NflI7z2LTcnsL2yBxNbr+WfxTf4NU4gtIqovUHlDZwEQIkhhfToE079EiOdH8ZKETBBEM5gNAPic/m6bDi+JUwq9lV3pm98Ht1j8wMe1ZeFQOZkPcb2s6+r115X1AFilDFgWxqKCLsgCGFFWtQJesbls+HU2T4fU2psDeBULMxfvNWSSYo4xflJm30+36Lj5zu9loengiA0WxqqX/3j9gGwq6qbz8f89fBvya7MpFfcQSL8XFnJV+5pP9/pde+fP2VN+WCePHybU/v7pRPp8/NHvFt6RZPY4Qsi7IIghA3943OZ0/1xAA5Ud/L5ODORvHv0CtKiTtI5poQpbZbyYY8/kxjh+wNbb9yW/j8ALt3zCiOz36VGR/Ob/U/xztEr7X2uzX2WRwvupErHUTeMFMwJSvLwVBCERkXrwKfn35n+kX0739DOr2Pzaiw3gsc6/oeLWq8H4KqUb5h37DJGtdrCttO9KDcnBmTX2fG59u3sqizqivb7pZeQEFHFxtPes3iCgQi7IAiNyqOLtvPlPWP8Pi45soJJKZYVkf6S/3sM2r8yt/utHr5N1AGU0nSLOcy87o/Y24oNqYzMno0J1ys9uWJxr/sAuOvAn3H1QPf/Cu72eg4pAiYIQrMlt7jCvnC0P9yR/jEAs0quZt6xy/w+vsSYWq8tNbKMb/vc7tTWLvo4N6ct8nq+rJgCutbJjf+2fJjfdoUCEXZBEEJO99h8/tBuIQAvFwWai64YsmMeAF+cGAXAnzrMc9nzkU7veDxTFEZW9bmD1X1uI1oZMOkIXi2aEnAoB4IbYxdhFwTBL7YXnOS/6/LYdaSMd77b77LPun2lfp3zjW6WKo1bT/fitNl9NUdvHDe1pv/2D7n34INO7YtPjGbIjnn03PY/e1tGdJHb85wdv9e+nTPgaiKV2ecFPcIBr8KulOqilFqllNqplNqhlLrX2t5GKbVcKZVj/b/+7yBBEFock179jkcX7eDSf67hycU7Xfa5+d0fXba7RnNWnGW1oStzX2ywfafMCRiJ4sFD9wBw3JjEXQdncNzUGiNR/P7ADAAyYopw50ef2+rnem0ry7zPgvVEuOWxG4E/aa37Ab8A/qCU6gfMAFZqrXsBK62vBUE4Q2gsoepv9Y7/U3IVDVuaw5mFxy8mc9tihux0zj8/VGOpFjk8cSd5A39J3sBJfHvWb+37hyZk83DH2U7HvF86kXxDh0azranxmhWjtS4ECq3b5UqpbKAzcCUwztptDvAN8FCTWCkIQlCoNpowmDStYoOXMNfDWgbAVsyrqTlhSgLggQ7v2du6xR6hfdRRqnWMPeXycE0a1+79B2fH72VZ2cgGjxvMWjF+fXpKqUxgCLAeaG8VfYAjgOeiyYIghD3XvbmOrfknyXvmcpf7dx4uq9fW0DS+DtGWeHyhIb1B5/GVQzUd2FHZnf7x+5za1/eb7vT6vF2zATjsZz59OODzw1OlVCvgY+A+rbXTp6stn6zLT1cpdbtSaqNSamNJSXBXCRcEwT+25p/0uD+nuH6VxoaGZNpHHeOUKY5yxxK3blj94AUNG8zK+6UTAfj42HiG7Xiv3v5Kc2yjjONEmMXYUUpFYxH1eVrrT6zNRUqpjtb9HQGXy5dorWdprYdrrYenpwfnjiwIQvAIJGfdkfbRpRwxtsWX+HrXtt7F3xfmHbuUcbv+zZ/y/0ipKYWJe16179t6upc9bbK54jUUo5RSwNtAttba8ZH1Z8BNwDPW/71n/AuC0OJoiKz3js1jUsp35FZlNJY5PqLIq+lsf7WrKot+2xfSJrLM61J8gRJueeyjgN8A45VSW6z/LsMi6BcppXKACdbXgiCcYTTEY1921l2AZTZoqDltjm+wqHdIjrNv3zjS9+qUjY0vWTHf4f43UmiW4BYEISQoVV8KGiPt8bI9rzT8JGHAhH7teO8HS07+3eN7MXfdAfu+YOaxSxEwQRB8xpWHF6hgJUdUYNCRvFVydZOFP4JNhIsbXyiQkgKCIDQIU4DKPibpJ6KVidXlQxrZotDhSdhlzVNBEMISV7pl8ramnBtGtdoKwLbKXg0xKaxwvD6hdN5F2AVB8BnlIhhjDkDYu8YUckPbJYCltktLIdKTxx5ueeyCILQsVu8p4fFF2xvlXEY/hT1OVbGg+8MAvFd6aaPYEC5ERNQKeyij7SLsgnAGcuM7G5jjkLHhK64cUqPZ7Nc5bkpbTKeYo6wpH8wjBX/w24ZwxpOYh1seuyAIAuBauKoN/gn7uKRNAPzhYMsrCOsqHTQUiLALglCP0opqKmtM5BZX2NsOlp7mZKWhXt8ak2/CfnnrNeQNnMTIVj9j0JGUmVo1mr3hQoTTw1NnkQ/mmqeSxy4IQj2GPbWCcWel883uEnKevpToyAjGPrfKZd8ao3dh7xl7kNe7PWt/fXveIx56w4V92rFyl8vyU2FNZIR47IIghDHf5x4FvJcMqDaaPO5vF1XK451m2V9nbvucVeX1VyNa9cA4AGKjInjrpuF+WhseOHrpdSVeZp4KghBybELkKsXRkWovHvuCHg/TPfYwAL1//hR3jxhjoyx+ZmpCTNjEqv0lTBx2EXZBEDzT+5GvPE628RSKaR1Zbhf178oHUaOjvY6XFNd8Zclx5mko703N9woKgtBgtNZuvWPt1M/9OTwJu20907dKruSVous92tKxdRwPTezDLwd1BODfvxlGfHQkN76zweNx4YQnj11CMYIgBAWt3XuWvmZxGEzu+12Y9CMAs0quoczsOQtGKcWd43rYX1/SP3wWj76oX3uW7yzy2i8iTGIx8vBUEM5gGsOJdDdBqTNNvE0AACAASURBVF/cPm5NX8RpcyzFxjaNMFL44/g8ou6zCSkCJghCUPCU8eKrDLny2KMw8mXvewD448E/EtoJ9oEzoHNrv/o7OexSBEwQhFDgKdria0zY4DBB6ZLktSzqeT8vd33B3rak7DwAnp08ICAbQ8lnd41i398u81mjHR+exkQ6y6vE2AVBCAoNXYgawGgXds2/M/8GwKCEHABG7JyLzXWNinDvR4ZrdqNSyi/bHPtGR4buTYnHLghnMI66vnbv0YDOUWMNxVyQtNHetrzsHHpu+x8lDrF1D7pORmp8QGOHE20SY5xmntadhRrMImDisQvCGYzjA72Xlu/x+/hYVW332LvH5gMweMf7nDAl1+vr+DAxOS6Ksiqj/fUHt490O8a/pg2lotpIWqsYn+269OwOREVG8PnWwz4f4w//uHYgPx08wfwNlvVN7xzXg+tHdGXV7toyCKGcZCUeuyCcwTiWUo+LjvTr2LvaLWD3gMlMKp5Kp+hibmz7BWWmBJeiDs5hiltHd3fa1ynFvcd+2YCOXDe8C+P7OK+LmpLgfrLTtHO7cf+ExluZqa5GXze8C9PO7Wp//dDEPnRtm+Alj12yYgRBaCQqa0yszLbkYOcWl7PrSJl9n6PY+CPsEZh4oMN7AHQ2bGRt31voFnuEclOi22OC6cEGug5rQwmXUggi7ILQwvm/T3/m1jkbySkqZ8KLq5n48hr7PkePPSbKNzmIxMR73R8FYGdlFvk16fZ9bx+9yu1x7rzZZD9LCFxwlmU8T9p9Vvskv84ZCK403NVi1rYaOBJjFwSh0dh1pBxwUzfdQW189TUf7zSL81ptw6QjuCLnJaKVkbFJm1ledi5m3Hv9rkQPYNvMS3wc2cIjk/qxave3DuetvUF1aRPPmj+PB2BvSYXTcfv/fhlKKTJnfOHXeN7o06H2JlL35pX3zOUs2lLAvQu2NOqY3hBhF4QWTrXBUlY3Nqq+6PqT7nhZ6+8YkbiDG9Mswjhxz6sYicKoo1hqzVX3hKPoNWQWZt3bg1LK7r57qkTZ2GESV2O5u3mBLGYtCGcsmw4cI3PGF+QfP91o56yyCrurUMiQvy4nc8YXmMyaxdsK3Z4jAhP/6vYMN6d9DsDdBx4kp7qbn5Y0rrBqu5jX0iklzr4d62NoyRfaJcV57wQkx9d/oBuKuLvXd66UekcpVayU2u7Q1kYptVwplWP9P7VpzRSEM4P5Gw4BsHZvaaOd0xam8OSdG7wsbze1zTL79g8VZ/P5yfP9tqOuvq16YBxzbjnH7/N4Ou8b04bZtzNSE3jl+iF8ec8YZv2mtn3JfWM8nm/2zfUXAfm/y/rWa7PlqTte10v6t6/Xr1e7Vtx1QU9SPWTxNDa+hGJmA68Bcx3aZgArtdbPKKVmWF8/1PjmCYLQWJg9hAKMnnaiuSVtEbtrenLJrpcI1POue1/JSkskK819Fo07bB6wK4tTE51z3a8Y1AmAfp1qUzD7dHCdjmlj3Fnt6rXFx0TSv1MyOw7XZhRFWWeWGh1q5bjyzvt2TKZvR89jNjZePXat9WrgWJ3mK4E51u05gPtH4YIghAUmD+L954+2ut13dvxeesbl80n5lTQsnFI7fmPGm72t8NRo49QZJsrqsRvcVLcMJYEGodprrW0BuSNA/d8fVpRStyulNiqlNpaUlAQ4nCAIgWITJE+hmC9/PuJmj+a/WZbUxm9Oj2qQHfExjZOr0SHZEu++98LAJyD1t3rwCTHOD5SvGdrZ7TG/H9fT6XW0tciX0UM9+lDR4KcL2vIEw+0701rP0loP11oPT09Pd9dNEARHmkArAnEsZ2fOJDWqnE2n+lBm9i2ckPfM5Vw1uFO99ugI1SAxthEfE0neM5dz9RCrCAfgsH9xzxjynrmcTY9c5NT+4nWD3R5z2YCOTq9toRhPC42EikCFvUgp1RHA+n+xl/6CIPhAUwYV/K3keH/79xiXvAmAG/b9za/wiauu2sv+QAnVXM9oa1UzdwuNhJJAhf0z4Cbr9k3AosYxRwhHMmd8wbNLdoXaDMELd8//iX6PLXFqy5zxBYUnqwD/ptlPTl3Jve0XADA6+22qdYxfNwZ3XdtbwyjtkmJ9Ppc7oq3pjD3beV5yr6mIjbaM3z2AB8BNjdegl1JqPjAOSFNK5QOPA88AHyqlbgUOANc1pZFC6Hnjm708NLFPqM0QPOCtkqHZY+ZLLUkRp3ihy0sAjN31H/INlkdoLmeuuhvLQdnTk2IpKa9GAVNHdCElIZqJjbCeaXJcNHNvOYde7Vsx8u9fB3SOhqSYJ8RE8d9bz+HsTs6rLK3441hqjKENz3gVdq21u6XFL2xkWwRBaEJ81HWus+asLz4xmoM1tXHlaoPvwu7osfdMb0VJeTVgWey5bqy6IYztnU5ljanRzucvY3rVf27Ys13T16nxhsw8DRMMJjP/Wb2PGmP4xeuE8OWHfaWs31d/MpPJrPnP6n1Obdf9e53X8ynMTE9bzPqK/tx1cIbzPj+8W0ePPZiLOAsWRNjDhPd+OMDTX2bz1nf7vHcOIsGsIS34z9RZPzBl1g/12hdvO8zTX2b7fb6JrdfSJaaID49fXG/fY5P6eT3+nEzLikm3j62tt37vhb1Jio3i7Az/Fob2lYaEU2IiI+jYOo6stERGZHqfQH/fhF729xjOSBGwMOFUtWU1mQqHVWXCAdH10NBQL9dWH8bfUV/r+g8ARoy+mY8/P+i0d+o5XZnxyc/21zFREfV+YX74O8tKSEO61orkyB5t+fkJ/yo4BouICMW6h32PKt83oTf3TWhCgxoJ8djDhHAp0F8X0fXg4vg1MJu1y19MZrP2+CDUZNYB3ZBHtdpKpDKTV90RY6T3nPUoT8sFCSFFhD3MCDchbYxV7IXA6P3IV1z+ynf12s9/fhWDn1zm1FZaUW3f7vF/Xzp51r4QrQzM6/4IANP2PU3H1t6rGY7s3tbj/s4elrtrTMLUJwopEooJM8JNR8PNnjMJo1mzs7CsXvuhY5X12gpO1G/zhdaR5byT+QTDEi3zFD48NoEnrr+MC/u6rRICwHu3nsuonm3p8+gSqt088P/87tEcDtAufwhWrZjmhHjsYUK4eh2S0RBcgnkjHZqQzdb+19tF/cUj0/hz/n1M6OdZ1AFG90pDKcVtY7q77dMmMYazOzfNA1PBMyLsIWTuujxyi8ud2o6dqublFXs8xlDfWrOPW2f/iNGPCSMA2wtOsmDDQe8dHXAUmoOljbf4Q0tmxc4ivt3jW8G7GqOZ55fu5vCJSl5cvsc+O9SdF+r4mb/7/X77tr83hOltP+OTng8CMKvkagZuX8Arxe6mrLgnHG784eoUhRIJxYSQxxbtIC46gl1/vdT+h/zhxnzAkjZ2Xs80l8c99YUlje3zbYe5ekiGz+NNetUSr516Tlefj3EUjF+/vZ7Vf77A52PPVH47dyNgKYbljY825fPaqlxeW5ULWLxccC+YnznMLn3i8532bX+ehbSKOM2v234JwK9yn+HH02d7Pebu8T1dtvs66am5cf+E3pyorAm1GQEjwh4ibNkOVW5m83le+MCCIQjTlh0Fo7zK0OTjnWmY6hSQqvaSpuju++INhZkYZaBNVBnr+t4MwCtFUzyK+i8HdeLzrYf559TBXDnYdTnbcHi4bnPYG9Nzv3dCw6tQhpJmIeyHjp3GaNb1VlsxmTWna4wkxUVTVmUgKTbK77RBs1lzynqOYGAyayoNJhKiI+u0e/+Dtb1HG6dqfM95t+XJ+4vjn60/3pnRZKbaaMZo1rR2sQ5kQzhZaWi0c1YbTWgNcdH1F3puLE5WGlDKUtukLpERztFQWyim7gPJaqMJs9l9Ia9jpzx5l5q3M59kfPJGe8vuqq78s+gGj3b7MjktDHTdjkRkamkWMfZHF23n3gU/1Wt/6oudDJi5jH0lFQycuYy31ux3cbRn/rF0NwNmLqMsSN7oo4u2c/bjS+sVVHp+2R6PxxWcqGTgzGW8/V3te3T8Ke6N/o8vtW97WkmnLo4emT/e2e/nbab/40sZ9MQytuWf8Pk4b2w6cJxBTyxj6Q53C0P4x9h/rKLPo0u8dwyQnYfLGPTEMgbOXEZxeVW9/XVzwW2fzWOLdji1j3/+W/o+tsTts5db52x02Q4wptVPTqL+3JHfcMmef2HC882sv7W4VUZqbdpiTJ0FokNVWdERmzM3yk3o8kykWXjskUq5FKNPNhcAkFNcAcCynUe4baz7p/SusFXEK6s0uPSoGpuPrDF0b4sH1323+ccsDy6X7ShqsA0Gk5nICN88VEct98c7W7az1s4dh8sYmJHi+8EesN0k1u0t5ZJGqBBYVFbtvVMD2HWkNl2xuKy63mr3kXWE3V0IzpbO6G/oIyP6CK92/QcmHUHf7R9To33/jt8xtjtjeqU5Zbb88PCFTr/+fjUsgz4dkujQOs4vh6ExiYxQrPjjWDoFKW++OdAshD0iwrWwa3sGQTPCaqy/y2k15p+MwWT2OfTg+HNc6sb4j+MlcxUlrCvs3i6xr+I5OH43XWMLeS7jZWIjjDx1+Ba/RB0sf3d10xXbJMbYH/CCxVturJt2QwiHiorhRLMIxUQqRU5xBc8v3V1HaJz7/XTwBDe/u4H/rstzas8pKueFZbspqzLw2KLtrM09ynRrP9sfyn0LtvDLV7+z/9TdXnCS4U8tZ9xzq9iw37KW94c/HmJltsUT3XLoBG98sxeAA6Wn+PtX2fWEb9eRMl5a7hxisdXW+N17m+xtq12kxj371S77+Q4dO80fP9gC1J+I8s3uYuZ7SGHUWtdbJOPvX+3io035Tm2VNSYeW7Td6QFpZY2JRx1CAqdqTLy8wvn9aK15afke/vzRVjbm1V3zvNbGGqOZmZ/t8BILtlyL+RsOsmhLAYu2FPDYou2crKwfJnO81it2FvHOd/v5/bxNPPzJz36ngQLM/n4/c9flsW5v/UqJa3JKeO+HA26PLSqr4snPd2Iya4/9IqzK/tGmfC5/ZQ0b9h/jr4u9h9Me/mSbfdub8A9NyCZv4CT+1+tPvNL1eTQR/PHg/bx19Bqv4wgth2bisVs8lddW5XLTeZmkW1dfsX3HbT9PjWbNqt0lrNpdwm9GZtqPn/bWeorLqyk8WcVHm/KZu87yx/fN7lpB3XjgOAC7i8rp2zHZnhp4tKKGBz/ayrcPXsCfP7b8geU9czlXvf49AHeO68Hv521mx+EyJg/NoHf7Ws/hujfXUVZl5M5xPep5yOv314rgje9sqPeedxaWse/oKXqkt2LuujwOW1fBqSvs09/9EYDr3aQw5h+vtN+AbLy//iDvrz/ItcNqUyXnrT/A3HUHSIiJYsallgU1PvjxYL3FG15ekcMdY3sQb10EuNJg4p8rcwBLqqarFL+lO4pYsuMIs9fmUVZl8LiupKtrER0ZwaPWyoKufp3Z0gttXNinnU+TbBzDYTMdnlfUfQ+/edti069/0c3leR76eBvf7C5hfJ92PPK/7U77HL102/YDC7cCvpXRBZi/4ZB929MqSK0iTvOetSyAQUfyeMHvWHh8AgYvnvqDl5zFc0t3+2SL0DxoHsLu8NfhKsbozUGzxS3dTX12xNX5iz3EYbXWdq+/bnjFNl6gsUeb8Phid0Ox2ej4/iMjXf+gc8yx9nWRA9svoUCuhcswnIf+vo7QWDFh2+fubbJOY0x992TzXe0WkBBRzS37H+Pr8nN8Ot/153RhZA/PNV+E5kezEHbHOOSpaiM5ReUkxUVTYX2I4yqjpeBEJYkxkRw6Vmn/+b/LRd2NupRXGTl0zHmGZaXB5PTAaF9JhX3blr4IlvTD7QUn6dA6jr3FFfY/c4PJTHmVgROn/cu8OXKyivRWsew87N3ur3cVMbJ7GhXVRpSypL8ZTGaPsfy8o6cwa03bVrXrT5ZWWK5VjdFMmYsQCEBucQWdU+JpHR/NvqOn6u23rZbjiO0anXa4EdQYzZyorKn3QLEuRWVVHDtVQ1x0hD0Dwnb/Oe0i5XP9vlLG9Epz+pVUcKLSqShVbnEFsVGeI5GHT1TWK4ZVbTRxstJASnwMJ07X0C7Zve0Gk5kjZbWZMDnF5fRIb9j6mFsO1c8w6hF7iPvbz2NSyncsrbzMZ1EHZ6dJaDk0D2F3+PJd9+8fOFrhLBwPu6hkN+qZ+msg2rJnPDHVxaIFABe9+K19e/wLtdsGk+aAdar9r950/dO6xmTmvnlbWOsifusJW5jFF26ZXRuOyEiNJ/+49+JL457/xr79sDX88vHmfF64bhD/9+nP9eLwNq54zRKGuuP87vz72/oLg4x4ekW9NttntNwhW+aPH25h8bZC9v3tMiI8lID9avsRvtp+hKy0RG4elem0708fbq3X/63v9jN7bR65f7vMPuZtczfyzvThjO/TntM1RiY4fJ6u2FtSwYUvfMvgLrUPBo0mM/fM/4mlO4q4anAn/rflMDlPX+r2HL3+8pXT67ve/6nB6YGO1w/gvvbzuK/9fIw6glVlw/ix3QzAuyNgIzJCNcrC0kJ40Swenjr+0dcV9WBhi3HXxeDDxCKjSfst6g3BF1GvS13HzZc88dV7jvo9jiOLtxUCnuPGjux38evguxzXNjimDdpSJLcXWATvVLX38JGtKqGjh3zaYGKpNd10kfXZg+MvIl/eRq4PzoVrNCmRZQyIz+HxTv8mb+Ak8gZO4r728zlpTGRk9mxuznuCySMH1Tty7Yzxbs8aoRQZqQmskVIRLYpm57GHGwYf4t/ectbDgbqiFOMmvu7Ux0UoI5CUSJNZ4+vET9s3oSHFp3yJrbuKh5+uNqGU5VrZ3qYvN/ZA6RhdwshEywP7O9p9zFlx9bOf5pVO5MnDt1GtLV63q9BKp5R42ifHuszZt4U5u7RJaEzThRDTLITd08/0UOMqi6Mu5z/3TdMb4jcaxxyTv39VmxKZOeMLn86w1UW8N+vhL70e94f3NzPRYXLRf9cd4I1v93pNhQSc0i+9MfOzHTz+y368+rWlwNaLy/eQHBdFlZeb8ac/5XP/B/VDPL/4+8p6bQNn1i544ct3wTuaS5LX8cuUNUxKWeO0Z2dlFsWGNoxL3sTVuc/z0+k+Lo52fdNy5xzJKkgtk2Yh7N6cx47RJSg0pcYUxiT9RK/Yg6wqH05uVReMDm8xWhkw6CjqJs21jiyn2hxNlY512hevqqis01aLRRh3+PBgsy7JkRVclLye5IgKFp8cS42OYkaHd7m+rUUksiszuefgg7SJKqNd1DFSosrZU9WN/Jr2FBjSiVFG4iKquTplFe2ij5ERXYyJCNpHlbL5dF/eOnoVJ031J2xEYeTRTv/hpjSLcG861YeUyAqKjG34R+FNbKk8y+/3EghfbCvkC2sYBgho0WWbx+zJ9569No97LnQu5jTThzIMrkTdX6KVAZOOwEwkoMmKOcw5rbbTObqYk6YkPj1+AVenfs0DHd4jPsLiSZeZEkiOrH1wX26K5/1jl5JX3Yk15YPJN9SfaduvYzIje7Tl7e/2MyIzld7tkvjVsAwWWp+PPHPNAADm3HIOCzfl0y4plhXZRfzhgp58sa2QPzhUbXxj2lDKw2zNXSEwVDBnEw4fPlxv3Oi+poU7Hlu03Z57XpfO0cV83/cWl/uqzVFsPNWPAkM7rmtjeaB30pjI5tN9aBt1kmPG1nSMKXH6iXvU2BqFpsYcTceYUkw6gv3VnXiv9DJOmeMZk/QTV6Sstvd/8cg0opWRtlEniVU1zC29nB2VPYiJMDAgPpeLkn8gKfI080ovJS6ihvZRpTzb5RUSIpr2WcERQxt+Pt2Lr8tHcMocx4iEnfwmzdmb3luVQVZsARFK26/Ni0W/Zk7pJBxvZhOS1/Obtl9QbY5hadlI+sTtJynyNF+XjWBnZXeilZHjpiROmBzXydREKyMD4nOp0dHUmKO4Jf0zkiMq+GfxDeyp6opuwCOe68/pyt+vGcDZjy+1Z0c5o0mJLGfJ/Rfwi+c3udjfNMSrKm5O+4y72n9AFCaKjalkxPhWm92R2/P+wg+nBlBmcv+w1ZeywELLQCm1SWs93Of+zUHYZ362g9lr89zun9HhHX7X7hO2ne7J9sqe5Ne0A+C6NsvJjC10e1ylOZZSYzIZMSXk16QDigjMpESVs686gwjM9InLswsfWLyqY8bWtI6sIDWq3OV5T5tjvQr3s4U30TWmkJ5x+UQrA5+fGMve6gy+LR/Gr1JXMDZpM8mRpzhiaMsFSRtJj64f9lh68hc8efh2jhjaEh9RzbCEbFKjyni56wtux114bAIP5t9nf60wkxpZzt3tF3Bz2uf29i2nexOJiQEJe12dxi1mrThtjqNVpOcHuGatqNIxfF8xiC9PjObTE64f8CnM9I/fR9eYI9ToaFIjy6gyx1Bk6sCtV03ljvcsxeGiMHJl6rcMS9jJuYk76BhTYv8Mfqg4GzMRvFx0A5tO9XUqftUh+ig3tPmKKGVCozgvcRttok6SGlXGouPjKDC0Iz6iiguTf6TKHMM35cO4vPV3KDTxEdWkRx+nyNCGUmMKEZgZmmiZ6LOjsjt7qzNoH1VKz7hD7K3O4LWiKeyo7MGd7RbSPbaAD45dzI7K7uQbOhCjDLSNOkGhId3nay3CfubQIoX9nvk/OS0w4A/tokppG3WS7KosbF5otDLQObqYUmMK5WZvecWa81ttJiGykmhl4uuyEVSYEwBNnKpmaOIuUiPLOVDTkThVzR/afUiUMpEZW8gHxy5ifulEDETxu/SPMOhoIjDz1clR7Kzyr1iZP0RhZETiTnrFHcCkI9lf04k4VcN3FUM81guJwsg1qV/zqzYraBNZhokIescdZE35YF4vvo5jxmSGJu6i2NCGnVXdOTt+L+e32sSFyRtoE1VGpTmWI4a2xEbUUGpMITWyjOyqLLrEHOGEMZmvys5jdflQRrf6iYmt19EpuoS+8XkA5NekE6sMzC29nE7RJfSJO0DnmGLaRR93a+/e6s4sOzmSbjGHuSxlrdO+5SfPZXtlD7JiC7gqtTa1sdiQyl8P/5bdVd2YlLKGO9I/Jjai1uPfdron0cpot8sV+6o7YdBRRGFmT3VXxidtIDbCyDFjMmvKh3DC1IoXjvyGMnPTVj4UYT9zCKqwK6UmAv8EIoG3tNbPeOofqLDf8d+N9jSzlsC5WW2cSgqcyXSIPspv0z7lypRv6/0qya7MJCbCwAfHLqbSHMtxYzJZsQXU6Gh6xOZzTuIOp19kc49ezqySqyk0pDt55R2jSziv1TZ6xh7i6tSv6RBde+1/Pt2Df5dMpsSYSm5VF0pNlrz1CEwkRlQxPnkDvVtX8Z/8UdZfDOUUGCy/7mzEqmrSo467jIHXZd5vz2XaW+t9vj6927diT5ElRXLtjPFUVBu5+CVLKFCE/czBX2EP+OGpUioSeB24CMgHflRKfaa19r1IuI94qkTYPS3R5ezHcCbah1TCM4UjhjSeKryNpwpvo0/cfgbE57Ctsje7qzJ9OFozMD6HIkMbiozua3EXGtL5+PiFALxcdAPXtVlGr9hDvHX0Kg7WdHR5jJlIys2JLDpxAVdndebEAUuJ6NPm+qVhq3Wsk6gnxEQ6zbB1xN+a4elJsXZh75QSz0nr7OWkuGaR9yCEiIZ8O84BcrXW+wCUUguAK4FGF3ZPddKb4xc8jNPyG4W2iTGU+pC6WJddVVnsqsry4wjFtsrefo1RrWP4b+kkv46Ji/bvRpwUF+VW2P3F3XyCxJjm970XgkdDXMfOwCGH1/nWNieUUrcrpTYqpTaWlPifHQBwu8PiGY9N6sfMX/Zj8d2juffCXvzr18P440W1f9y2JdM6WGt4XNinHYkxrj3+xJhIXvhV7Uy9cWelM7RrChmp8UwemsE5WW0sbzQlnuvP6cqvhmXwy0GdePCSs+z7bPzu/B727TG90rhmSGdemuI8CzCtVQw927XiuWsH8cDFtTYn1LGvs4sFAyKU5YbQs10rbhmVRfvkWPs5PS0TN/28TAAemtiHtokxXDssg3enj+DW0RYBdVwdZ2zvdEZ2b8ugLilcNbgTgzJa1zufTeTSWsW4tB3gw9+N5LIBtR5s55R4np08wK2N/tDdRa2Vl6c4V4t093nXpVe7VgzKaE1bh/ridRmU0ZqZV/S3v46PjrR/9gkxkTxyeV8Arhlq+erfPCqTJfeO5fzetQ9BrxzciYSYSBbc/gsALunfnssHduSKQZ2Yfl4mI7u3JTUhmj9c0INe1pID08/LZFTPtjx77UA+vGMk/7h2IACtE6L588SzmG89lyC4IuAYu1LqWmCi1vq31te/Ac7VWt/l7phAY+yCIAhnMv7G2BvisRcAXRxeZ1jbBEEQhBDSEGH/EeillMpSSsUAU4HPGscsQRAEIVACfgKjtTYqpe4ClmJJd3xHa+17IQ9BEAShSWjQo3Wt9ZeA96pPgiAIQtCQhGpBEIQWhgi7IAhCC0OEXRAEoYUhwi4IgtDCCGp1R6VUCeC6sLp30oCGLbLZdIhtgSG2BYbYFhjN2bZuWmufazoHVdgbglJqoz8zr4KJ2BYYYltgiG2BcSbZJqEYQRCEFoYIuyAIQgujOQn7rFAb4AGxLTDEtsAQ2wLjjLGt2cTYBUEQBN9oTh67IAiC4AMi7IIgCC2MZiHsSqmJSqndSqlcpdSMII/dRSm1Sim1Uym1Qyl1r7V9plKqQCm1xfrvModjHrbaulspdUkQbMxTSv1stWOjta2NUmq5UirH+n+qtV0ppV6x2rdNKTW0iWw6y+HabFFKlSml7gvldVNKvaOUKlZKbXdo8/s6KaVusvbPUUrd1IS2PaeU2mUd/1OlVIq1PVMpVelwDd90OGaY9buQa7W/wQsxurHN78+xKf6O3dj2gYNdeUqpLdb2YF83d9rR9N85rXVY/8NSEngv0B2IAbYC/YI4fkdgqHU7CdgD9ANmAg+46N/PamMs9SQI0wAAA+5JREFUkGW1PbKJbcwD0uq0/QOYYd2eATxr3b4M+ApQwC+A9UH6DI8A3UJ53YCxwFBge6DXCWgD7LP+n2rdTm0i2y4GoqzbzzrYlunYr855NljtVVb7L20i2/z6HJvq79iVbXX2vwA8FqLr5k47mvw71xw8dvui2VrrGsC2aHZQ0FoXaq03W7fLgWxcrO3qwJXAAq11tdZ6P5CL5T0EmyuBOdbtOcBVDu1ztYUfgBSlVMcmtuVCYK/W2tOs4ya/blrr1cAxF+P6c50uAZZrrY9prY8Dy4GJTWGb1nqZ1tpoffkDllXK3GK1L1lr/YO2KMJch/fTqLZ5wN3n2CR/x55ss3rd1wHzPZ2jCa+bO+1o8u9ccxB2nxbNDgZKqUxgCLDe2nSX9SfTO7afU4TGXg0sU0ptUkrdbm1rr7UutG4fAdqH0L6pOP9xhct1A/+vU6jsvAWLN2cjSyn1k1LqW6XUGGtbZ6s9wbLNn88xFNdtDFCktc5xaAvJdaujHU3+nWsOwh4WKKVaAR8D92mty4A3gB7AYKAQy0++UDFaaz0UuBT4g1JqrONOqxcSkrxWZVk28QpgobUpnK6bE6G8Tp5QSv0FMALzrE2FQFet9RDgj8D7SqnkIJsVtp+jA9fj7FCE5Lq50A47TfWdaw7CHvJFs5VS0Vg+mHla608AtNZFWmuT1toM/IfasEHQ7dVaF1j/LwY+tdpSZAuxWP8vDpF9lwKbtdZFVhvD5rpZ8fc6BdVOpdR0YBIwzSoCWMMcpdbtTVhi172tdjiGa5rMtgA+x2BftyjgGuADB5uDft1caQdB+M41B2EP6aLZ1jjd20C21vpFh3bHuPTVgO2p/GfAVKVUrFIqC+iF5cFMU9mXqJRKsm1jeeC23WqH7en5TcAiB/tutD6B/wVw0uFnYVPg5DWFy3VzwN/rtBS4WCmVag0/XGxta3SUUhOBPwNXaK1PO7SnK6UirdvdsVyrfVb7ypRSv7B+b290eD+NbZu/n2Ow/44nALu01vYQS7CvmzvtIBjfuYY++Q3GPyxPi/dgucP+Jchjj8byU2kbsMX67zLgv8DP1vbPgI4Ox/zFautuGuHpuhf7umPJMNgK7LBdH6AtsBLIAVYAbaztCnjdat/PwPAmtC0RKAVaO7SF7LphucEUAgYsccpbA7lOWOLdudZ/NzehbblYYqu2792b1r6TrZ/1FmAz8EuH8wzHIrJ7gdewzi5vAtv8/hyb4u/YlW3W9tnA7+r0DfZ1c6cdTf6dk5ICgiAILYzmEIoRBEEQ/ECEXRAEoYUhwi4IgtDCEGEXBEFoYYiwC4IgtDBE2AVBEFoYIuyCIAgtjP8HYrVeIy5RP6UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {'Reward':  stats.episode_rewards}\n",
    "df = pd.DataFrame (data)\n",
    "\n",
    "rolling_mean = df.Reward.rolling(window=50).mean()\n",
    "\n",
    "plt.plot(df.index, df.Reward, label='SER Reward')\n",
    "plt.plot(df.index, rolling_mean, label='SER MA Reward', color='orange')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "df.to_csv('output_SER.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
